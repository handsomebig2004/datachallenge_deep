{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3376c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — Exp04 (Method 4) paths + config\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# ====== Your provided paths ======\n",
    "X_TEST_DIR  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_test_xNbnvIa\")\n",
    "X_TRAIN_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_train_uDRk9z9\")\n",
    "X_UNLAB_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_unlabeled_mtkxUlo\")\n",
    "Y_TRAIN_CSV = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\Y_train_T9NrBYo.csv\")\n",
    "SAMPLE_SUB  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\submission_csv_file_random_example_3qPSCtv.csv\")\n",
    "\n",
    "# ====== Outputs ======\n",
    "OUT_DIR = Path(r\"exp_outputs\\Exp04_SSL_SegFormer_Semi\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SSL_DIR  = OUT_DIR / \"ssl_pretrain\"\n",
    "SUP_DIR  = OUT_DIR / \"supervised_finetune\"\n",
    "SEMI_DIR = OUT_DIR / \"semi_train\"\n",
    "for d in [SSL_DIR, SUP_DIR, SEMI_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ====== constants ======\n",
    "NUM_CLASSES  = 3\n",
    "IGNORE_INDEX = 255\n",
    "H            = 160\n",
    "W_PAD        = 288  # pad to 288, later crop to 160/272\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db345f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — utilities: file listing (no double counting), parse name, load/pad X, load/pad Y\n",
    "NAME_RE = re.compile(r\"well_(\\d+)_section_(\\d+)_patch_(\\d+)$\")\n",
    "\n",
    "def parse_name(stem: str):\n",
    "    m = NAME_RE.match(stem)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Bad patch name: {stem}\")\n",
    "    return int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "\n",
    "def list_npy_files(dir_path: Path):\n",
    "    # de-dup robustly; avoids Windows *.npy/*.NPY double counting\n",
    "    files = list(dir_path.rglob(\"*.npy\")) + list(dir_path.rglob(\"*.NPY\"))\n",
    "    uniq = sorted({Path(p).resolve() for p in files})\n",
    "    return [Path(p) for p in uniq]\n",
    "\n",
    "def load_x(path: Path) -> np.ndarray:\n",
    "    x = np.load(path)\n",
    "    if x.ndim == 3 and x.shape[0] == 1:\n",
    "        x = x[0]\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "    else:\n",
    "        x = np.zeros_like(x, dtype=np.float32)\n",
    "    return x  # (160,w)\n",
    "\n",
    "def pad_x_to_wpad(x: np.ndarray) -> np.ndarray:\n",
    "    h, w = x.shape\n",
    "    out = np.zeros((h, W_PAD), dtype=np.float32)\n",
    "    out[:, :w] = x\n",
    "    return out\n",
    "\n",
    "def make_valid_mask(w: int) -> np.ndarray:\n",
    "    valid = np.zeros((H, W_PAD), dtype=np.bool_)\n",
    "    valid[:, :w] = True\n",
    "    return valid\n",
    "\n",
    "y_df = pd.read_csv(Y_TRAIN_CSV, index_col=0)\n",
    "\n",
    "def restore_mask_from_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    vals = row_values[row_values != -1]\n",
    "    return vals.reshape(H, -1).astype(np.int64)  # (160,160) or (160,272)\n",
    "\n",
    "def pad_mask_to_wpad(mask: np.ndarray, w: int) -> np.ndarray:\n",
    "    out = np.full((H, W_PAD), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849f8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train(all images): 4410\n",
      "train(labeled):    4410\n",
      "unlabeled:         1980\n",
      "SSL pool:          6390\n",
      "test:              972\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — build manifests (train/unlab/test) + SSL pool = (train+unlab images)\n",
    "def build_manifest(x_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in list_npy_files(x_dir):\n",
    "        stem = p.stem\n",
    "        try:\n",
    "            well, section, patch = parse_name(stem)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        arr = np.load(p, mmap_mode=\"r\")\n",
    "        if arr.ndim == 3 and arr.shape[0] == 1:\n",
    "            w = int(arr.shape[2])\n",
    "        elif arr.ndim == 2:\n",
    "            w = int(arr.shape[1])\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected shape {arr.shape} for {p}\")\n",
    "        rows.append({\"name\": stem, \"well\": well, \"section\": section, \"patch\": patch, \"w\": w, \"path\": str(p)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_df = build_manifest(X_TRAIN_DIR)\n",
    "unlab_df = build_manifest(X_UNLAB_DIR)\n",
    "test_df  = build_manifest(X_TEST_DIR)\n",
    "\n",
    "# labeled train only\n",
    "train_labeled_df = train_df[train_df[\"name\"].isin(y_df.index)].reset_index(drop=True)\n",
    "\n",
    "# SSL uses: all train images (even if labeled) + unlabeled\n",
    "ssl_df = pd.concat([train_df, unlab_df], axis=0, ignore_index=True)\n",
    "ssl_df = ssl_df.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"train(all images):\", len(train_df))\n",
    "print(\"train(labeled):   \", len(train_labeled_df))\n",
    "print(\"unlabeled:        \", len(unlab_df))\n",
    "print(\"SSL pool:         \", len(ssl_df))\n",
    "print(\"test:             \", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bc23ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl batch: torch.Size([32, 1, 160, 288])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — SSL augmentations (SimSiam): two random views from same image\n",
    "def ssl_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (B,1,H,W_PAD) in [0,1]\n",
    "    B, _, Hh, Ww = x.shape\n",
    "\n",
    "    # intensity jitter\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.85, 1.15)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.08, 0.08)\n",
    "    out = torch.clamp(x * a + b, 0.0, 1.0)\n",
    "\n",
    "    # noise\n",
    "    sigma = torch.empty((B,1,1,1), device=x.device).uniform_(0.0, 0.06)\n",
    "    out = torch.clamp(out + torch.randn_like(out) * sigma, 0.0, 1.0)\n",
    "\n",
    "    # random horizontal flip\n",
    "    if torch.rand(()) < 0.5:\n",
    "        out = torch.flip(out, dims=[3])\n",
    "\n",
    "    # cutout\n",
    "    for i in range(B):\n",
    "        if torch.rand((), device=x.device).item() < 0.5:\n",
    "            ch = int(torch.randint(low=10, high=50, size=(1,), device=x.device).item())\n",
    "            cw = int(torch.randint(low=10, high=80, size=(1,), device=x.device).item())\n",
    "            y0 = int(torch.randint(low=0, high=Hh-ch+1, size=(1,), device=x.device).item())\n",
    "            x0 = int(torch.randint(low=0, high=Ww-cw+1, size=(1,), device=x.device).item())\n",
    "            out[i, :, y0:y0+ch, x0:x0+cw] = 0.0\n",
    "\n",
    "    return out\n",
    "\n",
    "class SSLDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        x = load_x(Path(row[\"path\"]))      # (160,w)\n",
    "        x = pad_x_to_wpad(x)               # (160,288)\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)  # (1,160,288)\n",
    "        # return raw tensor; augment will be done on GPU in training step for speed\n",
    "        return x_t\n",
    "\n",
    "ssl_loader = DataLoader(SSLDataset(ssl_df), batch_size=32, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "xb = next(iter(ssl_loader))\n",
    "print(\"ssl batch:\", xb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ffff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimSiam backbone last hidden: 512\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — SimSiam with SegFormer backbone\n",
    "from transformers import SegformerModel\n",
    "\n",
    "BACKBONE = \"nvidia/segformer-b2-finetuned-ade-512-512\"\n",
    "\n",
    "def global_pool(feat: torch.Tensor) -> torch.Tensor:\n",
    "    # feat: (B,C,H,W) -> (B,C)\n",
    "    return feat.mean(dim=(2,3))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "            nn.BatchNorm1d(out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimSiamSegFormer(nn.Module):\n",
    "    def __init__(self, backbone_name: str, proj_dim=256, pred_dim=256, hidden=1024):\n",
    "        super().__init__()\n",
    "        self.backbone = SegformerModel.from_pretrained(backbone_name)\n",
    "        # infer feature dim: segformer config has hidden_sizes per stage; last stage is strongest\n",
    "        feat_dim = self.backbone.config.hidden_sizes[-1]\n",
    "        self.projector = MLP(feat_dim, hidden, proj_dim)\n",
    "        self.predictor = Predictor(proj_dim, hidden//2, pred_dim)\n",
    "\n",
    "    def encode(self, x3):\n",
    "        # x3: (B,3,160,288)\n",
    "        out = self.backbone(pixel_values=x3, output_hidden_states=True)\n",
    "        # last stage feature map is hidden_states[-1] with shape (B,C,H',W')\n",
    "        feat = out.hidden_states[-1]\n",
    "        v = global_pool(feat)\n",
    "        z = self.projector(v)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.encode(x1)\n",
    "        z2 = self.encode(x2)\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        return p1, p2, z1.detach(), z2.detach()\n",
    "\n",
    "def neg_cos(p, z):\n",
    "    p = F.normalize(p, dim=1)\n",
    "    z = F.normalize(z, dim=1)\n",
    "    return -(p * z).sum(dim=1).mean()\n",
    "\n",
    "ssl_model = SimSiamSegFormer(BACKBONE).to(DEVICE)\n",
    "print(\"SimSiam backbone last hidden:\", ssl_model.backbone.config.hidden_sizes[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f65c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\3364793642.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp04-SSL] ep1:   0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\3364793642.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep01/10 loss=-0.8257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep02/10 loss=-0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep03/10 loss=-0.7892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep04/10 loss=-0.7829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep05/10 loss=-0.7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep06/10 loss=-0.7763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep07/10 loss=-0.7881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep08/10 loss=-0.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep09/10 loss=-0.7974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep10/10 loss=-0.8028\n",
      "[Exp04-SSL] best loss: -0.9305095878938368\n",
      "saved ssl_ckpt: exp_outputs\\Exp04_SSL_SegFormer_Semi\\ssl_pretrain\\ssl_best.pt\n",
      "saved ssl_backbone: exp_outputs\\Exp04_SSL_SegFormer_Semi\\ssl_pretrain\\segformer_backbone_ssl.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 5 — SSL pretrain loop (SimSiam) -> save backbone weights\n",
    "SSL_EPOCHS = 10\n",
    "SSL_LR = 3e-4\n",
    "SSL_WD = 1e-4\n",
    "\n",
    "opt = torch.optim.AdamW(ssl_model.parameters(), lr=SSL_LR, weight_decay=SSL_WD)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "best_ssl = 1e9\n",
    "ssl_ckpt = SSL_DIR / \"ssl_best.pt\"\n",
    "ssl_backbone = SSL_DIR / \"segformer_backbone_ssl.pt\"\n",
    "\n",
    "ssl_model.train()\n",
    "for ep in range(1, SSL_EPOCHS+1):\n",
    "    loss_sum, n = 0.0, 0\n",
    "    for x in tqdm(ssl_loader, desc=f\"[Exp04-SSL] ep{ep}\", leave=False):\n",
    "        x = x.to(DEVICE)  # (B,1,160,288)\n",
    "\n",
    "        # two views on GPU\n",
    "        x1 = ssl_aug(x)\n",
    "        x2 = ssl_aug(x)\n",
    "\n",
    "        # segformer needs 3 channels\n",
    "        x1 = x1.repeat(1,3,1,1)\n",
    "        x2 = x2.repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            p1, p2, z1, z2 = ssl_model(x1, x2)\n",
    "            loss = 0.5 * (neg_cos(p1, z2) + neg_cos(p2, z1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        loss_sum += float(loss.item()) * x.size(0)\n",
    "        n += x.size(0)\n",
    "\n",
    "    ep_loss = loss_sum / max(1, n)\n",
    "    print(f\"[Exp04-SSL] ep{ep:02d}/{SSL_EPOCHS} loss={ep_loss:.4f}\")\n",
    "\n",
    "    if ep_loss < best_ssl:\n",
    "        best_ssl = ep_loss\n",
    "        torch.save({\"model\": ssl_model.state_dict()}, ssl_ckpt)\n",
    "        # save ONLY backbone weights for later init\n",
    "        torch.save(ssl_model.backbone.state_dict(), ssl_backbone)\n",
    "\n",
    "print(\"[Exp04-SSL] best loss:\", best_ssl)\n",
    "print(\"saved ssl_ckpt:\", ssl_ckpt)\n",
    "print(\"saved ssl_backbone:\", ssl_backbone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df252dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\1604660959.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bb_state = torch.load(ssl_backbone, map_location=DEVICE)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\1604660959.py:90: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SSL backbone into model.segformer: exp_outputs\\Exp04_SSL_SegFormer_Semi\\ssl_pretrain\\segformer_backbone_ssl.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] train ep1:   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\1604660959.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep01/10 train_loss=0.2109 val_mIoU=0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep02/10 train_loss=0.1044 val_mIoU=0.7821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep03/10 train_loss=0.0945 val_mIoU=0.7847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep04/10 train_loss=0.0903 val_mIoU=0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep05/10 train_loss=0.0872 val_mIoU=0.7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep06/10 train_loss=0.0838 val_mIoU=0.7824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep07/10 train_loss=0.0813 val_mIoU=0.7956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep08/10 train_loss=0.0793 val_mIoU=0.7907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep09/10 train_loss=0.0770 val_mIoU=0.7948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep10/10 train_loss=0.0749 val_mIoU=0.8003\n",
      "[Exp04-SUP] BEST val mIoU: 0.8002571794721816 saved: exp_outputs\\Exp04_SSL_SegFormer_Semi\\supervised_finetune\\best_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Supervised finetune SegFormer (init backbone from SSL) on labeled data\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "# split by well\n",
    "VAL_WELLS = {5}\n",
    "train_split = train_labeled_df[~train_labeled_df[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "val_split   = train_labeled_df[train_labeled_df[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "\n",
    "class LabeledDatasetSup(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, train_mode: bool, seed=123):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.train_mode = train_mode\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        name = row[\"name\"]\n",
    "        w = int(row[\"w\"])\n",
    "\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)\n",
    "\n",
    "        y_raw = restore_mask_from_row(y_df.loc[name].values)\n",
    "        y = pad_mask_to_wpad(y_raw, w=w)\n",
    "\n",
    "        if self.train_mode and self.rng.rand() < 0.5:\n",
    "            x = np.flip(x, axis=1).copy()\n",
    "            y = np.flip(y, axis=1).copy()\n",
    "\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)  # (1,160,288)\n",
    "        y_t = torch.from_numpy(y).long()        # (160,288)\n",
    "        meta = {\"name\": name, \"orig_w\": w}\n",
    "        return x_t, y_t, meta\n",
    "\n",
    "train_loader = DataLoader(LabeledDatasetSup(train_split, True), batch_size=8, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "val_loader   = DataLoader(LabeledDatasetSup(val_split,   False), batch_size=8, shuffle=False, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "# losses\n",
    "ce_weights = torch.tensor([1.0, 3.0, 4.0], dtype=torch.float32).to(DEVICE)\n",
    "ce = nn.CrossEntropyLoss(weight=ce_weights, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "def soft_dice_loss(logits, target, smooth=1.0):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    valid = (target != IGNORE_INDEX).unsqueeze(1)\n",
    "    t = target.clone()\n",
    "    t[t == IGNORE_INDEX] = 0\n",
    "    onehot = F.one_hot(t, num_classes=NUM_CLASSES).permute(0,3,1,2).float()\n",
    "    probs = probs * valid\n",
    "    onehot = onehot * valid\n",
    "    inter = (probs * onehot).sum((0,2,3))\n",
    "    denom = (probs + onehot).sum((0,2,3))\n",
    "    dice = (2*inter + smooth) / (denom + smooth)\n",
    "    return 1.0 - dice.mean()\n",
    "\n",
    "def combo_loss(logits, y, dice_w=0.5):\n",
    "    return (1-dice_w)*ce(logits, y) + dice_w*soft_dice_loss(logits, y)\n",
    "\n",
    "def upsample_logits(logits, target_hw):\n",
    "    return F.interpolate(logits, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "def mean_iou(pred, target):\n",
    "    valid = (target != IGNORE_INDEX)\n",
    "    ious = []\n",
    "    for c in range(NUM_CLASSES):\n",
    "        p = (pred == c) & valid\n",
    "        t = (target == c) & valid\n",
    "        inter = (p & t).sum().float()\n",
    "        union = (p | t).sum().float()\n",
    "        ious.append(torch.tensor(1.0, device=pred.device) if union.item()==0 else inter/union)\n",
    "    return torch.stack(ious).mean()\n",
    "\n",
    "# build model\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "# load SSL backbone\n",
    "ssl_backbone = SSL_DIR / \"segformer_backbone_ssl.pt\"\n",
    "bb_state = torch.load(ssl_backbone, map_location=DEVICE)\n",
    "model.segformer.load_state_dict(bb_state, strict=False)\n",
    "print(\"Loaded SSL backbone into model.segformer:\", ssl_backbone)\n",
    "\n",
    "# train\n",
    "SUP_EPOCHS = 10\n",
    "SUP_LR = 6e-5\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=SUP_LR, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "best_path = SUP_DIR / \"best_state_dict.pt\"\n",
    "best_miou = -1.0\n",
    "\n",
    "for ep in range(1, SUP_EPOCHS+1):\n",
    "    model.train()\n",
    "    tr_loss, n = 0.0, 0\n",
    "    for x, y, meta in tqdm(train_loader, desc=f\"[Exp04-SUP] train ep{ep}\", leave=False):\n",
    "        x = x.to(DEVICE)            # (B,1,160,288)\n",
    "        y = y.to(DEVICE)            # (B,160,288)\n",
    "        x3 = x.repeat(1,3,1,1)      # (B,3,160,288)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            loss = combo_loss(logits, y, dice_w=0.5)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        tr_loss += float(loss.item()) * x.size(0)\n",
    "        n += x.size(0)\n",
    "    tr_loss /= max(1, n)\n",
    "\n",
    "    model.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(val_loader, desc=f\"[Exp04-SUP] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            x3 = x.repeat(1,3,1,1)\n",
    "            logits = model(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1, n)\n",
    "\n",
    "    print(f\"[Exp04-SUP] ep{ep:02d}/{SUP_EPOCHS} train_loss={tr_loss:.4f} val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "\n",
    "print(\"[Exp04-SUP] BEST val mIoU:\", best_miou, \"saved:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deb05d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\3083726334.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sup_state = torch.load(best_path, map_location=DEVICE)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\3083726334.py:76: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp04-SEMI] train ep1 (lam_u=0.20):   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\3083726334.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep01/10 val_mIoU=0.8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep02/10 val_mIoU=0.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep03/10 val_mIoU=0.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep04/10 val_mIoU=0.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep05/10 val_mIoU=0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep06/10 val_mIoU=0.7985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep07/10 val_mIoU=0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep08/10 val_mIoU=0.7984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep09/10 val_mIoU=0.7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep10/10 val_mIoU=0.7981\n",
      "[Exp04-SEMI] BEST val mIoU: 0.806527747048272 saved: exp_outputs\\Exp04_SSL_SegFormer_Semi\\semi_train\\best_state_dict.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Semi-supervised (EMA Teacher) starting from Exp04 supervised best\n",
    "# unlabeled loader (reuse unlab_df)\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        w = int(row[\"w\"])\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)\n",
    "        valid = torch.from_numpy(make_valid_mask(w))\n",
    "        return x_t, valid\n",
    "\n",
    "unlab_loader = DataLoader(UnlabeledDataset(unlab_df), batch_size=8, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "def weak_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B = x.size(0)\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.95, 1.05)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.03, 0.03)\n",
    "    return torch.clamp(x * a + b, 0.0, 1.0)\n",
    "\n",
    "def strong_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B, _, Hh, Ww = x.shape\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.85, 1.15)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.08, 0.08)\n",
    "    out = torch.clamp(x * a + b, 0.0, 1.0)\n",
    "    sigma = torch.empty((B,1,1,1), device=x.device).uniform_(0.0, 0.06)\n",
    "    out = torch.clamp(out + torch.randn_like(out) * sigma, 0.0, 1.0)\n",
    "    for i in range(B):\n",
    "        if torch.rand((), device=x.device).item() < 0.5:\n",
    "            ch = int(torch.randint(low=10, high=50, size=(1,), device=x.device).item())\n",
    "            cw = int(torch.randint(low=10, high=80, size=(1,), device=x.device).item())\n",
    "            y0 = int(torch.randint(low=0, high=Hh-ch+1, size=(1,), device=x.device).item())\n",
    "            x0 = int(torch.randint(low=0, high=Ww-cw+1, size=(1,), device=x.device).item())\n",
    "            out[i, :, y0:y0+ch, x0:x0+cw] = 0.0\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(teacher, student, alpha: float):\n",
    "    for t_p, s_p in zip(teacher.parameters(), student.parameters()):\n",
    "        t_p.data.mul_(alpha).add_(s_p.data, alpha=1.0 - alpha)\n",
    "    for t_b, s_b in zip(teacher.buffers(), student.buffers()):\n",
    "        t_b.copy_(s_b)\n",
    "\n",
    "def cycle(loader):\n",
    "    while True:\n",
    "        for b in loader:\n",
    "            yield b\n",
    "\n",
    "# init student/teacher from supervised best\n",
    "student = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "teacher = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "sup_state = torch.load(best_path, map_location=DEVICE)\n",
    "student.load_state_dict(sup_state)\n",
    "teacher.load_state_dict(sup_state)\n",
    "teacher.eval()\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "# unlabeled CE loss (ignore_index)\n",
    "ce_u = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
    "\n",
    "def rampup(epoch: int, ramp_epochs=5):\n",
    "    return min(1.0, float(epoch+1)/float(ramp_epochs))\n",
    "\n",
    "SEMI_EPOCHS = 10\n",
    "LR = 6e-5\n",
    "opt = torch.optim.AdamW(student.parameters(), lr=LR, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "TAU = 0.95\n",
    "EMA_ALPHA = 0.996\n",
    "LAMBDA_U = 1.0\n",
    "RAMP_E = 5\n",
    "\n",
    "semi_best = SEMI_DIR / \"best_state_dict.pt\"\n",
    "best_miou = -1.0\n",
    "\n",
    "unlab_iter = cycle(unlab_loader)\n",
    "\n",
    "for ep in range(1, SEMI_EPOCHS+1):\n",
    "    lam_u = LAMBDA_U * rampup(ep-1, RAMP_E)\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "\n",
    "    for x_l, y_l, meta in tqdm(train_loader, desc=f\"[Exp04-SEMI] train ep{ep} (lam_u={lam_u:.2f})\", leave=False):\n",
    "        x_u, valid_u = next(unlab_iter)\n",
    "\n",
    "        x_l = x_l.to(DEVICE)              # (B,1,160,288)\n",
    "        y_l = y_l.to(DEVICE)              # (B,160,288)\n",
    "        x_u = x_u.to(DEVICE)              # (B,1,160,288)\n",
    "        valid_u = valid_u.to(DEVICE)      # (B,160,288)\n",
    "\n",
    "        x_l3 = x_l.repeat(1,3,1,1)\n",
    "\n",
    "        x_u_w = weak_aug(x_u).repeat(1,3,1,1)\n",
    "        x_u_s = strong_aug(x_u).repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            # labeled\n",
    "            logits_l = student(pixel_values=x_l3).logits\n",
    "            logits_l = upsample_logits(logits_l, y_l.shape[-2:])\n",
    "            loss_l = combo_loss(logits_l, y_l, dice_w=0.5)\n",
    "\n",
    "            # teacher pseudo\n",
    "            with torch.no_grad():\n",
    "                logits_t = teacher(pixel_values=x_u_w).logits\n",
    "                logits_t = upsample_logits(logits_t, (H, W_PAD))\n",
    "                probs_t = torch.softmax(logits_t, dim=1)\n",
    "                conf, pseudo = torch.max(probs_t, dim=1)  # (B,160,288)\n",
    "                mask = (conf >= TAU) & valid_u\n",
    "                pseudo_pl = pseudo.clone()\n",
    "                pseudo_pl[~mask] = IGNORE_INDEX\n",
    "\n",
    "            # unlabeled loss\n",
    "            if lam_u > 0:\n",
    "                logits_u = student(pixel_values=x_u_s).logits\n",
    "                logits_u = upsample_logits(logits_u, (H, W_PAD))\n",
    "                loss_u = ce_u(logits_u, pseudo_pl)\n",
    "            else:\n",
    "                loss_u = torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "            loss = loss_l + lam_u * loss_u\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        ema_update(teacher, student, EMA_ALPHA)\n",
    "\n",
    "    # val\n",
    "    student.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(val_loader, desc=f\"[Exp04-SEMI] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            x3 = x.repeat(1,3,1,1)\n",
    "            logits = student(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1, n)\n",
    "    print(f\"[Exp04-SEMI] ep{ep:02d}/{SEMI_EPOCHS} val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(student.state_dict(), semi_best)\n",
    "\n",
    "print(\"[Exp04-SEMI] BEST val mIoU:\", best_miou, \"saved:\", semi_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d11209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample rows: 972 name_col: Unnamed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6428\\2643865133.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(semi_best, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Exp04 semi best: exp_outputs\\Exp04_SSL_SegFormer_Semi\\semi_train\\best_state_dict.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved npy predictions to: exp_outputs\\Exp04_SSL_SegFormer_Semi\\test_predictions\n",
      "Saved submission: exp_outputs\\Exp04_SSL_SegFormer_Semi\\y_test_submission_MATCH_SAMPLE.csv shape: (972, 43521)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 — Predict test (by sample order) using Exp04 semi best, save npy + submission CSV\n",
    "sample = pd.read_csv(SAMPLE_SUB)\n",
    "name_col = sample.columns[0]\n",
    "ordered_names_raw = sample[name_col].astype(str).tolist()\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    if s.lower().endswith(\".npy\"):\n",
    "        s = s[:-4]\n",
    "    return s\n",
    "\n",
    "ordered_names = [norm_name(n) for n in ordered_names_raw]\n",
    "print(\"sample rows:\", len(ordered_names), \"name_col:\", name_col)\n",
    "\n",
    "test_files = list_npy_files(X_TEST_DIR)\n",
    "test_index = {p.stem: p for p in test_files}\n",
    "test_index.update({p.stem.lower(): p for p in test_files})\n",
    "\n",
    "# load best semi student\n",
    "student = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "student.load_state_dict(torch.load(semi_best, map_location=DEVICE))\n",
    "student.eval()\n",
    "print(\"Loaded Exp04 semi best:\", semi_best)\n",
    "\n",
    "pred_dir = OUT_DIR / \"test_predictions\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "for p in pred_dir.glob(\"*.npy\"):\n",
    "    p.unlink()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name in tqdm(ordered_names, desc=\"[Exp04] predict test\", leave=False):\n",
    "        key = name if name in test_index else name.lower()\n",
    "        if key not in test_index:\n",
    "            hits = list(X_TEST_DIR.rglob(f\"{name}.npy\")) + list(X_TEST_DIR.rglob(f\"{name}.NPY\"))\n",
    "            if len(hits) == 0:\n",
    "                raise FileNotFoundError(f\"X_test missing: {name}.npy\")\n",
    "            x_path = hits[0]\n",
    "        else:\n",
    "            x_path = test_index[key]\n",
    "\n",
    "        x = load_x(x_path)\n",
    "        w = x.shape[1]\n",
    "        x_pad = pad_x_to_wpad(x)\n",
    "        x_t = torch.from_numpy(x_pad).unsqueeze(0).unsqueeze(0).to(DEVICE)  # (1,1,160,288)\n",
    "        x_t = x_t.repeat(1,3,1,1)\n",
    "\n",
    "        logits = student(pixel_values=x_t).logits\n",
    "        logits = upsample_logits(logits, (H, W_PAD))\n",
    "        pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)\n",
    "        pred = pred[:, :w]\n",
    "        np.save(pred_dir / f\"{name}.npy\", pred)\n",
    "\n",
    "print(\"saved npy predictions to:\", pred_dir)\n",
    "\n",
    "# build submission CSV (exact sample format)\n",
    "size_labels = 272\n",
    "flat_len = H * size_labels\n",
    "\n",
    "pred_map = {}\n",
    "for p in pred_dir.glob(\"*.npy\"):\n",
    "    nm = p.stem\n",
    "    pred = np.load(p)\n",
    "    if pred.shape[1] != size_labels:\n",
    "        aux = -1 + np.zeros(flat_len, dtype=np.int64)\n",
    "        aux[0:H*H] = pred.flatten()\n",
    "    else:\n",
    "        aux = pred.flatten().astype(np.int64)\n",
    "    pred_map[nm] = aux\n",
    "\n",
    "missing = [n for n in ordered_names if n not in pred_map]\n",
    "assert len(missing) == 0, f\"missing predictions: {missing[:10]}\"\n",
    "\n",
    "data = np.stack([pred_map[n] for n in ordered_names], axis=0)\n",
    "col_names = [str(i) for i in range(flat_len)]\n",
    "sub_df = pd.DataFrame(data, columns=col_names)\n",
    "sub_df.insert(0, name_col, ordered_names_raw)\n",
    "\n",
    "out_csv = OUT_DIR / \"y_test_submission_MATCH_SAMPLE.csv\"\n",
    "sub_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved submission:\", out_csv, \"shape:\", sub_df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepseg)",
   "language": "python",
   "name": "deepseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
