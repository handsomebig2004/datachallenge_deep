{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140b2c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — Exp04c config & paths (NO semi-supervised)\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# ====== Paths (your provided) ======\n",
    "X_TEST_DIR  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_test_xNbnvIa\")\n",
    "X_TRAIN_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_train_uDRk9z9\")\n",
    "X_UNLAB_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_unlabeled_mtkxUlo\")\n",
    "Y_TRAIN_CSV = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\Y_train_T9NrBYo.csv\")\n",
    "SAMPLE_SUB  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\submission_csv_file_random_example_3qPSCtv.csv\")\n",
    "\n",
    "OUT_DIR = Path(r\"exp_outputs\\Exp04c_SSLCombo_then_SUP\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SSL_DIR  = OUT_DIR / \"ssl_pretrain\"\n",
    "SUP_DIR  = OUT_DIR / \"supervised\"\n",
    "SUB_DIR  = OUT_DIR / \"test_predictions\"\n",
    "for d in [SSL_DIR, SUP_DIR, SUB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ====== constants ======\n",
    "NUM_CLASSES  = 3\n",
    "IGNORE_INDEX = 255\n",
    "H            = 160\n",
    "W_PAD        = 288          # train on padded width\n",
    "SIZE_LABELS  = 272          # submission flatten width\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "BACKBONE = \"nvidia/segformer-b2-finetuned-ade-512-512\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15fbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Utilities: de-dup list npy, parse, load/pad X, load/pad Y\n",
    "NAME_RE = re.compile(r\"well_(\\d+)_section_(\\d+)_patch_(\\d+)$\")\n",
    "\n",
    "def parse_name(stem: str):\n",
    "    m = NAME_RE.match(stem)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Bad patch name: {stem}\")\n",
    "    return int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "\n",
    "def list_npy_files(dir_path: Path):\n",
    "    files = list(dir_path.rglob(\"*.npy\")) + list(dir_path.rglob(\"*.NPY\"))\n",
    "    uniq = sorted({Path(p).resolve() for p in files})  # de-dup\n",
    "    return [Path(p) for p in uniq]\n",
    "\n",
    "def load_x(path: Path) -> np.ndarray:\n",
    "    x = np.load(path)\n",
    "    if x.ndim == 3 and x.shape[0] == 1:\n",
    "        x = x[0]\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "    else:\n",
    "        x = np.zeros_like(x, dtype=np.float32)\n",
    "    return x  # (160,w)\n",
    "\n",
    "def pad_x_to_wpad(x: np.ndarray) -> np.ndarray:\n",
    "    h, w = x.shape\n",
    "    out = np.zeros((h, W_PAD), dtype=np.float32)\n",
    "    out[:, :w] = x\n",
    "    return out\n",
    "\n",
    "def make_valid_mask(w: int) -> np.ndarray:\n",
    "    valid = np.zeros((H, W_PAD), dtype=np.bool_)\n",
    "    valid[:, :w] = True\n",
    "    return valid\n",
    "\n",
    "y_df = pd.read_csv(Y_TRAIN_CSV, index_col=0)\n",
    "\n",
    "def restore_mask_from_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    vals = row_values[row_values != -1]\n",
    "    return vals.reshape(H, -1).astype(np.int64)  # (160,160) or (160,272)\n",
    "\n",
    "def pad_mask_to_wpad(mask: np.ndarray, w: int) -> np.ndarray:\n",
    "    out = np.full((H, W_PAD), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa39fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train(all): 4410 labeled: 4410\n",
      "unlabeled : 1980\n",
      "ssl pool  : 6390 width: {272: 4230, 160: 2160}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Build manifests: ssl_df = (train images + unlabeled images)\n",
    "def build_manifest(x_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in list_npy_files(x_dir):\n",
    "        stem = p.stem\n",
    "        try:\n",
    "            parse_name(stem)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        arr = np.load(p, mmap_mode=\"r\")\n",
    "        if arr.ndim == 3 and arr.shape[0] == 1:\n",
    "            w = int(arr.shape[2])\n",
    "        elif arr.ndim == 2:\n",
    "            w = int(arr.shape[1])\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected shape {arr.shape} for {p}\")\n",
    "        rows.append({\"name\": stem, \"w\": w, \"path\": str(p)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_all = build_manifest(X_TRAIN_DIR)\n",
    "unlab_all = build_manifest(X_UNLAB_DIR)\n",
    "\n",
    "ssl_df = pd.concat([train_all, unlab_all], axis=0, ignore_index=True)\n",
    "ssl_df = ssl_df.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
    "\n",
    "# labeled subset for supervised\n",
    "train_labeled = train_all[train_all[\"name\"].isin(y_df.index)].reset_index(drop=True)\n",
    "\n",
    "print(\"train(all):\", len(train_all), \"labeled:\", len(train_labeled))\n",
    "print(\"unlabeled :\", len(unlab_all))\n",
    "print(\"ssl pool  :\", len(ssl_df), \"width:\", ssl_df[\"w\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb822efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — SSL Dataset + augment + masking (for recon)\n",
    "class SSLDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        w = int(row[\"w\"])\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)                       # (160,288)\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)     # (1,160,288)\n",
    "        valid = torch.from_numpy(make_valid_mask(w))  # (160,288) bool\n",
    "        return x_t, valid\n",
    "\n",
    "ssl_loader = DataLoader(\n",
    "    SSLDataset(ssl_df),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=(DEVICE==\"cuda\"),\n",
    ")\n",
    "\n",
    "def intensity_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (B,1,H,W) in [0,1]\n",
    "    B = x.size(0)\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.85, 1.15)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.08, 0.08)\n",
    "    out = torch.clamp(x * a + b, 0.0, 1.0)\n",
    "    sigma = torch.empty((B,1,1,1), device=x.device).uniform_(0.0, 0.04)\n",
    "    out = torch.clamp(out + torch.randn_like(out) * sigma, 0.0, 1.0)\n",
    "    if torch.rand((), device=x.device).item() < 0.5:\n",
    "        out = torch.flip(out, dims=[3])\n",
    "    return out\n",
    "\n",
    "def block_mask(valid: torch.Tensor, drop_prob=0.9, block_h=16, block_w=32):\n",
    "    # valid: (B,H,W) bool -> mask: (B,1,H,W) bool\n",
    "    B, Hh, Ww = valid.shape\n",
    "    mask = torch.zeros((B,1,Hh,Ww), dtype=torch.bool, device=valid.device)\n",
    "    for i in range(B):\n",
    "        if torch.rand((), device=valid.device).item() < drop_prob:\n",
    "            y0 = int(torch.randint(0, Hh-block_h+1, (1,), device=valid.device).item())\n",
    "            x0 = int(torch.randint(0, Ww-block_w+1, (1,), device=valid.device).item())\n",
    "            mask[i, :, y0:y0+block_h, x0:x0+block_w] = True\n",
    "    mask = mask & valid.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "def apply_mask(x: torch.Tensor, m: torch.Tensor):\n",
    "    x2 = x.clone()\n",
    "    x2[m] = 0.0\n",
    "    return x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "352816ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_model ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — SSL Model: SegFormer encoder + SimSiam head + Recon head (combo self-supervised)\n",
    "from transformers import SegformerModel\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    a = F.normalize(a, dim=1)\n",
    "    b = F.normalize(b, dim=1)\n",
    "    return (a * b).sum(dim=1).mean()\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class ReconHead(nn.Module):\n",
    "    def __init__(self, in_ch: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch//2, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_ch//2, 1, 1),\n",
    "        )\n",
    "    def forward(self, feat, out_hw=(H, W_PAD)):\n",
    "        x = self.conv(feat)  # (B,1,h',w')\n",
    "        x = F.interpolate(x, size=out_hw, mode=\"bilinear\", align_corners=False)\n",
    "        return torch.sigmoid(x)  # [0,1]\n",
    "\n",
    "class SegFormerSSLCombo(nn.Module):\n",
    "    def __init__(self, backbone_name: str, proj_dim=256, pred_dim=256, hidden=1024):\n",
    "        super().__init__()\n",
    "        self.backbone = SegformerModel.from_pretrained(backbone_name)\n",
    "        feat_dim = self.backbone.config.hidden_sizes[-1]\n",
    "        self.projector = MLP(feat_dim, hidden, proj_dim)\n",
    "        self.predictor = Predictor(proj_dim, hidden//2, pred_dim)\n",
    "        self.recon = ReconHead(feat_dim)\n",
    "\n",
    "    def forward_once(self, x3):\n",
    "        out = self.backbone(pixel_values=x3, output_hidden_states=True)\n",
    "        feat = out.hidden_states[-1]                 # (B,C,h',w')\n",
    "        v = feat.mean(dim=(2,3))                     # (B,C)\n",
    "        z = self.projector(v)                        # (B,D)\n",
    "        p = self.predictor(z)                        # (B,D)\n",
    "        r = self.recon(feat, out_hw=(H, W_PAD))      # (B,1,160,288)\n",
    "        return p, z, r\n",
    "\n",
    "    def forward(self, x1_3, x2_3):\n",
    "        p1, z1, r1 = self.forward_once(x1_3)\n",
    "        p2, z2, r2 = self.forward_once(x2_3)\n",
    "        return p1, p2, z1.detach(), z2.detach(), r1, r2\n",
    "\n",
    "ssl_model = SegFormerSSLCombo(BACKBONE).to(DEVICE)\n",
    "print(\"ssl_model ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc21626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_22704\\3005491715.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp04c-SSL] ep1:   0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_22704\\3005491715.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep01/10 loss=0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep02/10 loss=0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep03/10 loss=0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep04/10 loss=0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep05/10 loss=0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep06/10 loss=0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep07/10 loss=0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep08/10 loss=0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep09/10 loss=0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SSL] ep10/10 loss=0.0121\n",
      "[Exp04c-SSL] best loss: 0.012052356737996678\n",
      "saved ssl ckpt: exp_outputs\\Exp04c_SSLCombo_then_SUP\\ssl_pretrain\\ssl_combo_best.pt\n",
      "saved backbone: exp_outputs\\Exp04c_SSLCombo_then_SUP\\ssl_pretrain\\segformer_backbone_ssl_combo.pt\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — SSL pretrain loop (combo): SimSiam (1-cos) + masked recon MSE\n",
    "SSL_EPOCHS = 10\n",
    "LR = 3e-4\n",
    "WD = 1e-4\n",
    "LAMBDA_REC = 1.0\n",
    "\n",
    "opt = torch.optim.AdamW(ssl_model.parameters(), lr=LR, weight_decay=WD)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "best_ssl = 1e9\n",
    "ssl_best_ckpt = SSL_DIR / \"ssl_combo_best.pt\"\n",
    "ssl_backbone_path = SSL_DIR / \"segformer_backbone_ssl_combo.pt\"\n",
    "\n",
    "for ep in range(1, SSL_EPOCHS+1):\n",
    "    ssl_model.train()\n",
    "    loss_sum, n = 0.0, 0\n",
    "\n",
    "    for x, valid in tqdm(ssl_loader, desc=f\"[Exp04c-SSL] ep{ep}\", leave=False):\n",
    "        x = x.to(DEVICE)                 # (B,1,160,288)\n",
    "        valid = valid.to(DEVICE)         # (B,160,288) bool\n",
    "\n",
    "        # two views\n",
    "        x1 = intensity_aug(x)\n",
    "        x2 = intensity_aug(x)\n",
    "\n",
    "        # mask for reconstruction\n",
    "        m1 = block_mask(valid, drop_prob=0.9, block_h=16, block_w=32)\n",
    "        m2 = block_mask(valid, drop_prob=0.9, block_h=16, block_w=32)\n",
    "\n",
    "        x1_in = apply_mask(x1, m1)\n",
    "        x2_in = apply_mask(x2, m2)\n",
    "\n",
    "        x1_3 = x1_in.repeat(1,3,1,1)\n",
    "        x2_3 = x2_in.repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            p1, p2, z1, z2, r1, r2 = ssl_model(x1_3, x2_3)\n",
    "\n",
    "            # SimSiam loss: (1 - cosine) >= 0, smaller is better\n",
    "            sim_loss = 0.5 * ((1.0 - cos_sim(p1, z2)) + (1.0 - cos_sim(p2, z1)))\n",
    "\n",
    "            # masked recon MSE on masked pixels only\n",
    "            denom1 = m1.sum().clamp(min=1).float()\n",
    "            denom2 = m2.sum().clamp(min=1).float()\n",
    "            rec1 = ((r1 - x1)**2)[m1].sum() / denom1\n",
    "            rec2 = ((r2 - x2)**2)[m2].sum() / denom2\n",
    "            rec_loss = 0.5 * (rec1 + rec2)\n",
    "\n",
    "            loss = sim_loss + LAMBDA_REC * rec_loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        loss_sum += float(loss.item()) * x.size(0)\n",
    "        n += x.size(0)\n",
    "\n",
    "    ep_loss = loss_sum / max(1, n)\n",
    "    print(f\"[Exp04c-SSL] ep{ep:02d}/{SSL_EPOCHS} loss={ep_loss:.4f}\")\n",
    "\n",
    "    if ep_loss < best_ssl:\n",
    "        best_ssl = ep_loss\n",
    "        torch.save({\"model\": ssl_model.state_dict()}, ssl_best_ckpt)\n",
    "        torch.save(ssl_model.backbone.state_dict(), ssl_backbone_path)\n",
    "\n",
    "print(\"[Exp04c-SSL] best loss:\", best_ssl)\n",
    "print(\"saved ssl ckpt:\", ssl_best_ckpt)\n",
    "print(\"saved backbone:\", ssl_backbone_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a69e7d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split: 4122 val_split: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_22704\\181794350.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bb_state = torch.load(ssl_backbone_path, map_location=DEVICE)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_22704\\181794350.py:108: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SSL backbone: exp_outputs\\Exp04c_SSLCombo_then_SUP\\ssl_pretrain\\segformer_backbone_ssl_combo.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] train ep1:   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_22704\\181794350.py:121: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep01/10 val_mIoU=0.7560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep02/10 val_mIoU=0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep03/10 val_mIoU=0.7931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep04/10 val_mIoU=0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep05/10 val_mIoU=0.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep06/10 val_mIoU=0.7903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep07/10 val_mIoU=0.7898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep08/10 val_mIoU=0.8031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep09/10 val_mIoU=0.7858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04c-SUP] ep10/10 val_mIoU=0.7911\n",
      "[Exp04c-SUP] BEST val mIoU: 0.8031896617677476 saved: exp_outputs\\Exp04c_SSLCombo_then_SUP\\supervised\\best_state_dict.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Supervised SegFormer finetune using SSL backbone (NO semi-supervised)\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "# split by well (you can change VAL_WELLS)\n",
    "VAL_WELLS = {5}\n",
    "\n",
    "# we need well info for split -> rebuild manifest with well\n",
    "def build_manifest_with_well(x_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in list_npy_files(x_dir):\n",
    "        stem = p.stem\n",
    "        try:\n",
    "            well, section, patch = parse_name(stem)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        arr = np.load(p, mmap_mode=\"r\")\n",
    "        if arr.ndim == 3 and arr.shape[0] == 1:\n",
    "            w = int(arr.shape[2])\n",
    "        elif arr.ndim == 2:\n",
    "            w = int(arr.shape[1])\n",
    "        else:\n",
    "            raise ValueError(arr.shape)\n",
    "        rows.append({\"name\": stem, \"well\": well, \"w\": w, \"path\": str(p)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_all2 = build_manifest_with_well(X_TRAIN_DIR)\n",
    "train_labeled2 = train_all2[train_all2[\"name\"].isin(y_df.index)].reset_index(drop=True)\n",
    "\n",
    "train_split = train_labeled2[~train_labeled2[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "val_split   = train_labeled2[train_labeled2[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "print(\"train_split:\", len(train_split), \"val_split:\", len(val_split))\n",
    "\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, train_mode: bool, seed=123):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.train_mode = train_mode\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        name = row[\"name\"]\n",
    "        w = int(row[\"w\"])\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)\n",
    "\n",
    "        y_raw = restore_mask_from_row(y_df.loc[name].values)\n",
    "        y = pad_mask_to_wpad(y_raw, w=w)\n",
    "\n",
    "        # safe aug: horizontal flip\n",
    "        if self.train_mode and self.rng.rand() < 0.5:\n",
    "            x = np.flip(x, axis=1).copy()\n",
    "            y = np.flip(y, axis=1).copy()\n",
    "\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)   # (1,160,288)\n",
    "        y_t = torch.from_numpy(y).long()         # (160,288)\n",
    "        return x_t, y_t\n",
    "\n",
    "train_loader = DataLoader(LabeledDataset(train_split, True), batch_size=8, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "val_loader   = DataLoader(LabeledDataset(val_split,   False), batch_size=8, shuffle=False, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "# loss/metric\n",
    "ce_weights = torch.tensor([1.0, 3.0, 4.0], dtype=torch.float32).to(DEVICE)\n",
    "ce = nn.CrossEntropyLoss(weight=ce_weights, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "def soft_dice_loss(logits, target, smooth=1.0):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    valid = (target != IGNORE_INDEX).unsqueeze(1)\n",
    "    t = target.clone()\n",
    "    t[t == IGNORE_INDEX] = 0\n",
    "    onehot = F.one_hot(t, num_classes=NUM_CLASSES).permute(0,3,1,2).float()\n",
    "    probs = probs * valid\n",
    "    onehot = onehot * valid\n",
    "    inter = (probs * onehot).sum((0,2,3))\n",
    "    denom = (probs + onehot).sum((0,2,3))\n",
    "    dice = (2*inter + smooth) / (denom + smooth)\n",
    "    return 1.0 - dice.mean()\n",
    "\n",
    "def combo_loss(logits, y, dice_w=0.5):\n",
    "    return (1-dice_w)*ce(logits, y) + dice_w*soft_dice_loss(logits, y)\n",
    "\n",
    "def upsample_logits(logits, target_hw):\n",
    "    return F.interpolate(logits, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "def mean_iou(pred, target):\n",
    "    valid = (target != IGNORE_INDEX)\n",
    "    ious = []\n",
    "    for c in range(NUM_CLASSES):\n",
    "        p = (pred == c) & valid\n",
    "        t = (target == c) & valid\n",
    "        inter = (p & t).sum().float()\n",
    "        union = (p | t).sum().float()\n",
    "        ious.append(torch.tensor(1.0, device=pred.device) if union.item()==0 else inter/union)\n",
    "    return torch.stack(ious).mean()\n",
    "\n",
    "# model init\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "# load SSL backbone into model.segformer\n",
    "bb_state = torch.load(ssl_backbone_path, map_location=DEVICE)\n",
    "model.segformer.load_state_dict(bb_state, strict=False)\n",
    "print(\"Loaded SSL backbone:\", ssl_backbone_path)\n",
    "\n",
    "SUP_EPOCHS = 10\n",
    "SUP_LR = 6e-5\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=SUP_LR, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "best_miou = -1.0\n",
    "sup_best = SUP_DIR / \"best_state_dict.pt\"\n",
    "\n",
    "for ep in range(1, SUP_EPOCHS+1):\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader, desc=f\"[Exp04c-SUP] train ep{ep}\", leave=False):\n",
    "        x = x.to(DEVICE)             # (B,1,160,288)\n",
    "        y = y.to(DEVICE)             # (B,160,288)\n",
    "        x3 = x.repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            loss = combo_loss(logits, y, dice_w=0.5)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader, desc=f\"[Exp04c-SUP] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            x3 = x.repeat(1,3,1,1)\n",
    "            logits = model(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1, n)\n",
    "    print(f\"[Exp04c-SUP] ep{ep:02d}/{SUP_EPOCHS} val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(model.state_dict(), sup_best)\n",
    "\n",
    "print(\"[Exp04c-SUP] BEST val mIoU:\", best_miou, \"saved:\", sup_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1791aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample rows: 972 name_col: Unnamed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_22704\\1044417495.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(sup_best, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sup best: exp_outputs\\Exp04c_SSLCombo_then_SUP\\supervised\\best_state_dict.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved npy predictions to: exp_outputs\\Exp04c_SSLCombo_then_SUP\\test_predictions\n",
      "Saved submission: exp_outputs\\Exp04c_SSLCombo_then_SUP\\y_test_submission_MATCH_SAMPLE.csv shape: (972, 43521)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Predict test by SAMPLE order + save npy + submission CSV (NO missing, only 972)\n",
    "# 1) read sample\n",
    "sample = pd.read_csv(SAMPLE_SUB)\n",
    "name_col = sample.columns[0]\n",
    "ordered_names_raw = sample[name_col].astype(str).tolist()\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    if s.lower().endswith(\".npy\"):\n",
    "        s = s[:-4]\n",
    "    return s\n",
    "\n",
    "ordered_names = [norm_name(n) for n in ordered_names_raw]\n",
    "print(\"sample rows:\", len(ordered_names), \"name_col:\", name_col)\n",
    "\n",
    "# 2) index all X_test files\n",
    "test_files = list_npy_files(X_TEST_DIR)\n",
    "test_index = {p.stem: p for p in test_files}\n",
    "test_index.update({p.stem.lower(): p for p in test_files})\n",
    "\n",
    "# 3) load best supervised model\n",
    "model.load_state_dict(torch.load(sup_best, map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"Loaded sup best:\", sup_best)\n",
    "\n",
    "# clear old preds\n",
    "for p in SUB_DIR.glob(\"*.npy\"):\n",
    "    p.unlink()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name in tqdm(ordered_names, desc=\"[Exp04c] predict test\", leave=False):\n",
    "        key = name if name in test_index else name.lower()\n",
    "        if key not in test_index:\n",
    "            hits = list(X_TEST_DIR.rglob(f\"{name}.npy\")) + list(X_TEST_DIR.rglob(f\"{name}.NPY\"))\n",
    "            if len(hits) == 0:\n",
    "                raise FileNotFoundError(f\"X_test missing: {name}.npy\")\n",
    "            x_path = hits[0]\n",
    "        else:\n",
    "            x_path = test_index[key]\n",
    "\n",
    "        x = load_x(x_path)              # (160,w)\n",
    "        w = x.shape[1]\n",
    "        x_pad = pad_x_to_wpad(x)        # (160,288)\n",
    "        x_t = torch.from_numpy(x_pad).unsqueeze(0).unsqueeze(0).to(DEVICE)  # (1,1,160,288)\n",
    "        x_t = x_t.repeat(1,3,1,1)\n",
    "\n",
    "        logits = model(pixel_values=x_t).logits\n",
    "        logits = upsample_logits(logits, (H, W_PAD))\n",
    "        pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)  # (160,288)\n",
    "        pred = pred[:, :w]  # crop back to original width (160/272)\n",
    "        np.save(SUB_DIR / f\"{name}.npy\", pred)\n",
    "\n",
    "print(\"saved npy predictions to:\", SUB_DIR)\n",
    "\n",
    "# 4) build submission csv matching sample format\n",
    "flat_len = H * SIZE_LABELS  # 160*272 = 43520\n",
    "\n",
    "pred_map = {}\n",
    "for p in SUB_DIR.glob(\"*.npy\"):\n",
    "    nm = p.stem\n",
    "    pred = np.load(p)  # (160,160) or (160,272)\n",
    "    if pred.shape[1] != SIZE_LABELS:\n",
    "        aux = -1 + np.zeros(flat_len, dtype=np.int64)\n",
    "        aux[0:H*H] = pred.flatten()\n",
    "    else:\n",
    "        aux = pred.flatten().astype(np.int64)\n",
    "    pred_map[nm] = aux\n",
    "\n",
    "missing = [n for n in ordered_names if n not in pred_map]\n",
    "assert len(missing) == 0, f\"missing predictions: {missing[:10]}\"\n",
    "\n",
    "data = np.stack([pred_map[n] for n in ordered_names], axis=0)  # (972, 43520)\n",
    "col_names = [str(i) for i in range(flat_len)]\n",
    "\n",
    "sub_df = pd.DataFrame(data, columns=col_names)\n",
    "sub_df.insert(0, name_col, ordered_names_raw)\n",
    "\n",
    "out_csv = OUT_DIR / \"y_test_submission_MATCH_SAMPLE.csv\"\n",
    "sub_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved submission:\", out_csv, \"shape:\", sub_df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepseg)",
   "language": "python",
   "name": "deepseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
