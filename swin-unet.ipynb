{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e433fe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Train dir: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\X_train_uDRk9z9\\images\n",
      "Test dir:  C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\X_test_xNbnvIa\\images\n",
      "Model input size: 224x224\n",
      "Train samples: 2790 | Val samples: 1620 | val_wells={6}\n",
      "Epoch 01/20 | train_loss=0.2381 | val_loss=0.0994\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_swin_unet.pth\n",
      "Epoch 02/20 | train_loss=0.0835 | val_loss=0.0767\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_swin_unet.pth\n",
      "Epoch 03/20 | train_loss=0.0714 | val_loss=0.0793\n",
      "Epoch 04/20 | train_loss=0.0675 | val_loss=0.0746\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_swin_unet.pth\n",
      "Epoch 05/20 | train_loss=0.0666 | val_loss=0.0761\n",
      "Epoch 06/20 | train_loss=0.0645 | val_loss=0.0755\n",
      "Epoch 07/20 | train_loss=0.0617 | val_loss=0.0773\n",
      "Epoch 08/20 | train_loss=0.0612 | val_loss=0.0849\n",
      "Epoch 09/20 | train_loss=0.0611 | val_loss=0.0784\n",
      "Epoch 10/20 | train_loss=0.0592 | val_loss=0.0773\n",
      "Epoch 11/20 | train_loss=0.0579 | val_loss=0.0828\n",
      "Epoch 12/20 | train_loss=0.0592 | val_loss=0.0735\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_swin_unet.pth\n",
      "Epoch 13/20 | train_loss=0.0567 | val_loss=0.0888\n",
      "Epoch 14/20 | train_loss=0.0567 | val_loss=0.0778\n",
      "Epoch 15/20 | train_loss=0.0560 | val_loss=0.0914\n",
      "Epoch 16/20 | train_loss=0.0553 | val_loss=0.0889\n",
      "Epoch 17/20 | train_loss=0.0540 | val_loss=0.0812\n",
      "Epoch 18/20 | train_loss=0.0536 | val_loss=0.0970\n",
      "Epoch 19/20 | train_loss=0.0535 | val_loss=0.0803\n",
      "Epoch 20/20 | train_loss=0.0532 | val_loss=0.0901\n",
      "[OK] submission saved to: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Swin-UNet (Swin Transformer encoder + UNet decoder) - Full runnable code (224x224 input for Swin)\n",
    "\n",
    "Pipeline:\n",
    "- Train images:   X_train_uDRk9z9/images (well1-6)\n",
    "- Test images:    X_test_xNbnvIa/images  (well7-11)\n",
    "- Train labels:   Y_train_T9NrBYo.csv (flatten + -1 padding)\n",
    "- Validation split: well6 as val, well1-5 as train\n",
    "- Output: submission.csv (each row = one patch, flattened, padded to 160*272 with -1)\n",
    "\n",
    "Key point:\n",
    "- Swin encoders in timm/SMP often expect 224x224 inputs.\n",
    "- We resize image/mask to 224x224 for training and inference.\n",
    "- During inference we upsample logits back to (160,272), then crop to raw width and pad with -1 to match submission format.\n",
    "\n",
    "Dependencies:\n",
    "    pip install timm segmentation-models-pytorch\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0. Paths & Hyperparameters\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lenovo\\Desktop\\deep_datachallenge\")  # change to your path\n",
    "\n",
    "TRAIN_IMAGES_DIR = DATA_ROOT / \"X_train_uDRk9z9\" / \"images\"\n",
    "TEST_IMAGES_DIR = DATA_ROOT / \"X_test_xNbnvIa\" / \"images\"\n",
    "Y_TRAIN_CSV = DATA_ROOT / \"Y_train_T9NrBYo.csv\"\n",
    "\n",
    "# Original target size used by dataset/submission format\n",
    "TARGET_H = 160\n",
    "TARGET_W = 272\n",
    "\n",
    "# Model input size for Swin\n",
    "MODEL_H = 224\n",
    "MODEL_W = 224\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "IGNORE_INDEX = -1\n",
    "\n",
    "BATCH_SIZE = 4          # for RTX 4060(8GB), start with 2~4\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 20\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1. Utils\n",
    "# =========================\n",
    "def parse_well_id(name: str) -> int:\n",
    "    \"\"\"Extract well id from: well_1_section_0_patch_0 -> 1\"\"\"\n",
    "    m = re.search(r\"well_(\\d+)_\", name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def minmax_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Min-max normalize; replace NaN/inf with 0.\"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    x_min = float(x.min())\n",
    "    x_max = float(x.max())\n",
    "    if x_max - x_min < 1e-6:\n",
    "        return np.zeros_like(x, dtype=np.float32)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "\n",
    "def pad_to_160x272(img: np.ndarray, fill_value: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"Pad (160,160) or (160,272) to (160,272).\"\"\"\n",
    "    h, w = img.shape\n",
    "    assert h == TARGET_H, f\"Expected height {TARGET_H}, got {h}\"\n",
    "    if w == TARGET_W:\n",
    "        return img\n",
    "    if w < TARGET_W:\n",
    "        out = np.full((TARGET_H, TARGET_W), fill_value, dtype=img.dtype)\n",
    "        out[:, :w] = img\n",
    "        return out\n",
    "    return img[:, :TARGET_W]\n",
    "\n",
    "\n",
    "def decode_mask_from_csv_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Decode a mask from one CSV row:\n",
    "    - row_values: flattened mask with -1 padding\n",
    "    - remove -1 then reshape to (160, w)\n",
    "    \"\"\"\n",
    "    valid = row_values[row_values != IGNORE_INDEX]\n",
    "    assert len(valid) % TARGET_H == 0, f\"Valid mask length {len(valid)} not divisible by 160\"\n",
    "    w = len(valid) // TARGET_H\n",
    "    return valid.reshape(TARGET_H, w).astype(np.int64)\n",
    "\n",
    "\n",
    "def pad_mask_to_160x272(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Pad (160,w) to (160,272) using -1 for padding (ignore_index).\"\"\"\n",
    "    h, w = mask.shape\n",
    "    assert h == TARGET_H\n",
    "    if w == TARGET_W:\n",
    "        return mask\n",
    "    out = np.full((TARGET_H, TARGET_W), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n",
    "\n",
    "\n",
    "def resize_image_torch(img_t_1hw: torch.Tensor, h: int, w: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Resize an image tensor (1,H,W) -> (1,h,w) using bilinear.\n",
    "    \"\"\"\n",
    "    x = img_t_1hw.unsqueeze(0)  # (1,1,H,W)\n",
    "    x = F.interpolate(x, size=(h, w), mode=\"bilinear\", align_corners=False)\n",
    "    return x.squeeze(0)         # (1,h,w)\n",
    "\n",
    "\n",
    "def resize_mask_torch(mask_t_hw: torch.Tensor, h: int, w: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Resize a mask tensor (H,W) -> (h,w) using nearest.\n",
    "    IGNORE_INDEX is kept as-is via nearest interpolation.\n",
    "    \"\"\"\n",
    "    y = mask_t_hw.unsqueeze(0).unsqueeze(0).float()  # (1,1,H,W)\n",
    "    y = F.interpolate(y, size=(h, w), mode=\"nearest\")\n",
    "    return y.squeeze(0).squeeze(0).long()            # (h,w)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. Dataset\n",
    "# =========================\n",
    "class WellSegDataset(Dataset):\n",
    "    def __init__(self, images_dir: Path, y_csv_path: Path = None):\n",
    "        \"\"\"\n",
    "        If y_csv_path is None => test mode (no labels).\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.has_label = y_csv_path is not None\n",
    "\n",
    "        self.image_paths = sorted(images_dir.glob(\"*.npy\"))\n",
    "        self.names = [p.stem for p in self.image_paths]\n",
    "\n",
    "        if self.has_label:\n",
    "            self.y_df = pd.read_csv(y_csv_path, index_col=0)\n",
    "        else:\n",
    "            self.y_df = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        name = self.names[idx]\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        img = np.load(img_path)                 # (160,160) or (160,272)\n",
    "        raw_w = img.shape[1]                    # used to crop back at submission\n",
    "        img = minmax_normalize(img)\n",
    "        img = pad_to_160x272(img, fill_value=0.0)\n",
    "\n",
    "        # image: (1,160,272) -> resize to (1,224,224) for Swin\n",
    "        img_t = torch.from_numpy(img).unsqueeze(0).float()  # (1,160,272)\n",
    "        img_t_224 = resize_image_torch(img_t, MODEL_H, MODEL_W)  # (1,224,224)\n",
    "\n",
    "        if not self.has_label:\n",
    "            return {\"name\": name, \"image\": img_t_224, \"raw_w\": raw_w}\n",
    "\n",
    "        # mask: decode -> pad to (160,272) -> resize to (224,224) for training\n",
    "        row = self.y_df.loc[name].values.astype(np.int64)\n",
    "        mask = decode_mask_from_csv_row(row)     # (160,w)\n",
    "        mask = pad_mask_to_160x272(mask)         # (160,272)\n",
    "        mask_t = torch.from_numpy(mask).long()   # (160,272)\n",
    "        mask_t_224 = resize_mask_torch(mask_t, MODEL_H, MODEL_W)  # (224,224)\n",
    "\n",
    "        return {\"name\": name, \"image\": img_t_224, \"mask\": mask_t_224, \"raw_w\": raw_w}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. Swin-UNet model (SMP + timm)\n",
    "# =========================\n",
    "def choose_swin_encoder_name() -> str:\n",
    "    \"\"\"\n",
    "    Pick a Swin encoder name that exists in timm.\n",
    "    SMP uses timm models (sometimes with 'tu-' prefix).\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        \"tu-swin_tiny_patch4_window7_224\",\n",
    "        \"tu-swin_small_patch4_window7_224\",\n",
    "        \"tu-swin_base_patch4_window7_224\",\n",
    "        \"swin_tiny_patch4_window7_224\",\n",
    "        \"swin_small_patch4_window7_224\",\n",
    "        \"swin_base_patch4_window7_224\",\n",
    "    ]\n",
    "\n",
    "    timm_models = set(timm.list_models())\n",
    "    for name in candidates:\n",
    "        raw = name.replace(\"tu-\", \"\")\n",
    "        if raw in timm_models:\n",
    "            return name\n",
    "\n",
    "    return \"tu-swin_tiny_patch4_window7_224\"\n",
    "\n",
    "\n",
    "def build_swin_unet(num_classes: int) -> torch.nn.Module:\n",
    "    encoder_name = choose_swin_encoder_name()\n",
    "\n",
    "    # If your machine cannot download weights, set encoder_weights=None\n",
    "    model = smp.Unet(\n",
    "        encoder_name=encoder_name,\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=1,\n",
    "        classes=num_classes,\n",
    "        activation=None,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. Train / Validate\n",
    "# =========================\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)      # (B,1,224,224)\n",
    "        y = batch[\"mask\"].to(DEVICE)       # (B,224,224)\n",
    "\n",
    "        logits = model(x)                  # (B,C,224,224)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "        y = batch[\"mask\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. Inference & submission\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def predict_and_make_submission(model, test_images_dir: Path, out_csv_path: Path):\n",
    "    \"\"\"\n",
    "    Predict all .npy in test_images_dir and write submission.csv\n",
    "    - Model runs on 224x224 input\n",
    "    - Logits are upsampled back to (160,272)\n",
    "    - Then we crop to raw width and pad with -1 to match submission format\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    test_ds = WellSegDataset(test_images_dir, y_csv_path=None)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    preds_dict = {}\n",
    "\n",
    "    for batch in test_loader:\n",
    "        name = batch[\"name\"][0]\n",
    "        raw_w = int(batch[\"raw_w\"][0])\n",
    "        x = batch[\"image\"].to(DEVICE)  # (1,1,224,224)\n",
    "\n",
    "        logits_224 = model(x)  # (1,C,224,224)\n",
    "        logits = F.interpolate(logits_224, size=(TARGET_H, TARGET_W), mode=\"bilinear\", align_corners=False)\n",
    "        pred_full = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)  # (160,272)\n",
    "\n",
    "        pred = pred_full[:, :raw_w]  # crop back to original width\n",
    "\n",
    "        if raw_w < TARGET_W:\n",
    "            padded = np.full((TARGET_H * TARGET_W,), IGNORE_INDEX, dtype=np.int64)\n",
    "            padded[: TARGET_H * raw_w] = pred.flatten()\n",
    "            preds_dict[name] = padded\n",
    "        else:\n",
    "            preds_dict[name] = pred.flatten()\n",
    "\n",
    "    sub = pd.DataFrame(preds_dict, dtype=\"int64\").T\n",
    "    sub.to_csv(out_csv_path)\n",
    "    print(f\"[OK] submission saved to: {out_csv_path}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6. Main\n",
    "# =========================\n",
    "def main():\n",
    "    print(f\"DEVICE: {DEVICE}\")\n",
    "    print(f\"Train dir: {TRAIN_IMAGES_DIR}\")\n",
    "    print(f\"Test dir:  {TEST_IMAGES_DIR}\")\n",
    "    print(f\"Model input size: {MODEL_H}x{MODEL_W}\")\n",
    "\n",
    "    # (A) Load all train data (well1-6)\n",
    "    train_ds_all = WellSegDataset(TRAIN_IMAGES_DIR, Y_TRAIN_CSV)\n",
    "\n",
    "    # (B) Split by well: use well6 as validation\n",
    "    VAL_WELLS = {6}\n",
    "    train_indices, val_indices = [], []\n",
    "    for i, name in enumerate(train_ds_all.names):\n",
    "        w = parse_well_id(name)\n",
    "        if w in VAL_WELLS:\n",
    "            val_indices.append(i)\n",
    "        else:\n",
    "            train_indices.append(i)\n",
    "\n",
    "    train_ds = Subset(train_ds_all, train_indices)  # well1-5\n",
    "    val_ds = Subset(train_ds_all, val_indices)      # well6\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Train samples: {len(train_ds)} | Val samples: {len(val_ds)} | val_wells={VAL_WELLS}\")\n",
    "\n",
    "    # (C) Model & optimizer\n",
    "    model = build_swin_unet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    # (D) Train\n",
    "    best_val = 1e9\n",
    "    best_path = DATA_ROOT / \"best_swin_unet.pth\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "        va_loss = valid_one_epoch(model, val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{EPOCHS} | train_loss={tr_loss:.4f} | val_loss={va_loss:.4f}\")\n",
    "\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"  -> Best model saved: {best_path}\")\n",
    "\n",
    "    # (E) Predict test and write submission\n",
    "    out_csv = DATA_ROOT / \"submission.csv\"\n",
    "    state_dict = torch.load(best_path, map_location=DEVICE, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    predict_and_make_submission(model, TEST_IMAGES_DIR, out_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
