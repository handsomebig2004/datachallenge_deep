{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bff257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — Method 2 (SegFormer) 配置 + 路径（用你给的5个路径）\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "X_TEST_DIR  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_test_xNbnvIa\")\n",
    "X_TRAIN_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_train_uDRk9z9\")\n",
    "X_UNLAB_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_unlabeled_mtkxUlo\")\n",
    "Y_TRAIN_CSV = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\Y_train_T9NrBYo.csv\")\n",
    "SAMPLE_SUB  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\submission_csv_file_random_example_3qPSCtv.csv\")\n",
    "\n",
    "OUT_DIR = Path(r\"exp_outputs\\Exp02_SegFormer_keep272_pad288\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "IGNORE_INDEX = 255\n",
    "H = 160\n",
    "W_PAD = 288  # 为 SegFormer stride 更友好（32的倍数），推理/导出再裁回 160/272\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24fffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — 工具函数：解析名字 / 读取X / 读取Y（mask）/ padding\n",
    "NAME_RE = re.compile(r\"well_(\\d+)_section_(\\d+)_patch_(\\d+)$\")\n",
    "\n",
    "def parse_name(stem: str):\n",
    "    m = NAME_RE.match(stem)\n",
    "    if not m:\n",
    "        raise ValueError(stem)\n",
    "    return int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "\n",
    "def list_npy_once(dir_path: Path):\n",
    "    # Windows 下 *.npy 已经能匹配 .NPY，避免重复计数\n",
    "    return sorted(list(dir_path.rglob(\"*.npy\")))\n",
    "\n",
    "def load_x(path: Path) -> np.ndarray:\n",
    "    x = np.load(path)\n",
    "    if x.ndim == 3 and x.shape[0] == 1:\n",
    "        x = x[0]\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "    else:\n",
    "        x = np.zeros_like(x, dtype=np.float32)\n",
    "    return x  # (160,w)\n",
    "\n",
    "def pad_x_to_288(x: np.ndarray) -> np.ndarray:\n",
    "    h, w = x.shape\n",
    "    out = np.zeros((h, W_PAD), dtype=np.float32)\n",
    "    out[:, :w] = x\n",
    "    return out\n",
    "\n",
    "y_df = pd.read_csv(Y_TRAIN_CSV, index_col=0)\n",
    "\n",
    "def restore_mask_from_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    vals = row_values[row_values != -1]\n",
    "    return vals.reshape(160, -1).astype(np.int64)  # (160,160) or (160,272)\n",
    "\n",
    "def pad_mask_to_288(mask: np.ndarray, w: int) -> np.ndarray:\n",
    "    out = np.full((H, W_PAD), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n",
    "\n",
    "def make_valid_mask(w: int) -> np.ndarray:\n",
    "    valid = np.zeros((H, W_PAD), dtype=np.bool_)\n",
    "    valid[:, :w] = True\n",
    "    return valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a4c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 4410 w: {272: 3726, 160: 684} wells: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6)]\n",
      "unlab: 1980 w: {160: 1476, 272: 504}\n",
      "test : 972 w: {272: 972}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — manifest（train / unlabeled / test）\n",
    "def build_manifest(x_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in list_npy_once(x_dir):\n",
    "        stem = p.stem\n",
    "        well, section, patch = parse_name(stem)\n",
    "        arr = np.load(p, mmap_mode=\"r\")\n",
    "        if arr.ndim == 3 and arr.shape[0] == 1:\n",
    "            w = int(arr.shape[2])\n",
    "        elif arr.ndim == 2:\n",
    "            w = int(arr.shape[1])\n",
    "        else:\n",
    "            raise ValueError(arr.shape)\n",
    "        rows.append({\"name\": stem, \"well\": well, \"section\": section, \"patch\": patch, \"w\": w, \"path\": str(p)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_df = build_manifest(X_TRAIN_DIR)\n",
    "unlab_df = build_manifest(X_UNLAB_DIR)\n",
    "test_df  = build_manifest(X_TEST_DIR)\n",
    "\n",
    "# 只保留有标签的训练patch\n",
    "train_df = train_df[train_df[\"name\"].isin(y_df.index)].reset_index(drop=True)\n",
    "\n",
    "print(\"train:\", len(train_df), \"w:\", train_df[\"w\"].value_counts().to_dict(), \"wells:\", sorted(train_df[\"well\"].unique()))\n",
    "print(\"unlab:\", len(unlab_df), \"w:\", unlab_df[\"w\"].value_counts().to_dict())\n",
    "print(\"test :\", len(test_df),  \"w:\", test_df[\"w\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45e58c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split: 4122 val_split: 288\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Dataset + DataLoader（按 well 划分 val）\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SegDataset288(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, y_df: pd.DataFrame, train_mode: bool):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.y_df = y_df\n",
    "        self.train_mode = train_mode\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        name = row[\"name\"]\n",
    "        w = int(row[\"w\"])\n",
    "\n",
    "        x = load_x(Path(row[\"path\"]))          # (160,w)\n",
    "        x = pad_x_to_288(x)                    # (160,288)\n",
    "\n",
    "        # 简单增强（可删）\n",
    "        if self.train_mode:\n",
    "            if np.random.rand() < 0.5:\n",
    "                x = np.flip(x, axis=1).copy()\n",
    "\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)  # (1,160,288)\n",
    "        x_t = x_t.repeat(3, 1, 1)               # (3,160,288)\n",
    "\n",
    "\n",
    "        m = restore_mask_from_row(self.y_df.loc[name].values)  # (160,w)\n",
    "        y = pad_mask_to_288(m, w=w)                            # (160,288) padding 区 IGNORE\n",
    "        if self.train_mode:\n",
    "            if x.shape[1] == W_PAD and np.random.rand() < 0.5:\n",
    "                y = np.flip(y, axis=1).copy()\n",
    "\n",
    "        y_t = torch.from_numpy(y).long()\n",
    "        valid_t = torch.from_numpy(make_valid_mask(w))\n",
    "        meta = {\"name\": name, \"well\": int(row[\"well\"]), \"orig_w\": w}\n",
    "        return x_t, y_t, valid_t, meta\n",
    "\n",
    "VAL_WELLS = {5}  # 你也可以换成 {1} 或 {2} 等做对比\n",
    "train_split = train_df[~train_df[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "val_split   = train_df[train_df[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "\n",
    "train_loader = DataLoader(SegDataset288(train_split, y_df, train_mode=True),  batch_size=8, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(SegDataset288(val_split,   y_df, train_mode=False), batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"train_split:\", len(train_split), \"val_split:\", len(val_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd0dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Loss & Metric（ignore padding）\n",
    "# 用你统计的像素比例做一组合理权重（也可后面调）\n",
    "ce_weights = torch.tensor([1.0, 3.0, 4.0], dtype=torch.float32).to(DEVICE)\n",
    "ce = nn.CrossEntropyLoss(weight=ce_weights, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "def soft_dice_loss(logits, target, smooth=1.0):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    valid = (target != IGNORE_INDEX).unsqueeze(1)\n",
    "    t = target.clone()\n",
    "    t[t == IGNORE_INDEX] = 0\n",
    "    onehot = F.one_hot(t, num_classes=NUM_CLASSES).permute(0,3,1,2).float()\n",
    "    probs = probs * valid\n",
    "    onehot = onehot * valid\n",
    "    inter = (probs * onehot).sum((0,2,3))\n",
    "    denom = (probs + onehot).sum((0,2,3))\n",
    "    dice = (2*inter + smooth) / (denom + smooth)\n",
    "    return 1.0 - dice.mean()\n",
    "\n",
    "def combo_loss(logits, target, dice_w=0.5):\n",
    "    return (1-dice_w)*ce(logits, target) + dice_w*soft_dice_loss(logits, target)\n",
    "\n",
    "def mean_iou(pred, target):\n",
    "    valid = (target != IGNORE_INDEX)\n",
    "    ious = []\n",
    "    for c in range(NUM_CLASSES):\n",
    "        p = (pred == c) & valid\n",
    "        t = (target == c) & valid\n",
    "        inter = (p & t).sum().float()\n",
    "        union = (p | t).sum().float()\n",
    "        ious.append(torch.tensor(1.0, device=pred.device) if union.item()==0 else inter/union)\n",
    "    return torch.stack(ious).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bca1dc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded: nvidia/segformer-b2-finetuned-ade-512-512\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — SegFormer 模型（需要 transformers）\n",
    "# 如缺包：pip install transformers accelerate\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "BACKBONE = \"nvidia/segformer-b2-finetuned-ade-512-512\"  # 方法2：SegFormer（避开 ResNet34-UNet）\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE,\n",
    "    num_labels=NUM_CLASSES,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"model loaded:\", BACKBONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388b58dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6176\\1866584696.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp02] train ep1:   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6176\\1866584696.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                          \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input and target batch or spatial sizes don't match: target [8, 160, 288], input [8, 3, 40, 72]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.amp.autocast(enabled=(DEVICE==\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m     21\u001b[39m     logits = model(pixel_values=x).logits  \u001b[38;5;66;03m# (B,C,160,288)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     loss = \u001b[43mcombo_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdice_w\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m scaler.scale(loss).backward()\n\u001b[32m     25\u001b[39m scaler.step(opt)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mcombo_loss\u001b[39m\u001b[34m(logits, target, dice_w)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcombo_loss\u001b[39m(logits, target, dice_w=\u001b[32m0.5\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[32m1\u001b[39m-dice_w)*\u001b[43mce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m + dice_w*soft_dice_loss(logits, target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\deepseg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\deepseg\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\deepseg\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\deepseg\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3478\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3479\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3480\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3482\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3483\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3486\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: input and target batch or spatial sizes don't match: target [8, 160, 288], input [8, 3, 40, 72]"
     ]
    }
   ],
   "source": [
    "# Cell 6 — 训练（保存 best）\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_path = OUT_DIR / \"best.pt\"\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=6e-5, weight_decay=0.01)\n",
    "\n",
    "best_miou = -1.0\n",
    "EPOCHS = 10  # 先跑通；后面冲分再加\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    tr_loss, n = 0.0, 0\n",
    "    for x, y, valid, meta in tqdm(train_loader, desc=f\"[Exp02] train ep{ep}\", leave=False):\n",
    "        x = x.to(DEVICE)   # (B,1,160,288)\n",
    "        y = y.to(DEVICE)   # (B,160,288)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(pixel_values=x).logits  # (B,C,160,288)\n",
    "            loss = combo_loss(logits, y, dice_w=0.5)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        tr_loss += float(loss.item()) * x.size(0)\n",
    "        n += x.size(0)\n",
    "    tr_loss /= max(1,n)\n",
    "\n",
    "    model.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, valid, meta in tqdm(val_loader, desc=f\"[Exp02] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            logits = model(pixel_values=x).logits\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1,n)\n",
    "\n",
    "    print(f\"[Exp02] ep{ep:02d}/{EPOCHS}  train_loss={tr_loss:.4f}  val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "\n",
    "print(\"[Exp02] best mIoU:\", best_miou, \"saved:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cd725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — Exp02：重新对 test 预测（严格按样例 972 个名字），保存 npy + 生成正确 submission\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pred_dir = OUT_DIR / \"test_predictions\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 读取样例顺序\n",
    "sample = pd.read_csv(SAMPLE_SUB)\n",
    "name_col = sample.columns[0]\n",
    "ordered_names_raw = sample[name_col].astype(str).tolist()\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    if s.lower().endswith(\".npy\"):\n",
    "        s = s[:-4]\n",
    "    return s\n",
    "\n",
    "ordered_names = [norm_name(n) for n in ordered_names_raw]\n",
    "print(\"sample rows:\", len(ordered_names), \"name_col:\", name_col)\n",
    "\n",
    "# 建 test 索引（只 glob 一次，避免重复）\n",
    "test_files = sorted(list(X_TEST_DIR.rglob(\"*.npy\")))\n",
    "test_index = {p.stem: p for p in test_files}\n",
    "test_index.update({p.stem.lower(): p for p in test_files})\n",
    "\n",
    "# 加载 best\n",
    "model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"loaded best:\", best_path)\n",
    "\n",
    "# 清空旧预测（避免混入残留）\n",
    "for p in pred_dir.glob(\"*.npy\"):\n",
    "    p.unlink()\n",
    "\n",
    "def pad_x_to_288(x: np.ndarray) -> np.ndarray:\n",
    "    h, w = x.shape\n",
    "    out = np.zeros((h, W_PAD), dtype=np.float32)\n",
    "    out[:, :w] = x\n",
    "    return out\n",
    "\n",
    "# 推理（按样例 972 个）\n",
    "with torch.no_grad():\n",
    "    for name in ordered_names:\n",
    "        key = name if name in test_index else name.lower()\n",
    "        if key not in test_index:\n",
    "            hits = list(X_TEST_DIR.rglob(f\"{name}.npy\"))\n",
    "            if len(hits) == 0:\n",
    "                raise FileNotFoundError(f\"X_test 中找不到：{name}.npy\")\n",
    "            x_path = hits[0]\n",
    "        else:\n",
    "            x_path = test_index[key]\n",
    "\n",
    "        x = load_x(x_path)\n",
    "        w = x.shape[1]\n",
    "        x_pad = pad_x_to_288(x)\n",
    "        x_t = torch.from_numpy(x_pad).unsqueeze(0).to(DEVICE)   # (1,160,288)\n",
    "        x_t = x_t.repeat(3,1,1)                                 # (3,160,288)\n",
    "        x_t = x_t.unsqueeze(0)                                  # (1,3,160,288)\n",
    "\n",
    "\n",
    "        logits = model(pixel_values=x_t).logits  # (1,C,160,288)\n",
    "        pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)  # (160,288)\n",
    "\n",
    "        # 裁回原宽（160 或 272）\n",
    "        pred = pred[:, :w]\n",
    "        np.save(pred_dir / f\"{name}.npy\", pred)\n",
    "\n",
    "print(\"saved npy predictions to:\", pred_dir)\n",
    "\n",
    "# 生成 submission（完全匹配样例结构）\n",
    "size_labels = 272\n",
    "flat_len = 160 * size_labels\n",
    "pred_map = {}\n",
    "\n",
    "for p in pred_dir.glob(\"*.npy\"):\n",
    "    name = p.stem\n",
    "    prediction = np.load(p)\n",
    "    if prediction.shape[1] != size_labels:\n",
    "        aux = -1 + np.zeros(flat_len, dtype=np.int64)\n",
    "        aux[0:160*160] = prediction.flatten()\n",
    "    else:\n",
    "        aux = prediction.flatten().astype(np.int64)\n",
    "    pred_map[name] = aux\n",
    "\n",
    "missing = [n for n in ordered_names if n not in pred_map]\n",
    "assert len(missing) == 0, f\"仍缺预测：{missing[:5]}\"\n",
    "\n",
    "data = np.stack([pred_map[n] for n in ordered_names], axis=0)  # (972, 43520)\n",
    "col_names = [str(i) for i in range(flat_len)]\n",
    "sub_df = pd.DataFrame(data, columns=col_names)\n",
    "sub_df.insert(0, name_col, ordered_names_raw)\n",
    "\n",
    "out_csv = OUT_DIR / \"y_test_submission_MATCH_SAMPLE.csv\"\n",
    "sub_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved submission:\", out_csv, \"shape:\", sub_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e288d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
