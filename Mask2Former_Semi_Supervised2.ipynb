{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fca60f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\anaconda3\\envs\\deep-torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda | AMP: True\n",
      "Labeled train dir: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\X_train_uDRk9z9\\images\n",
      "Unlabeled dir:     C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\X_unlabeled_mtkxUlo\\images\n",
      "Test dir:          C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\X_test_xNbnvIa\\images\n",
      "Pretrained:        facebook/mask2former-swin-tiny-ade-semantic\n",
      "EPOCHS=5, pseudo_update_every=2, unlab_ratio=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "c:\\Users\\lenovo\\anaconda3\\envs\\deep-torch\\lib\\site-packages\\transformers\\image_processing_base.py:417: UserWarning: The following named arguments are not valid for `Mask2FormerImageProcessor.__init__` and were ignored: '_max_size', 'reduce_labels'\n",
      "  image_processor = cls(**image_processor_dict)\n",
      "Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-tiny-ade-semantic and are newly initialized because the shapes did not match:\n",
      "- class_predictor.bias: found shape torch.Size([151]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- class_predictor.weight: found shape torch.Size([151, 256]) in the checkpoint and torch.Size([4, 256]) in the model instantiated\n",
      "- criterion.empty_weight: found shape torch.Size([151]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled train: 2790 | Val: 1620 | Unlabeled used: 990\n",
      "\n",
      "Epoch 01/5 | lambda_u=0.050 | tau=0.95\n",
      "[Info] Building pseudo-label cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_24600\\1117854030.py:375: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=AMP):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Pseudo cache size: 990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_24600\\1117854030.py:408: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=AMP)\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_24600\\1117854030.py:441: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=AMP):\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_24600\\1117854030.py:483: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=AMP):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loss] train=20.0172 | val(well6)=14.3855\n",
      "[OK] Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_mask2former_semi.pth\n",
      "\n",
      "Epoch 02/5 | lambda_u=0.163 | tau=0.92\n",
      "[Loss] train=18.9800 | val(well6)=14.1031\n",
      "[OK] Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_mask2former_semi.pth\n",
      "\n",
      "Epoch 03/5 | lambda_u=0.275 | tau=0.90\n",
      "[Info] Building pseudo-label cache...\n",
      "[Info] Pseudo cache size: 990\n",
      "[Loss] train=19.6246 | val(well6)=15.1079\n",
      "\n",
      "Epoch 04/5 | lambda_u=0.388 | tau=0.88\n",
      "[Loss] train=20.9259 | val(well6)=14.5028\n",
      "\n",
      "Epoch 05/5 | lambda_u=0.500 | tau=0.85\n",
      "[Info] Building pseudo-label cache...\n",
      "[Info] Pseudo cache size: 990\n",
      "[Loss] train=21.1578 | val(well6)=14.7531\n",
      "\n",
      "[Info] Loading best model and generating submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_24600\\1117854030.py:515: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=AMP):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] submission saved to: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Mask2Former + Semi-Supervised Pseudo-Label (Full runnable, 5-epoch quick run)\n",
    "\n",
    "Data:\n",
    "- Labeled train images:   X_train_uDRk9z9/images (well1-6)\n",
    "- Unlabeled images:       X_unlabeled_mtkxUlo/images (well12-14)\n",
    "- Test images:            X_test_xNbnvIa/images  (well7-11)\n",
    "- Train labels (CSV):     Y_train_T9NrBYo.csv  (flattened + -1 padding)\n",
    "\n",
    "Split (avoid leakage by well):\n",
    "- Train: well1-5\n",
    "- Val:   well6\n",
    "- Test:  well7-11 (submission only)\n",
    "\n",
    "Output:\n",
    "- submission.csv (one row per patch name, flattened, padded to 160*272 with -1)\n",
    "\n",
    "Notes:\n",
    "- Model input uses 224x224 (Mask2Former pretrained backbone-friendly).\n",
    "- Images are single-channel; we repeat channel to 3.\n",
    "- Semi-supervised from epoch 1: supervised + lambda_u * unsup_loss\n",
    "- Pseudo labels are filtered by pixel confidence threshold tau.\n",
    "\n",
    "Install (in your env):\n",
    "    pip install -U transformers accelerate\n",
    "    # if transformers complains about huggingface-hub:\n",
    "    # pip install \"huggingface-hub<1.0,>=0.34.0\"\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) Paths\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lenovo\\Desktop\\deep_datachallenge\")\n",
    "\n",
    "TRAIN_IMAGES_DIR = DATA_ROOT / \"X_train_uDRk9z9\" / \"images\"\n",
    "UNLAB_IMAGES_DIR = DATA_ROOT / \"X_unlabeled_mtkxUlo\" / \"images\"\n",
    "TEST_IMAGES_DIR  = DATA_ROOT / \"X_test_xNbnvIa\" / \"images\"\n",
    "Y_TRAIN_CSV      = DATA_ROOT / \"Y_train_T9NrBYo.csv\"\n",
    "\n",
    "# Submission target size\n",
    "TARGET_H, TARGET_W = 160, 272\n",
    "IGNORE_INDEX = -1\n",
    "NUM_CLASSES = 3  # classes are 0/1/2\n",
    "\n",
    "# Model input size\n",
    "MODEL_H, MODEL_W = 224, 224\n",
    "\n",
    "# Pretrained checkpoint (semantic)\n",
    "PRETRAINED = \"facebook/mask2former-swin-tiny-ade-semantic\"\n",
    "\n",
    "# =========================\n",
    "# 1) Hyperparameters (5-epoch quick run)\n",
    "# =========================\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE_L = 2       # labeled batch size\n",
    "BATCH_SIZE_U = 2       # unlabeled batch size (keep small)\n",
    "LR = 5e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Semi-supervised schedule (start from epoch 1)\n",
    "LAMBDA_U_MIN = 0.05\n",
    "LAMBDA_U_MAX = 0.50\n",
    "RAMP_EPOCHS = 5\n",
    "\n",
    "# Pseudo label threshold schedule\n",
    "PSEUDO_TH_START = 0.95\n",
    "PSEUDO_TH_END   = 0.85\n",
    "\n",
    "# Cache pseudo labels and refresh every N epochs\n",
    "PSEUDO_UPDATE_EVERY = 2\n",
    "\n",
    "# Unlabeled sampling ratio (0~1): use a subset of unlabeled per epoch for speed\n",
    "UNLAB_SAMPLE_RATIO = 0.50\n",
    "\n",
    "# Speed\n",
    "NUM_WORKERS = 0  # set to 2~4 if your Windows setup is stable\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "AMP = (DEVICE == \"cuda\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Utils\n",
    "# =========================\n",
    "def parse_well_id(name: str) -> int:\n",
    "    m = re.search(r\"well_(\\d+)_\", name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def minmax_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    x_min = float(x.min())\n",
    "    x_max = float(x.max())\n",
    "    if x_max - x_min < 1e-6:\n",
    "        return np.zeros_like(x, dtype=np.float32)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "\n",
    "def pad_to_160x272(img: np.ndarray, fill_value: float = 0.0) -> np.ndarray:\n",
    "    h, w = img.shape\n",
    "    assert h == TARGET_H, f\"Expected height {TARGET_H}, got {h}\"\n",
    "    if w == TARGET_W:\n",
    "        return img\n",
    "    if w < TARGET_W:\n",
    "        out = np.full((TARGET_H, TARGET_W), fill_value, dtype=img.dtype)\n",
    "        out[:, :w] = img\n",
    "        return out\n",
    "    return img[:, :TARGET_W]\n",
    "\n",
    "\n",
    "def decode_mask_from_csv_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    valid = row_values[row_values != IGNORE_INDEX]\n",
    "    assert len(valid) % TARGET_H == 0, f\"Valid mask length {len(valid)} not divisible by {TARGET_H}\"\n",
    "    w = len(valid) // TARGET_H\n",
    "    return valid.reshape(TARGET_H, w).astype(np.int64)\n",
    "\n",
    "\n",
    "def pad_mask_to_160x272(mask: np.ndarray) -> np.ndarray:\n",
    "    h, w = mask.shape\n",
    "    assert h == TARGET_H\n",
    "    if w == TARGET_W:\n",
    "        return mask\n",
    "    out = np.full((TARGET_H, TARGET_W), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n",
    "\n",
    "\n",
    "def resize_image_torch(img_1hw: torch.Tensor, h: int, w: int) -> torch.Tensor:\n",
    "    x = img_1hw.unsqueeze(0)  # (1,1,H,W)\n",
    "    x = F.interpolate(x, size=(h, w), mode=\"bilinear\", align_corners=False)\n",
    "    return x.squeeze(0)       # (1,h,w)\n",
    "\n",
    "\n",
    "def resize_mask_torch(mask_hw: torch.Tensor, h: int, w: int) -> torch.Tensor:\n",
    "    y = mask_hw.unsqueeze(0).unsqueeze(0).float()\n",
    "    y = F.interpolate(y, size=(h, w), mode=\"nearest\")\n",
    "    return y.squeeze(0).squeeze(0).long()\n",
    "\n",
    "\n",
    "def semantic_to_mask2former_targets(\n",
    "    semantic_mask: torch.Tensor,\n",
    "    num_classes: int,\n",
    "    ignore_index: int = -1,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Convert semantic (H,W) to set-based:\n",
    "    - class_labels: (N,)\n",
    "    - mask_labels:  (N,H,W) float 0/1\n",
    "    Ignore pixels == ignore_index.\n",
    "    \"\"\"\n",
    "    valid = semantic_mask != ignore_index\n",
    "    if valid.sum() == 0:\n",
    "        class_labels = torch.tensor([0], dtype=torch.long)\n",
    "        mask_labels = torch.zeros((1, semantic_mask.shape[0], semantic_mask.shape[1]), dtype=torch.float32)\n",
    "        return class_labels, mask_labels\n",
    "\n",
    "    present = torch.unique(semantic_mask[valid]).tolist()\n",
    "    present = [int(c) for c in present if 0 <= int(c) < num_classes]\n",
    "    if len(present) == 0:\n",
    "        class_labels = torch.tensor([0], dtype=torch.long)\n",
    "        mask_labels = torch.zeros((1, semantic_mask.shape[0], semantic_mask.shape[1]), dtype=torch.float32)\n",
    "        return class_labels, mask_labels\n",
    "\n",
    "    masks, classes = [], []\n",
    "    for c in present:\n",
    "        m = (semantic_mask == c) & valid\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        masks.append(m.float())\n",
    "        classes.append(c)\n",
    "\n",
    "    if len(classes) == 0:\n",
    "        class_labels = torch.tensor([0], dtype=torch.long)\n",
    "        mask_labels = torch.zeros((1, semantic_mask.shape[0], semantic_mask.shape[1]), dtype=torch.float32)\n",
    "        return class_labels, mask_labels\n",
    "\n",
    "    class_labels = torch.tensor(classes, dtype=torch.long)\n",
    "    mask_labels = torch.stack(masks, dim=0).float()\n",
    "    return class_labels, mask_labels\n",
    "\n",
    "\n",
    "def get_lambda_u(epoch: int) -> float:\n",
    "    if RAMP_EPOCHS <= 1:\n",
    "        return LAMBDA_U_MAX\n",
    "    t = (epoch - 1) / (RAMP_EPOCHS - 1)\n",
    "    t = max(0.0, min(1.0, t))\n",
    "    return LAMBDA_U_MIN + (LAMBDA_U_MAX - LAMBDA_U_MIN) * t\n",
    "\n",
    "\n",
    "def get_pseudo_th(epoch: int) -> float:\n",
    "    if EPOCHS <= 1:\n",
    "        return PSEUDO_TH_END\n",
    "    t = (epoch - 1) / (EPOCHS - 1)\n",
    "    t = max(0.0, min(1.0, t))\n",
    "    return PSEUDO_TH_START + (PSEUDO_TH_END - PSEUDO_TH_START) * t\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Datasets\n",
    "# =========================\n",
    "class LabeledWellDataset(Dataset):\n",
    "    def __init__(self, images_dir: Path, y_csv_path: Path):\n",
    "        self.image_paths = sorted(images_dir.glob(\"*.npy\"))\n",
    "        self.names = [p.stem for p in self.image_paths]\n",
    "        self.y_df = pd.read_csv(y_csv_path, index_col=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        name = self.names[idx]\n",
    "        img = np.load(self.image_paths[idx])  # (160,160) or (160,272)\n",
    "        raw_w = int(img.shape[1])\n",
    "\n",
    "        img = minmax_normalize(img)\n",
    "        img = pad_to_160x272(img, fill_value=0.0)\n",
    "\n",
    "        img_t = torch.from_numpy(img).unsqueeze(0).float()         # (1,160,272)\n",
    "        img_t = resize_image_torch(img_t, MODEL_H, MODEL_W)        # (1,224,224)\n",
    "\n",
    "        row = self.y_df.loc[name].values.astype(np.int64)\n",
    "        mask = decode_mask_from_csv_row(row)                       # (160,w)\n",
    "        mask = pad_mask_to_160x272(mask)                           # (160,272)\n",
    "        mask_t = torch.from_numpy(mask).long()                     # (160,272)\n",
    "        mask_t = resize_mask_torch(mask_t, MODEL_H, MODEL_W)       # (224,224)\n",
    "\n",
    "        return {\"name\": name, \"image\": img_t, \"mask\": mask_t, \"raw_w\": raw_w}\n",
    "\n",
    "\n",
    "class UnlabeledWellDataset(Dataset):\n",
    "    def __init__(self, images_dir: Path):\n",
    "        self.image_paths = sorted(images_dir.glob(\"*.npy\"))\n",
    "        self.names = [p.stem for p in self.image_paths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        name = self.names[idx]\n",
    "        img = np.load(self.image_paths[idx])\n",
    "        raw_w = int(img.shape[1])\n",
    "\n",
    "        img = minmax_normalize(img)\n",
    "        img = pad_to_160x272(img, fill_value=0.0)\n",
    "\n",
    "        img_t = torch.from_numpy(img).unsqueeze(0).float()         # (1,160,272)\n",
    "        img_t = resize_image_torch(img_t, MODEL_H, MODEL_W)        # (1,224,224)\n",
    "\n",
    "        return {\"name\": name, \"image\": img_t, \"raw_w\": raw_w, \"idx\": idx}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Collate\n",
    "# =========================\n",
    "def collate_labeled(batch: List[Dict]) -> Dict:\n",
    "    names = [b[\"name\"] for b in batch]\n",
    "    raw_ws = torch.tensor([b[\"raw_w\"] for b in batch], dtype=torch.long)\n",
    "\n",
    "    imgs_1 = torch.stack([b[\"image\"] for b in batch], dim=0)   # (B,1,224,224)\n",
    "    pixel_values = imgs_1.repeat(1, 3, 1, 1)                   # (B,3,224,224)\n",
    "    pixel_mask = torch.ones((pixel_values.shape[0], MODEL_H, MODEL_W), dtype=torch.long)\n",
    "\n",
    "    class_labels_list, mask_labels_list = [], []\n",
    "    for b in batch:\n",
    "        cls, msk = semantic_to_mask2former_targets(b[\"mask\"], NUM_CLASSES, IGNORE_INDEX)\n",
    "        class_labels_list.append(cls)\n",
    "        mask_labels_list.append(msk)\n",
    "\n",
    "    return {\n",
    "        \"names\": names,\n",
    "        \"raw_ws\": raw_ws,\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"pixel_mask\": pixel_mask,\n",
    "        \"class_labels\": class_labels_list,\n",
    "        \"mask_labels\": mask_labels_list,\n",
    "    }\n",
    "\n",
    "\n",
    "def collate_unlabeled(batch: List[Dict]) -> Dict:\n",
    "    names = [b[\"name\"] for b in batch]\n",
    "    raw_ws = torch.tensor([b[\"raw_w\"] for b in batch], dtype=torch.long)\n",
    "    idxs = torch.tensor([b[\"idx\"] for b in batch], dtype=torch.long)\n",
    "\n",
    "    imgs_1 = torch.stack([b[\"image\"] for b in batch], dim=0)\n",
    "    pixel_values = imgs_1.repeat(1, 3, 1, 1)\n",
    "    pixel_mask = torch.ones((pixel_values.shape[0], MODEL_H, MODEL_W), dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        \"names\": names,\n",
    "        \"raw_ws\": raw_ws,\n",
    "        \"idxs\": idxs,\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"pixel_mask\": pixel_mask,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Build model & processor\n",
    "# =========================\n",
    "def build_model_and_processor() -> Tuple[Mask2FormerForUniversalSegmentation, AutoImageProcessor]:\n",
    "    id2label = {0: \"class0\", 1: \"class1\", 2: \"class2\"}\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "    processor = AutoImageProcessor.from_pretrained(PRETRAINED)\n",
    "\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\n",
    "        PRETRAINED,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        num_labels=NUM_CLASSES,\n",
    "        use_safetensors=True,  # safer + avoids torch.load restrictions\n",
    "    )\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) Pseudo label from Mask2Former outputs\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def outputs_to_semantic_and_conf(outputs) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    From Mask2Former outputs -> semantic label map + confidence map (both HxW, H=W=224).\n",
    "    Using:\n",
    "      class_probs: softmax over (num_classes + no-object), drop last\n",
    "      mask_probs:  sigmoid\n",
    "      per-pixel per-class score = sum_q class_probs[q,c] * mask_probs[q, y, x]\n",
    "    \"\"\"\n",
    "    class_logits = outputs.class_queries_logits[0]  # (Q, C+1)\n",
    "    mask_logits  = outputs.masks_queries_logits[0]  # (Q, H, W)\n",
    "\n",
    "    class_probs = F.softmax(class_logits, dim=-1)[..., :NUM_CLASSES]  # (Q, C)\n",
    "    mask_probs  = torch.sigmoid(mask_logits)                          # (Q, H, W)\n",
    "\n",
    "    # score: (C, H, W)\n",
    "    score = torch.einsum(\"qc,qhw->chw\", class_probs, mask_probs)\n",
    "\n",
    "    conf, pred = torch.max(score, dim=0)  # (H,W), (H,W)\n",
    "    return pred.to(torch.int64), conf.to(torch.float32)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def build_pseudo_cache(\n",
    "    model: torch.nn.Module,\n",
    "    unlab_loader: DataLoader,\n",
    "    tau: float,\n",
    ") -> Dict[int, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Create a cache: {unlabeled_idx -> pseudo_mask(H,W) int64}, with low-confidence pixels set to IGNORE_INDEX.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    cache: Dict[int, torch.Tensor] = {}\n",
    "\n",
    "    for batch in unlab_loader:\n",
    "        pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
    "        pixel_mask = batch[\"pixel_mask\"].to(DEVICE)\n",
    "        idxs = batch[\"idxs\"].tolist()\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=AMP):\n",
    "            outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "        # process each sample in batch\n",
    "        for b_i, u_idx in enumerate(idxs):\n",
    "            # take sample b_i outputs by slicing\n",
    "            out_i = type(outputs)(\n",
    "                **{k: (v[b_i:b_i+1] if torch.is_tensor(v) else v) for k, v in outputs.items()}\n",
    "            )\n",
    "\n",
    "            pred, conf = outputs_to_semantic_and_conf(out_i)\n",
    "            pseudo = pred.clone()\n",
    "            pseudo[conf < tau] = IGNORE_INDEX\n",
    "            cache[u_idx] = pseudo.cpu()\n",
    "\n",
    "    return cache\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7) Train / Eval\n",
    "# =========================\n",
    "def train_one_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    labeled_loader: DataLoader,\n",
    "    unlabeled_loader: DataLoader,\n",
    "    pseudo_cache: Dict[int, torch.Tensor],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    lambda_u: float,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_seen = 0\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=AMP)\n",
    "\n",
    "    # iterate by min length (simple)\n",
    "    it_u = iter(unlabeled_loader)\n",
    "    for batch_l in labeled_loader:\n",
    "        try:\n",
    "            batch_u = next(it_u)\n",
    "        except StopIteration:\n",
    "            it_u = iter(unlabeled_loader)\n",
    "            batch_u = next(it_u)\n",
    "\n",
    "        # ----- labeled -----\n",
    "        pv_l = batch_l[\"pixel_values\"].to(DEVICE)\n",
    "        pm_l = batch_l[\"pixel_mask\"].to(DEVICE)\n",
    "        cls_l = [x.to(DEVICE) for x in batch_l[\"class_labels\"]]\n",
    "        msk_l = [x.to(DEVICE) for x in batch_l[\"mask_labels\"]]\n",
    "\n",
    "        # ----- unlabeled -----\n",
    "        pv_u = batch_u[\"pixel_values\"].to(DEVICE)\n",
    "        pm_u = batch_u[\"pixel_mask\"].to(DEVICE)\n",
    "        idxs_u = batch_u[\"idxs\"].tolist()\n",
    "\n",
    "        # build pseudo targets for this unlabeled batch from cache\n",
    "        class_labels_u, mask_labels_u = [], []\n",
    "        for u_idx in idxs_u:\n",
    "            pseudo = pseudo_cache[u_idx]  # (224,224) on CPU\n",
    "            pseudo_t = pseudo.to(torch.int64)\n",
    "            cls, msk = semantic_to_mask2former_targets(pseudo_t, NUM_CLASSES, IGNORE_INDEX)\n",
    "            class_labels_u.append(cls.to(DEVICE))\n",
    "            mask_labels_u.append(msk.to(DEVICE))\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=AMP):\n",
    "            out_l = model(\n",
    "                pixel_values=pv_l,\n",
    "                pixel_mask=pm_l,\n",
    "                class_labels=cls_l,\n",
    "                mask_labels=msk_l,\n",
    "            )\n",
    "            loss_sup = out_l.loss\n",
    "\n",
    "            out_u = model(\n",
    "                pixel_values=pv_u,\n",
    "                pixel_mask=pm_u,\n",
    "                class_labels=class_labels_u,\n",
    "                mask_labels=mask_labels_u,\n",
    "            )\n",
    "            loss_unsup = out_u.loss\n",
    "\n",
    "            loss = loss_sup + lambda_u * loss_unsup\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = pv_l.size(0)\n",
    "        total_loss += float(loss.item()) * bs\n",
    "        n_seen += bs\n",
    "\n",
    "    return total_loss / max(1, n_seen)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model: torch.nn.Module, val_loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n_seen = 0\n",
    "\n",
    "    for batch in val_loader:\n",
    "        pv = batch[\"pixel_values\"].to(DEVICE)\n",
    "        pm = batch[\"pixel_mask\"].to(DEVICE)\n",
    "        cls = [x.to(DEVICE) for x in batch[\"class_labels\"]]\n",
    "        msk = [x.to(DEVICE) for x in batch[\"mask_labels\"]]\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=AMP):\n",
    "            out = model(pixel_values=pv, pixel_mask=pm, class_labels=cls, mask_labels=msk)\n",
    "            loss = out.loss\n",
    "\n",
    "        bs = pv.size(0)\n",
    "        total_loss += float(loss.item()) * bs\n",
    "        n_seen += bs\n",
    "\n",
    "    return total_loss / max(1, n_seen)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 8) Predict & submission\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def predict_and_submit(model: torch.nn.Module, processor: AutoImageProcessor, out_csv_path: Path):\n",
    "    model.eval()\n",
    "\n",
    "    test_ds = UnlabeledWellDataset(TEST_IMAGES_DIR)  # same structure, no labels\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=1, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_unlabeled\n",
    "    )\n",
    "\n",
    "    preds_dict = {}\n",
    "\n",
    "    for batch in test_loader:\n",
    "        name = batch[\"names\"][0]\n",
    "        raw_w = int(batch[\"raw_ws\"][0].item())\n",
    "\n",
    "        pv = batch[\"pixel_values\"].to(DEVICE)\n",
    "        pm = batch[\"pixel_mask\"].to(DEVICE)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=AMP):\n",
    "            outputs = model(pixel_values=pv, pixel_mask=pm)\n",
    "\n",
    "        # semantic map at 224x224\n",
    "        pred_224, _ = outputs_to_semantic_and_conf(outputs)  # (224,224)\n",
    "\n",
    "        # upsample back to 160x272\n",
    "        pred_224_f = pred_224.unsqueeze(0).unsqueeze(0).float()\n",
    "        pred_160_272 = F.interpolate(pred_224_f, size=(TARGET_H, TARGET_W), mode=\"nearest\").squeeze(0).squeeze(0)\n",
    "        pred_160_272 = pred_160_272.cpu().numpy().astype(np.int64)\n",
    "\n",
    "        # crop to original width\n",
    "        pred = pred_160_272[:, :raw_w]\n",
    "\n",
    "        # flatten + pad -1 to 160*272\n",
    "        if raw_w < TARGET_W:\n",
    "            padded = np.full((TARGET_H * TARGET_W,), IGNORE_INDEX, dtype=np.int64)\n",
    "            padded[: TARGET_H * raw_w] = pred.flatten()\n",
    "            preds_dict[name] = padded\n",
    "        else:\n",
    "            preds_dict[name] = pred.flatten()\n",
    "\n",
    "    sub = pd.DataFrame(preds_dict, dtype=\"int64\").T\n",
    "    sub.to_csv(out_csv_path)\n",
    "    print(f\"[OK] submission saved to: {out_csv_path}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 9) Main\n",
    "# =========================\n",
    "def main():\n",
    "    print(f\"DEVICE: {DEVICE} | AMP: {AMP}\")\n",
    "    print(f\"Labeled train dir: {TRAIN_IMAGES_DIR}\")\n",
    "    print(f\"Unlabeled dir:     {UNLAB_IMAGES_DIR}\")\n",
    "    print(f\"Test dir:          {TEST_IMAGES_DIR}\")\n",
    "    print(f\"Pretrained:        {PRETRAINED}\")\n",
    "    print(f\"EPOCHS={EPOCHS}, pseudo_update_every={PSEUDO_UPDATE_EVERY}, unlab_ratio={UNLAB_SAMPLE_RATIO}\")\n",
    "\n",
    "    # ----- labeled dataset (well1-6) -----\n",
    "    labeled_all = LabeledWellDataset(TRAIN_IMAGES_DIR, Y_TRAIN_CSV)\n",
    "\n",
    "    # split: well6 as val, well1-5 as train\n",
    "    VAL_WELLS = {6}\n",
    "    tr_idx, va_idx = [], []\n",
    "    for i, name in enumerate(labeled_all.names):\n",
    "        w = parse_well_id(name)\n",
    "        if w in VAL_WELLS:\n",
    "            va_idx.append(i)\n",
    "        else:\n",
    "            tr_idx.append(i)\n",
    "\n",
    "    train_ds = Subset(labeled_all, tr_idx)\n",
    "    val_ds   = Subset(labeled_all, va_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE_L, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, collate_fn=collate_labeled, drop_last=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE_L, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, collate_fn=collate_labeled)\n",
    "\n",
    "    # ----- unlabeled dataset (well12-14) -----\n",
    "    unlab_all = UnlabeledWellDataset(UNLAB_IMAGES_DIR)\n",
    "    n_unlab = len(unlab_all)\n",
    "    n_use = max(1, int(n_unlab * UNLAB_SAMPLE_RATIO))\n",
    "\n",
    "    # sample a fixed subset for this run (fast & reproducible)\n",
    "    rng = np.random.RandomState(42)\n",
    "    use_indices = rng.choice(n_unlab, size=n_use, replace=False).tolist()\n",
    "    unlab_ds = Subset(unlab_all, use_indices)\n",
    "\n",
    "    unlab_loader = DataLoader(unlab_ds, batch_size=BATCH_SIZE_U, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, collate_fn=collate_unlabeled, drop_last=True)\n",
    "\n",
    "    # ----- model -----\n",
    "    model, processor = build_model_and_processor()\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    print(f\"Labeled train: {len(train_ds)} | Val: {len(val_ds)} | Unlabeled used: {len(unlab_ds)}\")\n",
    "\n",
    "    best_val = 1e9\n",
    "    best_path = DATA_ROOT / \"best_mask2former_semi.pth\"\n",
    "\n",
    "    pseudo_cache: Dict[int, torch.Tensor] = {}\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        lambda_u = get_lambda_u(epoch)\n",
    "        tau = get_pseudo_th(epoch)\n",
    "        print(f\"\\nEpoch {epoch:02d}/{EPOCHS} | lambda_u={lambda_u:.3f} | tau={tau:.2f}\")\n",
    "\n",
    "        # refresh pseudo cache\n",
    "        if (epoch == 1) or ((epoch - 1) % PSEUDO_UPDATE_EVERY == 0) or (len(pseudo_cache) == 0):\n",
    "            print(\"[Info] Building pseudo-label cache...\")\n",
    "            # build cache over current unlabeled subset loader (teacher = current model)\n",
    "            pseudo_cache = build_pseudo_cache(model, unlab_loader, tau=tau)\n",
    "            print(f\"[Info] Pseudo cache size: {len(pseudo_cache)}\")\n",
    "\n",
    "        tr_loss = train_one_epoch(model, train_loader, unlab_loader, pseudo_cache, optimizer, lambda_u=lambda_u)\n",
    "        va_loss = eval_one_epoch(model, val_loader)\n",
    "\n",
    "        print(f\"[Loss] train={tr_loss:.4f} | val(well6)={va_loss:.4f}\")\n",
    "\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"[OK] Best model saved: {best_path}\")\n",
    "\n",
    "    # ----- inference -----\n",
    "    print(\"\\n[Info] Loading best model and generating submission...\")\n",
    "    state = torch.load(best_path, map_location=DEVICE, weights_only=True)\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    out_csv = DATA_ROOT / \"submission.csv\"\n",
    "    predict_and_submit(model, processor, out_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
