{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45402a1d",
   "metadata": {},
   "source": [
    "# La solution finale choisie---un modèle semi-supervisé et auto-supervisé pré-entraîné de type Segformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3376c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — Imports and Constants\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "X_TEST_DIR  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_test_xNbnvIa\")\n",
    "X_TRAIN_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_train_uDRk9z9\")\n",
    "X_UNLAB_DIR = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\X_unlabeled_mtkxUlo\")\n",
    "Y_TRAIN_CSV = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\Y_train_T9NrBYo.csv\")\n",
    "SAMPLE_SUB  = Path(r\"C:\\Users\\asus\\Desktop\\ECN\\DEEP\\DataChallenge\\data\\submission_csv_file_random_example_3qPSCtv.csv\")\n",
    "\n",
    "# ====== Outputs ======\n",
    "OUT_DIR = Path(r\"exp_outputs\\Exp04_SSL_SegFormer_Semi\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SSL_DIR  = OUT_DIR / \"ssl_pretrain\"\n",
    "SUP_DIR  = OUT_DIR / \"supervised_finetune\"\n",
    "SEMI_DIR = OUT_DIR / \"semi_train\"\n",
    "for d in [SSL_DIR, SUP_DIR, SEMI_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ====== constants ======\n",
    "NUM_CLASSES  = 3\n",
    "IGNORE_INDEX = 255\n",
    "H            = 160\n",
    "W_PAD        = 288  # pad to 288, later crop to 160/272\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72e517",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires de lecture et de prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db345f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — utilities: file listing (no double counting), parse name, load/pad X, load/pad Y\n",
    "NAME_RE = re.compile(r\"well_(\\d+)_section_(\\d+)_patch_(\\d+)$\")\n",
    "\n",
    "def parse_name(stem: str):\n",
    "    m = NAME_RE.match(stem)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Bad patch name: {stem}\")\n",
    "    return int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
    "\n",
    "def list_npy_files(dir_path: Path):\n",
    "    # de-dup robustly; avoids Windows *.npy/*.NPY double counting\n",
    "    files = list(dir_path.rglob(\"*.npy\")) + list(dir_path.rglob(\"*.NPY\"))\n",
    "    uniq = sorted({Path(p).resolve() for p in files})\n",
    "    return [Path(p) for p in uniq]\n",
    "\n",
    "def load_x(path: Path) -> np.ndarray:\n",
    "    x = np.load(path)\n",
    "    if x.ndim == 3 and x.shape[0] == 1:\n",
    "        x = x[0]\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx > mn:\n",
    "        x = (x - mn) / (mx - mn)\n",
    "    else:\n",
    "        x = np.zeros_like(x, dtype=np.float32)\n",
    "    return x  # (160,w)\n",
    "\n",
    "def pad_x_to_wpad(x: np.ndarray) -> np.ndarray:\n",
    "    h, w = x.shape\n",
    "    out = np.zeros((h, W_PAD), dtype=np.float32)\n",
    "    out[:, :w] = x\n",
    "    return out\n",
    "\n",
    "def make_valid_mask(w: int) -> np.ndarray:\n",
    "    valid = np.zeros((H, W_PAD), dtype=np.bool_)\n",
    "    valid[:, :w] = True\n",
    "    return valid\n",
    "\n",
    "y_df = pd.read_csv(Y_TRAIN_CSV, index_col=0)\n",
    "\n",
    "def restore_mask_from_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    vals = row_values[row_values != -1]\n",
    "    return vals.reshape(H, -1).astype(np.int64)  # (160,160) or (160,272)\n",
    "\n",
    "def pad_mask_to_wpad(mask: np.ndarray, w: int) -> np.ndarray:\n",
    "    out = np.full((H, W_PAD), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train(all images): 4410\n",
      "train(labeled):    4410\n",
      "unlabeled:         1980\n",
      "SSL pool:          6390\n",
      "test:              972\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — build manifests (train/unlab/test) + SSL pool \n",
    "def build_manifest(x_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for p in list_npy_files(x_dir):\n",
    "        stem = p.stem\n",
    "        try:\n",
    "            well, section, patch = parse_name(stem)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        arr = np.load(p, mmap_mode=\"r\")\n",
    "        if arr.ndim == 3 and arr.shape[0] == 1:\n",
    "            w = int(arr.shape[2])\n",
    "        elif arr.ndim == 2:\n",
    "            w = int(arr.shape[1])\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected shape {arr.shape} for {p}\")\n",
    "        rows.append({\"name\": stem, \"well\": well, \"section\": section, \"patch\": patch, \"w\": w, \"path\": str(p)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_df = build_manifest(X_TRAIN_DIR)\n",
    "unlab_df = build_manifest(X_UNLAB_DIR)\n",
    "test_df  = build_manifest(X_TEST_DIR)\n",
    "\n",
    "# labeled train only\n",
    "train_labeled_df = train_df[train_df[\"name\"].isin(y_df.index)].reset_index(drop=True)\n",
    "\n",
    "# SSL uses: all train images (even if labeled) + unlabeled\n",
    "ssl_df = pd.concat([train_df, unlab_df], axis=0, ignore_index=True)\n",
    "ssl_df = ssl_df.drop_duplicates(subset=[\"path\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"train(all images):\", len(train_df))\n",
    "print(\"train(labeled):   \", len(train_labeled_df))\n",
    "print(\"unlabeled:        \", len(unlab_df))\n",
    "print(\"SSL pool:         \", len(ssl_df))\n",
    "print(\"test:             \", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc23ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl batch: torch.Size([32, 1, 160, 288])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — SSL augmentations (SimSiam): two random views from same image\n",
    "def ssl_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (B,1,H,W_PAD) in [0,1]\n",
    "    B, _, Hh, Ww = x.shape\n",
    "\n",
    "    # intensity jitter\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.85, 1.15)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.08, 0.08)\n",
    "    out = torch.clamp(x * a + b, 0.0, 1.0)\n",
    "\n",
    "    # noise\n",
    "    sigma = torch.empty((B,1,1,1), device=x.device).uniform_(0.0, 0.06)\n",
    "    out = torch.clamp(out + torch.randn_like(out) * sigma, 0.0, 1.0)\n",
    "\n",
    "    # random horizontal flip\n",
    "    if torch.rand(()) < 0.5:\n",
    "        out = torch.flip(out, dims=[3])\n",
    "\n",
    "    # cutout\n",
    "    for i in range(B):\n",
    "        if torch.rand((), device=x.device).item() < 0.5:\n",
    "            ch = int(torch.randint(low=10, high=50, size=(1,), device=x.device).item())\n",
    "            cw = int(torch.randint(low=10, high=80, size=(1,), device=x.device).item())\n",
    "            y0 = int(torch.randint(low=0, high=Hh-ch+1, size=(1,), device=x.device).item())\n",
    "            x0 = int(torch.randint(low=0, high=Ww-cw+1, size=(1,), device=x.device).item())\n",
    "            out[i, :, y0:y0+ch, x0:x0+cw] = 0.0\n",
    "\n",
    "    return out\n",
    "\n",
    "class SSLDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        x = load_x(Path(row[\"path\"]))      # (160,w)\n",
    "        x = pad_x_to_wpad(x)               # (160,288)\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)  # (1,160,288)\n",
    "        # return raw tensor; augment will be done on GPU in training step for speed\n",
    "        return x_t\n",
    "\n",
    "ssl_loader = DataLoader(SSLDataset(ssl_df), batch_size=32, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "xb = next(iter(ssl_loader))\n",
    "print(\"ssl batch:\", xb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e761e",
   "metadata": {},
   "source": [
    "## Définition du modèle auto-supervisé (architecture de base SimSiam + SegFormer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ffff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimSiam backbone last hidden: 512\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — SimSiam with SegFormer backbone\n",
    "from transformers import SegformerModel\n",
    "\n",
    "BACKBONE = \"nvidia/segformer-b2-finetuned-ade-512-512\"\n",
    "\n",
    "def global_pool(feat: torch.Tensor) -> torch.Tensor:\n",
    "    # feat: (B,C,H,W) -> (B,C)\n",
    "    return feat.mean(dim=(2,3))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "            nn.BatchNorm1d(out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimSiamSegFormer(nn.Module):\n",
    "    def __init__(self, backbone_name: str, proj_dim=256, pred_dim=256, hidden=1024):\n",
    "        super().__init__()\n",
    "        self.backbone = SegformerModel.from_pretrained(backbone_name)\n",
    "        # infer feature dim: segformer config has hidden_sizes per stage; last stage is strongest\n",
    "        feat_dim = self.backbone.config.hidden_sizes[-1]\n",
    "        self.projector = MLP(feat_dim, hidden, proj_dim)\n",
    "        self.predictor = Predictor(proj_dim, hidden//2, pred_dim)\n",
    "\n",
    "    def encode(self, x3):\n",
    "        # x3: (B,3,160,288)\n",
    "        out = self.backbone(pixel_values=x3, output_hidden_states=True)\n",
    "        # last stage feature map is hidden_states[-1] with shape (B,C,H',W')\n",
    "        feat = out.hidden_states[-1]\n",
    "        v = global_pool(feat)\n",
    "        z = self.projector(v)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.encode(x1)\n",
    "        z2 = self.encode(x2)\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        return p1, p2, z1.detach(), z2.detach()\n",
    "\n",
    "def neg_cos(p, z):\n",
    "    p = F.normalize(p, dim=1)\n",
    "    z = F.normalize(z, dim=1)\n",
    "    return -(p * z).sum(dim=1).mean()\n",
    "\n",
    "ssl_model = SimSiamSegFormer(BACKBONE).to(DEVICE)\n",
    "print(\"SimSiam backbone last hidden:\", ssl_model.backbone.config.hidden_sizes[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805a2dd",
   "metadata": {},
   "source": [
    "## Pré-formation auto-supervisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f65c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\2460274430.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp04-SSL] ep1:   0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\2460274430.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep01/10 loss=-0.6239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep02/10 loss=-0.6491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep03/10 loss=-0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep04/10 loss=-0.6547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep05/10 loss=-0.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep06/10 loss=-0.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep07/10 loss=-0.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep08/10 loss=-0.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep09/10 loss=-0.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SSL] ep10/10 loss=-0.6435\n",
      "[Exp04-SSL] best loss: -0.6650720976887734\n",
      "saved ssl_ckpt: exp_outputs\\Exp04_SSL_SegFormer_Semi\\ssl_pretrain\\ssl_best.pt\n",
      "saved ssl_backbone: exp_outputs\\Exp04_SSL_SegFormer_Semi\\ssl_pretrain\\segformer_backbone_ssl.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 5 — SSL pretrain loop (SimSiam) -> save backbone weights\n",
    "SSL_EPOCHS = 10\n",
    "SSL_LR = 3e-4\n",
    "SSL_WD = 1e-4\n",
    "\n",
    "opt = torch.optim.AdamW(ssl_model.parameters(), lr=SSL_LR, weight_decay=SSL_WD)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "best_ssl = 1e9\n",
    "ssl_ckpt = SSL_DIR / \"ssl_best.pt\"\n",
    "ssl_backbone = SSL_DIR / \"segformer_backbone_ssl.pt\"\n",
    "\n",
    "ssl_model.train()\n",
    "for ep in range(1, SSL_EPOCHS+1):\n",
    "    loss_sum, n = 0.0, 0\n",
    "    for x in tqdm(ssl_loader, desc=f\"[Exp04-SSL] ep{ep}\", leave=False):\n",
    "        x = x.to(DEVICE)  # (B,1,160,288)\n",
    "\n",
    "        # two views on GPU\n",
    "        x1 = ssl_aug(x)\n",
    "        x2 = ssl_aug(x)\n",
    "\n",
    "        # segformer needs 3 channels\n",
    "        x1 = x1.repeat(1,3,1,1)\n",
    "        x2 = x2.repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            p1, p2, z1, z2 = ssl_model(x1, x2)\n",
    "            loss = 0.5 * (neg_cos(p1, z2) + neg_cos(p2, z1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        loss_sum += float(loss.item()) * x.size(0)\n",
    "        n += x.size(0)\n",
    "\n",
    "    ep_loss = loss_sum / max(1, n)\n",
    "    print(f\"[Exp04-SSL] ep{ep:02d}/{SSL_EPOCHS} loss={ep_loss:.4f}\")\n",
    "\n",
    "    if ep_loss < best_ssl:\n",
    "        best_ssl = ep_loss\n",
    "        torch.save({\"model\": ssl_model.state_dict()}, ssl_ckpt)\n",
    "        # save ONLY backbone weights for later init\n",
    "        torch.save(ssl_model.backbone.state_dict(), ssl_backbone)\n",
    "\n",
    "print(\"[Exp04-SSL] best loss:\", best_ssl)\n",
    "print(\"saved ssl_ckpt:\", ssl_ckpt)\n",
    "print(\"saved ssl_backbone:\", ssl_backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd673a0",
   "metadata": {},
   "source": [
    "## SegFormer à réglage fin supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df252dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1567590258.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bb_state = torch.load(ssl_backbone, map_location=DEVICE)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1567590258.py:90: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SSL backbone into model.segformer: exp_outputs\\Exp04_SSL_SegFormer_Semi\\ssl_pretrain\\segformer_backbone_ssl.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] train ep1:   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1567590258.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep01/10 train_loss=0.2335 val_mIoU=0.7810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep02/10 train_loss=0.1061 val_mIoU=0.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep03/10 train_loss=0.0971 val_mIoU=0.7858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep04/10 train_loss=0.0923 val_mIoU=0.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep05/10 train_loss=0.0888 val_mIoU=0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep06/10 train_loss=0.0859 val_mIoU=0.7979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep07/10 train_loss=0.0835 val_mIoU=0.7781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep08/10 train_loss=0.0821 val_mIoU=0.7990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] ep09/10 train_loss=0.0795 val_mIoU=0.7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Exp04-SUP] train ep10:  87%|████████▋ | 449/516 [1:10:01<3:05:30, 166.13s/it]"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Supervised finetune SegFormer (init backbone from SSL) on labeled data\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "# split by well\n",
    "VAL_WELLS = {5}\n",
    "train_split = train_labeled_df[~train_labeled_df[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "val_split   = train_labeled_df[train_labeled_df[\"well\"].isin(VAL_WELLS)].reset_index(drop=True)\n",
    "\n",
    "class LabeledDatasetSup(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, train_mode: bool, seed=123):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.train_mode = train_mode\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        name = row[\"name\"]\n",
    "        w = int(row[\"w\"])\n",
    "\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)\n",
    "\n",
    "        y_raw = restore_mask_from_row(y_df.loc[name].values)\n",
    "        y = pad_mask_to_wpad(y_raw, w=w)\n",
    "\n",
    "        if self.train_mode and self.rng.rand() < 0.5:\n",
    "            x = np.flip(x, axis=1).copy()\n",
    "            y = np.flip(y, axis=1).copy()\n",
    "\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)  # (1,160,288)\n",
    "        y_t = torch.from_numpy(y).long()        # (160,288)\n",
    "        meta = {\"name\": name, \"orig_w\": w}\n",
    "        return x_t, y_t, meta\n",
    "\n",
    "train_loader = DataLoader(LabeledDatasetSup(train_split, True), batch_size=8, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "val_loader   = DataLoader(LabeledDatasetSup(val_split,   False), batch_size=8, shuffle=False, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "# losses\n",
    "ce_weights = torch.tensor([1.0, 3.0, 4.0], dtype=torch.float32).to(DEVICE)\n",
    "ce = nn.CrossEntropyLoss(weight=ce_weights, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "def soft_dice_loss(logits, target, smooth=1.0):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    valid = (target != IGNORE_INDEX).unsqueeze(1)\n",
    "    t = target.clone()\n",
    "    t[t == IGNORE_INDEX] = 0\n",
    "    onehot = F.one_hot(t, num_classes=NUM_CLASSES).permute(0,3,1,2).float()\n",
    "    probs = probs * valid\n",
    "    onehot = onehot * valid\n",
    "    inter = (probs * onehot).sum((0,2,3))\n",
    "    denom = (probs + onehot).sum((0,2,3))\n",
    "    dice = (2*inter + smooth) / (denom + smooth)\n",
    "    return 1.0 - dice.mean()\n",
    "\n",
    "def combo_loss(logits, y, dice_w=0.5):\n",
    "    return (1-dice_w)*ce(logits, y) + dice_w*soft_dice_loss(logits, y)\n",
    "\n",
    "def upsample_logits(logits, target_hw):\n",
    "    return F.interpolate(logits, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "def mean_iou(pred, target):\n",
    "    valid = (target != IGNORE_INDEX)\n",
    "    ious = []\n",
    "    for c in range(NUM_CLASSES):\n",
    "        p = (pred == c) & valid\n",
    "        t = (target == c) & valid\n",
    "        inter = (p & t).sum().float()\n",
    "        union = (p | t).sum().float()\n",
    "        ious.append(torch.tensor(1.0, device=pred.device) if union.item()==0 else inter/union)\n",
    "    return torch.stack(ious).mean()\n",
    "\n",
    "# build model\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "# load SSL backbone\n",
    "ssl_backbone = SSL_DIR / \"segformer_backbone_ssl.pt\"\n",
    "bb_state = torch.load(ssl_backbone, map_location=DEVICE)\n",
    "model.segformer.load_state_dict(bb_state, strict=False)\n",
    "print(\"Loaded SSL backbone into model.segformer:\", ssl_backbone)\n",
    "\n",
    "# train\n",
    "SUP_EPOCHS = 10\n",
    "SUP_LR = 6e-5\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=SUP_LR, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "best_path = SUP_DIR / \"best_state_dict.pt\"\n",
    "best_miou = -1.0\n",
    "\n",
    "for ep in range(1, SUP_EPOCHS+1):\n",
    "    model.train()\n",
    "    tr_loss, n = 0.0, 0\n",
    "    for x, y, meta in tqdm(train_loader, desc=f\"[Exp04-SUP] train ep{ep}\", leave=False):\n",
    "        x = x.to(DEVICE)            # (B,1,160,288)\n",
    "        y = y.to(DEVICE)            # (B,160,288)\n",
    "        x3 = x.repeat(1,3,1,1)      # (B,3,160,288)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            loss = combo_loss(logits, y, dice_w=0.5)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        tr_loss += float(loss.item()) * x.size(0)\n",
    "        n += x.size(0)\n",
    "    tr_loss /= max(1, n)\n",
    "\n",
    "    model.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(val_loader, desc=f\"[Exp04-SUP] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            x3 = x.repeat(1,3,1,1)\n",
    "            logits = model(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1, n)\n",
    "\n",
    "    print(f\"[Exp04-SUP] ep{ep:02d}/{SUP_EPOCHS} train_loss={tr_loss:.4f} val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "\n",
    "print(\"[Exp04-SUP] BEST val mIoU:\", best_miou, \"saved:\", best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126913f",
   "metadata": {},
   "source": [
    "## Formation semi-supervisée (pseudo-étiquette d'enseignant EMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb05d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\3083726334.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sup_state = torch.load(best_path, map_location=DEVICE)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\3083726334.py:76: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp04-SEMI] train ep1 (lam_u=0.20):   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\3083726334.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep01/10 val_mIoU=0.7896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep02/10 val_mIoU=0.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep03/10 val_mIoU=0.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep04/10 val_mIoU=0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep05/10 val_mIoU=0.8034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep06/10 val_mIoU=0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep07/10 val_mIoU=0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep08/10 val_mIoU=0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep09/10 val_mIoU=0.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04-SEMI] ep10/10 val_mIoU=0.8005\n",
      "[Exp04-SEMI] BEST val mIoU: 0.8033703847063912 saved: exp_outputs\\Exp04_SSL_SegFormer_Semi\\semi\\best_state_dict.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Semi-supervised (EMA Teacher) starting from Exp04 supervised best\n",
    "# unlabeled loader (reuse unlab_df)\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        w = int(row[\"w\"])\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)\n",
    "        valid = torch.from_numpy(make_valid_mask(w))\n",
    "        return x_t, valid\n",
    "\n",
    "unlab_loader = DataLoader(UnlabeledDataset(unlab_df), batch_size=8, shuffle=True, num_workers=0, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "def weak_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B = x.size(0)\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.95, 1.05)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.03, 0.03)\n",
    "    return torch.clamp(x * a + b, 0.0, 1.0)\n",
    "\n",
    "def strong_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B, _, Hh, Ww = x.shape\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.85, 1.15)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.08, 0.08)\n",
    "    out = torch.clamp(x * a + b, 0.0, 1.0)\n",
    "    sigma = torch.empty((B,1,1,1), device=x.device).uniform_(0.0, 0.06)\n",
    "    out = torch.clamp(out + torch.randn_like(out) * sigma, 0.0, 1.0)\n",
    "    for i in range(B):\n",
    "        if torch.rand((), device=x.device).item() < 0.5:\n",
    "            ch = int(torch.randint(low=10, high=50, size=(1,), device=x.device).item())\n",
    "            cw = int(torch.randint(low=10, high=80, size=(1,), device=x.device).item())\n",
    "            y0 = int(torch.randint(low=0, high=Hh-ch+1, size=(1,), device=x.device).item())\n",
    "            x0 = int(torch.randint(low=0, high=Ww-cw+1, size=(1,), device=x.device).item())\n",
    "            out[i, :, y0:y0+ch, x0:x0+cw] = 0.0\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(teacher, student, alpha: float):\n",
    "    for t_p, s_p in zip(teacher.parameters(), student.parameters()):\n",
    "        t_p.data.mul_(alpha).add_(s_p.data, alpha=1.0 - alpha)\n",
    "    for t_b, s_b in zip(teacher.buffers(), student.buffers()):\n",
    "        t_b.copy_(s_b)\n",
    "\n",
    "def cycle(loader):\n",
    "    while True:\n",
    "        for b in loader:\n",
    "            yield b\n",
    "\n",
    "# init student/teacher from supervised best\n",
    "student = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "teacher = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "sup_state = torch.load(best_path, map_location=DEVICE)\n",
    "student.load_state_dict(sup_state)\n",
    "teacher.load_state_dict(sup_state)\n",
    "teacher.eval()\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "# unlabeled CE loss (ignore_index)\n",
    "ce_u = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
    "\n",
    "def rampup(epoch: int, ramp_epochs=5):\n",
    "    return min(1.0, float(epoch+1)/float(ramp_epochs))\n",
    "\n",
    "SEMI_EPOCHS = 10\n",
    "LR = 6e-5\n",
    "opt = torch.optim.AdamW(student.parameters(), lr=LR, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "TAU = 0.95\n",
    "EMA_ALPHA = 0.996\n",
    "LAMBDA_U = 1.0\n",
    "RAMP_E = 5\n",
    "\n",
    "semi_best = SEMI_DIR / \"best_state_dict.pt\"\n",
    "best_miou = -1.0\n",
    "\n",
    "unlab_iter = cycle(unlab_loader)\n",
    "\n",
    "for ep in range(1, SEMI_EPOCHS+1):\n",
    "    lam_u = LAMBDA_U * rampup(ep-1, RAMP_E)\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "\n",
    "    for x_l, y_l, meta in tqdm(train_loader, desc=f\"[Exp04-SEMI] train ep{ep} (lam_u={lam_u:.2f})\", leave=False):\n",
    "        x_u, valid_u = next(unlab_iter)\n",
    "\n",
    "        x_l = x_l.to(DEVICE)              # (B,1,160,288)\n",
    "        y_l = y_l.to(DEVICE)              # (B,160,288)\n",
    "        x_u = x_u.to(DEVICE)              # (B,1,160,288)\n",
    "        valid_u = valid_u.to(DEVICE)      # (B,160,288)\n",
    "\n",
    "        x_l3 = x_l.repeat(1,3,1,1)\n",
    "\n",
    "        x_u_w = weak_aug(x_u).repeat(1,3,1,1)\n",
    "        x_u_s = strong_aug(x_u).repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            # labeled\n",
    "            logits_l = student(pixel_values=x_l3).logits\n",
    "            logits_l = upsample_logits(logits_l, y_l.shape[-2:])\n",
    "            loss_l = combo_loss(logits_l, y_l, dice_w=0.5)\n",
    "\n",
    "            # teacher pseudo\n",
    "            with torch.no_grad():\n",
    "                logits_t = teacher(pixel_values=x_u_w).logits\n",
    "                logits_t = upsample_logits(logits_t, (H, W_PAD))\n",
    "                probs_t = torch.softmax(logits_t, dim=1)\n",
    "                conf, pseudo = torch.max(probs_t, dim=1)  # (B,160,288)\n",
    "                mask = (conf >= TAU) & valid_u\n",
    "                pseudo_pl = pseudo.clone()\n",
    "                pseudo_pl[~mask] = IGNORE_INDEX\n",
    "\n",
    "            # unlabeled loss\n",
    "            if lam_u > 0:\n",
    "                logits_u = student(pixel_values=x_u_s).logits\n",
    "                logits_u = upsample_logits(logits_u, (H, W_PAD))\n",
    "                loss_u = ce_u(logits_u, pseudo_pl)\n",
    "            else:\n",
    "                loss_u = torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "            loss = loss_l + lam_u * loss_u\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        ema_update(teacher, student, EMA_ALPHA)\n",
    "\n",
    "    # val\n",
    "    student.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(val_loader, desc=f\"[Exp04-SEMI] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            x3 = x.repeat(1,3,1,1)\n",
    "            logits = student(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1, n)\n",
    "    print(f\"[Exp04-SEMI] ep{ep:02d}/{SEMI_EPOCHS} val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(student.state_dict(), semi_best)\n",
    "\n",
    "print(\"[Exp04-SEMI] BEST val mIoU:\", best_miou, \"saved:\", semi_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4d336",
   "metadata": {},
   "source": [
    "## Raisonnement sur l'ensemble de tests et génération du fichier de soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample rows: 972 name_col: Unnamed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\2646445382.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(semi_best, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded semi best: exp_outputs\\Exp04_SSL_SegFormer_Semi\\semi\\best_state_dict.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved npy predictions to: exp_outputs\\Exp04_SSL_SegFormer_Semi\\test_predictions\n",
      "Saved submission: exp_outputs\\Exp04_SSL_SegFormer_Semi\\y_test_submission_MATCH_SAMPLE.csv shape: (972, 43521)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 — Predict test (by sample order) using Exp04 semi best, save npy + submission CSV\n",
    "sample = pd.read_csv(SAMPLE_SUB)\n",
    "name_col = sample.columns[0]\n",
    "ordered_names_raw = sample[name_col].astype(str).tolist()\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    if s.lower().endswith(\".npy\"):\n",
    "        s = s[:-4]\n",
    "    return s\n",
    "\n",
    "ordered_names = [norm_name(n) for n in ordered_names_raw]\n",
    "print(\"sample rows:\", len(ordered_names), \"name_col:\", name_col)\n",
    "\n",
    "test_files = list_npy_files(X_TEST_DIR)\n",
    "test_index = {p.stem: p for p in test_files}\n",
    "test_index.update({p.stem.lower(): p for p in test_files})\n",
    "\n",
    "# load best semi student\n",
    "student = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "student.load_state_dict(torch.load(semi_best, map_location=DEVICE))\n",
    "student.eval()\n",
    "print(\"Loaded Exp04 semi best:\", semi_best)\n",
    "\n",
    "pred_dir = OUT_DIR / \"test_predictions\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "for p in pred_dir.glob(\"*.npy\"):\n",
    "    p.unlink()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name in tqdm(ordered_names, desc=\"[Exp04] predict test\", leave=False):\n",
    "        key = name if name in test_index else name.lower()\n",
    "        if key not in test_index:\n",
    "            hits = list(X_TEST_DIR.rglob(f\"{name}.npy\")) + list(X_TEST_DIR.rglob(f\"{name}.NPY\"))\n",
    "            if len(hits) == 0:\n",
    "                raise FileNotFoundError(f\"X_test missing: {name}.npy\")\n",
    "            x_path = hits[0]\n",
    "        else:\n",
    "            x_path = test_index[key]\n",
    "\n",
    "        x = load_x(x_path)\n",
    "        w = x.shape[1]\n",
    "        x_pad = pad_x_to_wpad(x)\n",
    "        x_t = torch.from_numpy(x_pad).unsqueeze(0).unsqueeze(0).to(DEVICE)  # (1,1,160,288)\n",
    "        x_t = x_t.repeat(1,3,1,1)\n",
    "\n",
    "        logits = student(pixel_values=x_t).logits\n",
    "        logits = upsample_logits(logits, (H, W_PAD))\n",
    "        pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)\n",
    "        pred = pred[:, :w]\n",
    "        np.save(pred_dir / f\"{name}.npy\", pred)\n",
    "\n",
    "print(\"saved npy predictions to:\", pred_dir)\n",
    "\n",
    "# build submission CSV (exact sample format)\n",
    "size_labels = 272\n",
    "flat_len = H * size_labels\n",
    "\n",
    "pred_map = {}\n",
    "for p in pred_dir.glob(\"*.npy\"):\n",
    "    nm = p.stem\n",
    "    pred = np.load(p)\n",
    "    if pred.shape[1] != size_labels:\n",
    "        aux = -1 + np.zeros(flat_len, dtype=np.int64)\n",
    "        aux[0:H*H] = pred.flatten()\n",
    "    else:\n",
    "        aux = pred.flatten().astype(np.int64)\n",
    "    pred_map[nm] = aux\n",
    "\n",
    "missing = [n for n in ordered_names if n not in pred_map]\n",
    "assert len(missing) == 0, f\"missing predictions: {missing[:10]}\"\n",
    "\n",
    "data = np.stack([pred_map[n] for n in ordered_names], axis=0)\n",
    "col_names = [str(i) for i in range(flat_len)]\n",
    "sub_df = pd.DataFrame(data, columns=col_names)\n",
    "sub_df.insert(0, name_col, ordered_names_raw)\n",
    "\n",
    "out_csv = OUT_DIR / \"y_test_submission_MATCH_SAMPLE.csv\"\n",
    "sub_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved submission:\", out_csv, \"shape:\", sub_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ab74f",
   "metadata": {},
   "source": [
    "## Expérience semi-supervisée améliorée opt2 --Pseudo-étiquettes de contrôle de couverture + KL masqué + (phase d'inférence) TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1779857020.py:127: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sup_state = torch.load(best_path, map_location=DEVICE)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1779857020.py:142: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp04_SEMI_opt2_Q30] train ep1 (lam_u=0.05):   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1779857020.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep01: pseudo_cov=0.302  pseudo_cls_ratio=[9.8469114e-01 1.1722528e-06 1.5307704e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep01/10 val_mIoU=0.7972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep02: pseudo_cov=0.303  pseudo_cls_ratio=[0.9826055  0.         0.01739453]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep02/10 val_mIoU=0.7923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep03: pseudo_cov=0.303  pseudo_cls_ratio=[0.98382986 0.         0.01617016]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep03/10 val_mIoU=0.7948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep04: pseudo_cov=0.306  pseudo_cls_ratio=[0.9865239  0.         0.01347608]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep04/10 val_mIoU=0.7902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep05: pseudo_cov=0.307  pseudo_cls_ratio=[0.98596615 0.         0.01403393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep05/10 val_mIoU=0.7794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep06: pseudo_cov=0.312  pseudo_cls_ratio=[0.9874522  0.         0.01254772]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep06/10 val_mIoU=0.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep07: pseudo_cov=0.312  pseudo_cls_ratio=[0.98723954 0.         0.01276045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep07/10 val_mIoU=0.7966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep08: pseudo_cov=0.312  pseudo_cls_ratio=[0.9854275  0.         0.01457244]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep08/10 val_mIoU=0.7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep09: pseudo_cov=0.310  pseudo_cls_ratio=[9.8177379e-01 4.9080318e-06 1.8221341e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep09/10 val_mIoU=0.7903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep10: pseudo_cov=0.309  pseudo_cls_ratio=[9.7869164e-01 3.6085919e-06 2.1304812e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt2_Q30] ep10/10 val_mIoU=0.7970\n",
      "[Exp04_SEMI_opt2_Q30] BEST val mIoU: 0.7987618578804864 saved: exp_outputs\\Exp04_SEMI_opt2_Q30\\semi\\best_state_dict_opt2.pt\n",
      "Outputs in: exp_outputs\\Exp04_SEMI_opt2_Q30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 7b — Semi-supervised v2 (EMA + coverage-controlled pseudo labels) [NEW EXP, NEW FILE NAMES]\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EXP_NAME = \"Exp04_SEMI_opt2_Q30\"\n",
    "OUT_DIR2 = Path(rf\"exp_outputs\\{EXP_NAME}\")\n",
    "OUT_DIR2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEMI_DIR2 = OUT_DIR2 / \"semi\"\n",
    "SEMI_DIR2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- unlabeled loader ----------\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        w = int(row[\"w\"])\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)                      # (160,288)\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)    # (1,160,288)\n",
    "        valid = torch.from_numpy(make_valid_mask(w))  # (160,288) bool\n",
    "        return x_t, valid\n",
    "\n",
    "unlab_loader2 = DataLoader(\n",
    "    UnlabeledDataset(unlab_df),\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=(DEVICE==\"cuda\")\n",
    ")\n",
    "\n",
    "def cycle(loader):\n",
    "    while True:\n",
    "        for b in loader:\n",
    "            yield b\n",
    "\n",
    "# ---------- augmentations (保守版 strong aug) ----------\n",
    "def weak_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B = x.size(0)\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.97, 1.03)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.02, 0.02)\n",
    "    return torch.clamp(x * a + b, 0.0, 1.0)\n",
    "\n",
    "def strong_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B, _, Hh, Ww = x.shape\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.90, 1.10)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.05, 0.05)\n",
    "    out = torch.clamp(x * a + b, 0.0, 1.0)\n",
    "    sigma = torch.empty((B,1,1,1), device=x.device).uniform_(0.0, 0.03)\n",
    "    out = torch.clamp(out + torch.randn_like(out) * sigma, 0.0, 1.0)\n",
    "\n",
    "    # 低概率小cutout（可关掉：把0.25改成0）\n",
    "    for i in range(B):\n",
    "        if torch.rand((), device=x.device).item() < 0.25:\n",
    "            ch = int(torch.randint(low=8, high=24, size=(1,), device=x.device).item())\n",
    "            cw = int(torch.randint(low=12, high=48, size=(1,), device=x.device).item())\n",
    "            y0 = int(torch.randint(low=0, high=Hh-ch+1, size=(1,), device=x.device).item())\n",
    "            x0 = int(torch.randint(low=0, high=Ww-cw+1, size=(1,), device=x.device).item())\n",
    "            out[i, :, y0:y0+ch, x0:x0+cw] = 0.0\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(teacher, student, alpha: float):\n",
    "    for t_p, s_p in zip(teacher.parameters(), student.parameters()):\n",
    "        t_p.data.mul_(alpha).add_(s_p.data, alpha=1.0 - alpha)\n",
    "    for t_b, s_b in zip(teacher.buffers(), student.buffers()):\n",
    "        t_b.copy_(s_b)\n",
    "\n",
    "def rampup(epoch0: int, ramp_epochs: int):\n",
    "    if ramp_epochs <= 0:\n",
    "        return 1.0\n",
    "    return min(1.0, float(epoch0 + 1) / float(ramp_epochs))\n",
    "\n",
    "# ---------- pseudo-label selection (关键：限制覆盖率) ----------\n",
    "TAU_BY_CLASS = torch.tensor([0.995, 0.97, 0.96], device=DEVICE)  # base阈值\n",
    "TARGET_COVER = 0.30  # 目标覆盖率：30%（你也可以试0.20/0.40）\n",
    "TEMP = 1.0           # 关闭sharpening（避免conf虚高）\n",
    "\n",
    "def build_mask_with_target_cover(conf, pseudo, valid, target_cover: float):\n",
    "    \"\"\"\n",
    "    conf:  (B,H,W)\n",
    "    pseudo:(B,H,W)\n",
    "    valid: (B,H,W) bool\n",
    "    return: mask (B,H,W) bool\n",
    "    \"\"\"\n",
    "    # 1) class-wise base threshold\n",
    "    thr_base = TAU_BY_CLASS[pseudo]           # (B,H,W)\n",
    "    mask = (conf >= thr_base) & valid\n",
    "\n",
    "    # 2) 再做“覆盖率控制”：只保留 valid 内 top-q 的 conf\n",
    "    conf_valid = conf[valid]\n",
    "    if conf_valid.numel() == 0:\n",
    "        return mask\n",
    "\n",
    "    # 想保留 top-q => 阈值 = quantile(conf, 1-q)\n",
    "    q = 1.0 - float(target_cover)\n",
    "    q = min(max(q, 0.0), 1.0)\n",
    "    thr_q = torch.quantile(conf_valid, q)\n",
    "\n",
    "    mask = mask & (conf >= thr_q)\n",
    "    return mask\n",
    "\n",
    "def masked_kl(student_logits, teacher_probs, mask):\n",
    "    # KL( teacher || student ) on masked pixels\n",
    "    if mask.sum().item() == 0:\n",
    "        return torch.tensor(0.0, device=student_logits.device)\n",
    "    logp_s = F.log_softmax(student_logits, dim=1)                 # (B,C,H,W)\n",
    "    kl_map = F.kl_div(logp_s, teacher_probs, reduction=\"none\").sum(1)  # (B,H,W)\n",
    "    return kl_map[mask].mean()\n",
    "\n",
    "# ---------- init student/teacher from supervised best ----------\n",
    "student = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "teacher = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "sup_state = torch.load(best_path, map_location=DEVICE)\n",
    "student.load_state_dict(sup_state)\n",
    "teacher.load_state_dict(sup_state)\n",
    "teacher.eval()\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "# ---------- training hyperparams ----------\n",
    "SEMI_EPOCHS = 10\n",
    "LR = 6e-5\n",
    "EMA_ALPHA = 0.999\n",
    "LAMBDA_U  = 0.5\n",
    "RAMP_E    = 10\n",
    "\n",
    "opt = torch.optim.AdamW(student.parameters(), lr=LR, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "semi_best2 = SEMI_DIR2 / \"best_state_dict_opt2.pt\"\n",
    "best_miou2 = -1.0\n",
    "\n",
    "unlab_iter = cycle(unlab_loader2)\n",
    "\n",
    "for ep in range(1, SEMI_EPOCHS+1):\n",
    "    lam_u = LAMBDA_U * rampup(ep-1, RAMP_E)\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "\n",
    "    cov_sum, cov_n = 0.0, 0\n",
    "    cls_cnt = torch.zeros(NUM_CLASSES, device=DEVICE)\n",
    "\n",
    "    for x_l, y_l, meta in tqdm(train_loader, desc=f\"[{EXP_NAME}] train ep{ep} (lam_u={lam_u:.2f})\", leave=False):\n",
    "        x_u, valid_u = next(unlab_iter)\n",
    "\n",
    "        x_l = x_l.to(DEVICE)              # (B,1,160,288)\n",
    "        y_l = y_l.to(DEVICE)              # (B,160,288)\n",
    "        x_u = x_u.to(DEVICE)              # (B,1,160,288)\n",
    "        valid_u = valid_u.to(DEVICE)      # (B,160,288) bool\n",
    "\n",
    "        x_l3 = x_l.repeat(1,3,1,1)\n",
    "        x_u_w = weak_aug(x_u).repeat(1,3,1,1)\n",
    "        x_u_s = strong_aug(x_u).repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            # labeled loss\n",
    "            logits_l = student(pixel_values=x_l3).logits\n",
    "            logits_l = upsample_logits(logits_l, y_l.shape[-2:])\n",
    "            loss_l = combo_loss(logits_l, y_l, dice_w=0.5)\n",
    "\n",
    "            # teacher soft probs + mask\n",
    "            with torch.no_grad():\n",
    "                logits_t = teacher(pixel_values=x_u_w).logits\n",
    "                logits_t = upsample_logits(logits_t, (H, W_PAD))\n",
    "                probs_t = torch.softmax(logits_t / TEMP, dim=1)   # (B,C,H,W)\n",
    "                conf, pseudo = torch.max(probs_t, dim=1)          # (B,H,W)\n",
    "\n",
    "                mask = build_mask_with_target_cover(conf, pseudo, valid_u, TARGET_COVER)\n",
    "\n",
    "            # unlabeled loss (KL)\n",
    "            if lam_u > 0:\n",
    "                logits_u = student(pixel_values=x_u_s).logits\n",
    "                logits_u = upsample_logits(logits_u, (H, W_PAD))\n",
    "                loss_u = masked_kl(logits_u, probs_t, mask)\n",
    "            else:\n",
    "                loss_u = torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "            loss = loss_l + lam_u * loss_u\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(opt)\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), 1.0)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        ema_update(teacher, student, EMA_ALPHA)\n",
    "\n",
    "        # monitor coverage + class ratio on masked pixels\n",
    "        with torch.no_grad():\n",
    "            denom = valid_u.float().sum().clamp(min=1.0)\n",
    "            cov = (mask.float().sum() / denom).item()\n",
    "            cov_sum += cov\n",
    "            cov_n += 1\n",
    "            if mask.sum().item() > 0:\n",
    "                cls_cnt += torch.bincount(pseudo[mask], minlength=NUM_CLASSES).float()\n",
    "\n",
    "    cov_avg = cov_sum / max(1, cov_n)\n",
    "    cls_ratio = (cls_cnt / cls_cnt.sum().clamp(min=1.0)).detach().cpu().numpy()\n",
    "    print(f\"[{EXP_NAME}] ep{ep:02d}: pseudo_cov={cov_avg:.3f}  pseudo_cls_ratio={cls_ratio}\")\n",
    "\n",
    "    # val\n",
    "    student.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(val_loader, desc=f\"[{EXP_NAME}] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            x3 = x.repeat(1,3,1,1)\n",
    "            logits = student(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1, n)\n",
    "    print(f\"[{EXP_NAME}] ep{ep:02d}/{SEMI_EPOCHS} val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou2:\n",
    "        best_miou2 = val_miou\n",
    "        torch.save(student.state_dict(), semi_best2)\n",
    "\n",
    "print(f\"[{EXP_NAME}] BEST val mIoU:\", best_miou2, \"saved:\", semi_best2)\n",
    "print(\"Outputs in:\", OUT_DIR2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7a14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample rows: 972 name_col: Unnamed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\782593947.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student2.load_state_dict(torch.load(semi_best2, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: exp_outputs\\Exp04_SEMI_opt2_Q30\\semi\\best_state_dict_opt2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved npy predictions to: exp_outputs\\Exp04_SEMI_opt2_Q30\\test_predictions_opt2\n",
      "Saved submission: exp_outputs\\Exp04_SEMI_opt2_Q30\\y_test_submission_MATCH_SAMPLE_Exp04_SEMI_opt2_Q30.csv shape: (972, 43521)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8b — Predict test (sample order) + TTA + NEW submission name\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "sample = pd.read_csv(SAMPLE_SUB)\n",
    "name_col = sample.columns[0]\n",
    "ordered_names_raw = sample[name_col].astype(str).tolist()\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    if s.lower().endswith(\".npy\"):\n",
    "        s = s[:-4]\n",
    "    return s\n",
    "\n",
    "ordered_names = [norm_name(n) for n in ordered_names_raw]\n",
    "print(\"sample rows:\", len(ordered_names), \"name_col:\", name_col)\n",
    "\n",
    "test_files = list_npy_files(X_TEST_DIR)\n",
    "test_index = {p.stem: p for p in test_files}\n",
    "test_index.update({p.stem.lower(): p for p in test_files})\n",
    "\n",
    "# load best semi v2\n",
    "student2 = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "student2.load_state_dict(torch.load(semi_best2, map_location=DEVICE))\n",
    "student2.eval()\n",
    "print(\"Loaded:\", semi_best2)\n",
    "\n",
    "pred_dir2 = OUT_DIR2 / \"test_predictions_opt2\"\n",
    "pred_dir2.mkdir(parents=True, exist_ok=True)\n",
    "for p in pred_dir2.glob(\"*.npy\"):\n",
    "    p.unlink()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_logits_tta(x_pad_288: np.ndarray):\n",
    "    x_t = torch.from_numpy(x_pad_288).unsqueeze(0).unsqueeze(0).to(DEVICE)  # (1,1,160,288)\n",
    "    x3 = x_t.repeat(1,3,1,1)\n",
    "\n",
    "    logits1 = student2(pixel_values=x3).logits\n",
    "    logits1 = upsample_logits(logits1, (H, W_PAD))  # (1,C,160,288)\n",
    "\n",
    "    x3f = torch.flip(x3, dims=[3])\n",
    "    logits2 = student2(pixel_values=x3f).logits\n",
    "    logits2 = upsample_logits(logits2, (H, W_PAD))\n",
    "    logits2 = torch.flip(logits2, dims=[3])\n",
    "\n",
    "    return (0.5 * (logits1 + logits2)).squeeze(0).cpu()  # (C,160,288)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name in tqdm(ordered_names, desc=f\"[{EXP_NAME}] predict test (TTA)\", leave=False):\n",
    "        key = name if name in test_index else name.lower()\n",
    "        if key not in test_index:\n",
    "            hits = list(X_TEST_DIR.rglob(f\"{name}.npy\")) + list(X_TEST_DIR.rglob(f\"{name}.NPY\"))\n",
    "            if len(hits) == 0:\n",
    "                raise FileNotFoundError(f\"X_test missing: {name}.npy\")\n",
    "            x_path = hits[0]\n",
    "        else:\n",
    "            x_path = test_index[key]\n",
    "\n",
    "        x = load_x(x_path)          # (160,w)\n",
    "        w = x.shape[1]\n",
    "        x_pad = pad_x_to_wpad(x)    # (160,288)\n",
    "\n",
    "        logits = predict_logits_tta(x_pad)  # (C,160,288)\n",
    "        pred = torch.argmax(logits, dim=0).numpy().astype(np.int64)  # (160,288)\n",
    "        pred = pred[:, :w]\n",
    "        np.save(pred_dir2 / f\"{name}.npy\", pred)\n",
    "\n",
    "print(\"saved npy predictions to:\", pred_dir2)\n",
    "\n",
    "# ---- build submission (match sample) ----\n",
    "size_labels = 272\n",
    "flat_len = H * size_labels\n",
    "\n",
    "pred_map = {}\n",
    "for p in pred_dir2.glob(\"*.npy\"):\n",
    "    nm = p.stem\n",
    "    pred = np.load(p)  # (160,160) or (160,272)\n",
    "    if pred.shape[1] != size_labels:\n",
    "        aux = -1 + np.zeros(flat_len, dtype=np.int64)\n",
    "        aux[0:H*H] = pred.flatten()\n",
    "    else:\n",
    "        aux = pred.flatten().astype(np.int64)\n",
    "    pred_map[nm] = aux\n",
    "\n",
    "missing = [n for n in ordered_names if n not in pred_map]\n",
    "assert len(missing) == 0, f\"missing predictions: {missing[:10]}\"\n",
    "\n",
    "data = np.stack([pred_map[n] for n in ordered_names], axis=0)\n",
    "col_names = [str(i) for i in range(flat_len)]\n",
    "sub_df = pd.DataFrame(data, columns=col_names)\n",
    "sub_df.insert(0, name_col, ordered_names_raw)\n",
    "\n",
    "out_csv2 = OUT_DIR2 / f\"y_test_submission_MATCH_SAMPLE_{EXP_NAME}.csv\"\n",
    "sub_df.to_csv(out_csv2, index=False)\n",
    "print(\"Saved submission:\", out_csv2, \"shape:\", sub_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5082c08",
   "metadata": {},
   "source": [
    "## Expérience semi-supervisée améliorée opt3 -- Pseudo-étiquettes de premier plan uniquement + KL masqué + (étape d'inférence) TTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1330001677.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sup_state = torch.load(best_path, map_location=DEVICE)\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1330001677.py:133: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
      "[Exp04_SEMI_opt3_FGOnly_Q15] train ep1 (lam_u=0.10):   0%|          | 0/516 [00:00<?, ?it/s]C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\1330001677.py:161: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep01: pseudo_cov=0.026  pseudo_cls_ratio=[0.         0.01619996 0.98380005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep01/10 val_mIoU=0.7891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep02: pseudo_cov=0.026  pseudo_cls_ratio=[0.        0.0164028 0.9835972]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep02/10 val_mIoU=0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep03: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.01387506 0.98612493]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep03/10 val_mIoU=0.7870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep04: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.01628043 0.9837196 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep04/10 val_mIoU=0.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep05: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.01227641 0.9877236 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep05/10 val_mIoU=0.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep06: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.01330168 0.9866983 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep06/10 val_mIoU=0.7885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep07: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.02521074 0.97478926]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep07/10 val_mIoU=0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep08: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.03387412 0.96612585]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep08/10 val_mIoU=0.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep09: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.03421669 0.9657833 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep09/10 val_mIoU=0.7826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep10: pseudo_cov=0.027  pseudo_cls_ratio=[0.         0.05288752 0.9471125 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exp04_SEMI_opt3_FGOnly_Q15] ep10/10 val_mIoU=0.7940\n",
      "[Exp04_SEMI_opt3_FGOnly_Q15] BEST val mIoU: 0.7991736680269241 saved: exp_outputs\\Exp04_SEMI_opt3_FGOnly_Q15\\semi\\best_state_dict_opt3.pt\n",
      "Outputs in: exp_outputs\\Exp04_SEMI_opt3_FGOnly_Q15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 7c — Semi-supervised opt3: Foreground-only pseudo label (EMA Teacher) [NEW EXP]\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EXP_NAME3 = \"Exp04_SEMI_opt3_FGOnly_Q15\"\n",
    "OUT_DIR3 = Path(rf\"exp_outputs\\{EXP_NAME3}\")\n",
    "OUT_DIR3.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEMI_DIR3 = OUT_DIR3 / \"semi\"\n",
    "SEMI_DIR3.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- unlabeled loader ----------\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        w = int(row[\"w\"])\n",
    "        x = load_x(Path(row[\"path\"]))\n",
    "        x = pad_x_to_wpad(x)                      # (160,288)\n",
    "        x_t = torch.from_numpy(x).unsqueeze(0)    # (1,160,288)\n",
    "        valid = torch.from_numpy(make_valid_mask(w))  # (160,288) bool\n",
    "        return x_t, valid\n",
    "\n",
    "unlab_loader3 = DataLoader(\n",
    "    UnlabeledDataset(unlab_df),\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=(DEVICE==\"cuda\")\n",
    ")\n",
    "\n",
    "def cycle(loader):\n",
    "    while True:\n",
    "        for b in loader:\n",
    "            yield b\n",
    "\n",
    "# ---------- augmentations (保守) ----------\n",
    "def weak_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B = x.size(0)\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.97, 1.03)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.02, 0.02)\n",
    "    return torch.clamp(x * a + b, 0.0, 1.0)\n",
    "\n",
    "def strong_aug(x: torch.Tensor) -> torch.Tensor:\n",
    "    B, _, Hh, Ww = x.shape\n",
    "    a = torch.empty((B,1,1,1), device=x.device).uniform_(0.90, 1.10)\n",
    "    b = torch.empty((B,1,1,1), device=x.device).uniform_(-0.05, 0.05)\n",
    "    out = torch.clamp(x * a + b, 0.0, 1.0)\n",
    "    sigma = torch.empty((B,1,1,1), device=x.device).uniform_(0.0, 0.03)\n",
    "    out = torch.clamp(out + torch.randn_like(out) * sigma, 0.0, 1.0)\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(teacher, student, alpha: float):\n",
    "    for t_p, s_p in zip(teacher.parameters(), student.parameters()):\n",
    "        t_p.data.mul_(alpha).add_(s_p.data, alpha=1.0 - alpha)\n",
    "    for t_b, s_b in zip(teacher.buffers(), student.buffers()):\n",
    "        t_b.copy_(s_b)\n",
    "\n",
    "def rampup(epoch0: int, ramp_epochs: int):\n",
    "    if ramp_epochs <= 0:\n",
    "        return 1.0\n",
    "    return min(1.0, float(epoch0 + 1) / float(ramp_epochs))\n",
    "\n",
    "# ---------- FG-only mask builder ----------\n",
    "TAU_BY_CLASS = torch.tensor([0.999, 0.93, 0.93], device=DEVICE)  # bg阈值不用了（FG-only），类1/2阈值可以更松\n",
    "FG_TARGET_COVER = 0.15  # 只在前景里保留 top 15%（你可以试 0.10/0.20）\n",
    "TEMP = 1.0              # 不 sharpen\n",
    "\n",
    "def build_fg_mask(conf, pseudo, valid, fg_target_cover: float):\n",
    "    \"\"\"\n",
    "    只在前景 (pseudo!=0) 上选伪标签，并用 quantile 控制覆盖率\n",
    "    \"\"\"\n",
    "    fg = (pseudo != 0) & valid\n",
    "    if fg.sum().item() == 0:\n",
    "        return torch.zeros_like(fg, dtype=torch.bool)\n",
    "\n",
    "    thr_base = TAU_BY_CLASS[pseudo]             # (B,H,W)\n",
    "    mask = fg & (conf >= thr_base)\n",
    "\n",
    "    # quantile in FG only\n",
    "    conf_fg = conf[fg]\n",
    "    if conf_fg.numel() == 0:\n",
    "        return torch.zeros_like(fg, dtype=torch.bool)\n",
    "\n",
    "    q = 1.0 - float(fg_target_cover)\n",
    "    q = min(max(q, 0.0), 1.0)\n",
    "    thr_q = torch.quantile(conf_fg, q)\n",
    "    mask = mask & (conf >= thr_q)\n",
    "    return mask\n",
    "\n",
    "def masked_kl(student_logits, teacher_probs, mask, fg_weight=2.0):\n",
    "    \"\"\"\n",
    "    在mask上做KL。为了更强调前景，可以放大权重（因为mask本身就是FG-only）\n",
    "    \"\"\"\n",
    "    if mask.sum().item() == 0:\n",
    "        return torch.tensor(0.0, device=student_logits.device)\n",
    "    logp_s = F.log_softmax(student_logits, dim=1)                    # (B,C,H,W)\n",
    "    kl_map = F.kl_div(logp_s, teacher_probs, reduction=\"none\").sum(1)  # (B,H,W)\n",
    "    return fg_weight * kl_map[mask].mean()\n",
    "\n",
    "# ---------- init student/teacher from supervised best ----------\n",
    "student3 = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "teacher3 = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "\n",
    "sup_state = torch.load(best_path, map_location=DEVICE)\n",
    "student3.load_state_dict(sup_state)\n",
    "teacher3.load_state_dict(sup_state)\n",
    "teacher3.eval()\n",
    "for p in teacher3.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "# ---------- training hyperparams ----------\n",
    "SEMI_EPOCHS = 10\n",
    "LR = 6e-5\n",
    "EMA_ALPHA = 0.999\n",
    "LAMBDA_U  = 0.8      # FG-only时可以适当加大一点（因为噪声小）\n",
    "RAMP_E    = 8\n",
    "\n",
    "opt = torch.optim.AdamW(student3.parameters(), lr=LR, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "semi_best3 = SEMI_DIR3 / \"best_state_dict_opt3.pt\"\n",
    "best_miou3 = -1.0\n",
    "\n",
    "unlab_iter = cycle(unlab_loader3)\n",
    "\n",
    "for ep in range(1, SEMI_EPOCHS+1):\n",
    "    lam_u = LAMBDA_U * rampup(ep-1, RAMP_E)\n",
    "    student3.train()\n",
    "    teacher3.eval()\n",
    "\n",
    "    cov_sum, cov_n = 0.0, 0\n",
    "    cls_cnt = torch.zeros(NUM_CLASSES, device=DEVICE)\n",
    "\n",
    "    for x_l, y_l, meta in tqdm(train_loader, desc=f\"[{EXP_NAME3}] train ep{ep} (lam_u={lam_u:.2f})\", leave=False):\n",
    "        x_u, valid_u = next(unlab_iter)\n",
    "\n",
    "        x_l = x_l.to(DEVICE)\n",
    "        y_l = y_l.to(DEVICE)\n",
    "        x_u = x_u.to(DEVICE)\n",
    "        valid_u = valid_u.to(DEVICE)\n",
    "\n",
    "        x_l3 = x_l.repeat(1,3,1,1)\n",
    "        x_u_w = weak_aug(x_u).repeat(1,3,1,1)\n",
    "        x_u_s = strong_aug(x_u).repeat(1,3,1,1)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            # labeled\n",
    "            logits_l = student3(pixel_values=x_l3).logits\n",
    "            logits_l = upsample_logits(logits_l, y_l.shape[-2:])\n",
    "            loss_l = combo_loss(logits_l, y_l, dice_w=0.5)\n",
    "\n",
    "            # teacher\n",
    "            with torch.no_grad():\n",
    "                logits_t = teacher3(pixel_values=x_u_w).logits\n",
    "                logits_t = upsample_logits(logits_t, (H, W_PAD))\n",
    "                probs_t = torch.softmax(logits_t / TEMP, dim=1)\n",
    "                conf, pseudo = torch.max(probs_t, dim=1)\n",
    "\n",
    "                mask_fg = build_fg_mask(conf, pseudo, valid_u, FG_TARGET_COVER)\n",
    "\n",
    "            # unlabeled (FG-only KL)\n",
    "            if lam_u > 0:\n",
    "                logits_u = student3(pixel_values=x_u_s).logits\n",
    "                logits_u = upsample_logits(logits_u, (H, W_PAD))\n",
    "                loss_u = masked_kl(logits_u, probs_t, mask_fg, fg_weight=2.0)\n",
    "            else:\n",
    "                loss_u = torch.tensor(0.0, device=DEVICE)\n",
    "\n",
    "            loss = loss_l + lam_u * loss_u\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(opt)\n",
    "        torch.nn.utils.clip_grad_norm_(student3.parameters(), 1.0)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        ema_update(teacher3, student3, EMA_ALPHA)\n",
    "\n",
    "        # monitor\n",
    "        with torch.no_grad():\n",
    "            denom = valid_u.float().sum().clamp(min=1.0)\n",
    "            cov = (mask_fg.float().sum() / denom).item()\n",
    "            cov_sum += cov\n",
    "            cov_n += 1\n",
    "            if mask_fg.sum().item() > 0:\n",
    "                cls_cnt += torch.bincount(pseudo[mask_fg], minlength=NUM_CLASSES).float()\n",
    "\n",
    "    cov_avg = cov_sum / max(1, cov_n)\n",
    "    cls_ratio = (cls_cnt / cls_cnt.sum().clamp(min=1.0)).detach().cpu().numpy()\n",
    "    print(f\"[{EXP_NAME3}] ep{ep:02d}: pseudo_cov={cov_avg:.3f}  pseudo_cls_ratio={cls_ratio}\")\n",
    "\n",
    "    # val\n",
    "    student3.eval()\n",
    "    miou_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(val_loader, desc=f\"[{EXP_NAME3}] val ep{ep}\", leave=False):\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            x3 = x.repeat(1,3,1,1)\n",
    "            logits = student3(pixel_values=x3).logits\n",
    "            logits = upsample_logits(logits, y.shape[-2:])\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            miou_sum += float(mean_iou(pred, y).item()) * x.size(0)\n",
    "            n += x.size(0)\n",
    "    val_miou = miou_sum / max(1, n)\n",
    "    print(f\"[{EXP_NAME3}] ep{ep:02d}/{SEMI_EPOCHS} val_mIoU={val_miou:.4f}\")\n",
    "\n",
    "    if val_miou > best_miou3:\n",
    "        best_miou3 = val_miou\n",
    "        torch.save(student3.state_dict(), semi_best3)\n",
    "\n",
    "print(f\"[{EXP_NAME3}] BEST val mIoU:\", best_miou3, \"saved:\", semi_best3)\n",
    "print(\"Outputs in:\", OUT_DIR3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565fda57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample rows: 972 name_col: Unnamed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
      "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
      "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_10968\\3104168265.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student_pred.load_state_dict(torch.load(semi_best3, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: exp_outputs\\Exp04_SEMI_opt3_FGOnly_Q15\\semi\\best_state_dict_opt3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved npy predictions to: exp_outputs\\Exp04_SEMI_opt3_FGOnly_Q15\\test_predictions_opt3\n",
      "Saved submission: exp_outputs\\Exp04_SEMI_opt3_FGOnly_Q15\\y_test_submission_MATCH_SAMPLE_Exp04_SEMI_opt3_FGOnly_Q15.csv shape: (972, 43521)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8c — Predict test (sample order) + TTA + NEW submission name (opt3)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "sample = pd.read_csv(SAMPLE_SUB)\n",
    "name_col = sample.columns[0]\n",
    "ordered_names_raw = sample[name_col].astype(str).tolist()\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    if s.lower().endswith(\".npy\"):\n",
    "        s = s[:-4]\n",
    "    return s\n",
    "\n",
    "ordered_names = [norm_name(n) for n in ordered_names_raw]\n",
    "print(\"sample rows:\", len(ordered_names), \"name_col:\", name_col)\n",
    "\n",
    "test_files = list_npy_files(X_TEST_DIR)\n",
    "test_index = {p.stem: p for p in test_files}\n",
    "test_index.update({p.stem.lower(): p for p in test_files})\n",
    "\n",
    "# load best opt3\n",
    "student_pred = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    BACKBONE, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n",
    "student_pred.load_state_dict(torch.load(semi_best3, map_location=DEVICE))\n",
    "student_pred.eval()\n",
    "print(\"Loaded:\", semi_best3)\n",
    "\n",
    "pred_dir3 = OUT_DIR3 / \"test_predictions_opt3\"\n",
    "pred_dir3.mkdir(parents=True, exist_ok=True)\n",
    "for p in pred_dir3.glob(\"*.npy\"):\n",
    "    p.unlink()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_logits_tta(x_pad_288: np.ndarray):\n",
    "    x_t = torch.from_numpy(x_pad_288).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    x3 = x_t.repeat(1,3,1,1)\n",
    "\n",
    "    logits1 = student_pred(pixel_values=x3).logits\n",
    "    logits1 = upsample_logits(logits1, (H, W_PAD))\n",
    "\n",
    "    x3f = torch.flip(x3, dims=[3])\n",
    "    logits2 = student_pred(pixel_values=x3f).logits\n",
    "    logits2 = upsample_logits(logits2, (H, W_PAD))\n",
    "    logits2 = torch.flip(logits2, dims=[3])\n",
    "\n",
    "    return (0.5 * (logits1 + logits2)).squeeze(0).cpu()  # (C,160,288)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name in tqdm(ordered_names, desc=f\"[{EXP_NAME3}] predict test (TTA)\", leave=False):\n",
    "        key = name if name in test_index else name.lower()\n",
    "        if key not in test_index:\n",
    "            hits = list(X_TEST_DIR.rglob(f\"{name}.npy\")) + list(X_TEST_DIR.rglob(f\"{name}.NPY\"))\n",
    "            if len(hits) == 0:\n",
    "                raise FileNotFoundError(f\"X_test missing: {name}.npy\")\n",
    "            x_path = hits[0]\n",
    "        else:\n",
    "            x_path = test_index[key]\n",
    "\n",
    "        x = load_x(x_path)         # (160,w)\n",
    "        w = x.shape[1]\n",
    "        x_pad = pad_x_to_wpad(x)   # (160,288)\n",
    "\n",
    "        logits = predict_logits_tta(x_pad)\n",
    "        pred = torch.argmax(logits, dim=0).numpy().astype(np.int64)  # (160,288)\n",
    "        pred = pred[:, :w]\n",
    "        np.save(pred_dir3 / f\"{name}.npy\", pred)\n",
    "\n",
    "print(\"saved npy predictions to:\", pred_dir3)\n",
    "\n",
    "# build submission\n",
    "size_labels = 272\n",
    "flat_len = H * size_labels\n",
    "\n",
    "pred_map = {}\n",
    "for p in pred_dir3.glob(\"*.npy\"):\n",
    "    nm = p.stem\n",
    "    pred = np.load(p)\n",
    "    if pred.shape[1] != size_labels:\n",
    "        aux = -1 + np.zeros(flat_len, dtype=np.int64)\n",
    "        aux[0:H*H] = pred.flatten()\n",
    "    else:\n",
    "        aux = pred.flatten().astype(np.int64)\n",
    "    pred_map[nm] = aux\n",
    "\n",
    "missing = [n for n in ordered_names if n not in pred_map]\n",
    "assert len(missing) == 0, f\"missing predictions: {missing[:10]}\"\n",
    "\n",
    "data = np.stack([pred_map[n] for n in ordered_names], axis=0)\n",
    "col_names = [str(i) for i in range(flat_len)]\n",
    "sub_df = pd.DataFrame(data, columns=col_names)\n",
    "sub_df.insert(0, name_col, ordered_names_raw)\n",
    "\n",
    "out_csv3 = OUT_DIR3 / f\"y_test_submission_MATCH_SAMPLE_{EXP_NAME3}.csv\"\n",
    "sub_df.to_csv(out_csv3, index=False)\n",
    "print(\"Saved submission:\", out_csv3, \"shape:\", sub_df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
