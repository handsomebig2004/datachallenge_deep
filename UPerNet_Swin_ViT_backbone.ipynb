{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Epoch 01/20 | train=0.1124 | val=0.0792\n",
      "  -> best model saved\n",
      "Epoch 02/20 | train=0.0740 | val=0.0748\n",
      "  -> best model saved\n",
      "Epoch 03/20 | train=0.0674 | val=0.0782\n",
      "Epoch 04/20 | train=0.0624 | val=0.0876\n",
      "Epoch 05/20 | train=0.0597 | val=0.0759\n",
      "Epoch 06/20 | train=0.0535 | val=0.0836\n",
      "Epoch 07/20 | train=0.0491 | val=0.0806\n",
      "Epoch 08/20 | train=0.0463 | val=0.0891\n",
      "Epoch 09/20 | train=0.0423 | val=0.0952\n",
      "Epoch 10/20 | train=0.0395 | val=0.1013\n",
      "Epoch 11/20 | train=0.0362 | val=0.0972\n",
      "Epoch 12/20 | train=0.0334 | val=0.1049\n",
      "Epoch 13/20 | train=0.0334 | val=0.1016\n",
      "Epoch 14/20 | train=0.0295 | val=0.1128\n",
      "Epoch 15/20 | train=0.0279 | val=0.1291\n",
      "Epoch 16/20 | train=0.0273 | val=0.1160\n",
      "Epoch 17/20 | train=0.0250 | val=0.1186\n",
      "Epoch 18/20 | train=0.0289 | val=0.1225\n",
      "Epoch 19/20 | train=0.0227 | val=0.1314\n",
      "Epoch 20/20 | train=0.0234 | val=0.1459\n",
      "[OK] submission saved to C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "UPerNet + Swin Transformer backbone\n",
    "FINAL VERSION (NO cv2, PyTorch interpolate only)\n",
    "\n",
    "Key points:\n",
    "- Swin requires 224x224 input\n",
    "- Original data: (160,160) or (160,272)\n",
    "- Strategy:\n",
    "    (160,w) -> pad to (160,272) -> resize to (224,224) -> model\n",
    "    output (224,224) -> resize back to (160,272) -> crop raw_w\n",
    "- Submission remains 160*272 with -1 padding\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) Config\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lenovo\\Desktop\\deep_datachallenge\")\n",
    "\n",
    "TRAIN_IMG_DIR = DATA_ROOT / \"X_train_uDRk9z9\" / \"images\"\n",
    "TEST_IMG_DIR  = DATA_ROOT / \"X_test_xNbnvIa\" / \"images\"\n",
    "Y_TRAIN_CSV   = DATA_ROOT / \"Y_train_T9NrBYo.csv\"\n",
    "\n",
    "# submission size (fixed by challenge)\n",
    "H_SUB, W_SUB = 160, 272\n",
    "\n",
    "# model input size (Swin requirement)\n",
    "H_MODEL, W_MODEL = 224, 224\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "IGNORE_INDEX = -1\n",
    "\n",
    "BATCH_SIZE = 4        # RTX 4060 (8GB): 2~4 recommended\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 20\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Utils\n",
    "# =========================\n",
    "def parse_well_id(name: str) -> int:\n",
    "    m = re.search(r\"well_(\\d+)_\", name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def minmax_norm(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.nan_to_num(x)\n",
    "    mn, mx = x.min(), x.max()\n",
    "    if mx - mn < 1e-6:\n",
    "        return np.zeros_like(x)\n",
    "    return (x - mn) / (mx - mn)\n",
    "\n",
    "\n",
    "def resize_image_to_224(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    img: (160, w)\n",
    "    -> pad to (160,272)\n",
    "    -> resize to (224,224) using bilinear\n",
    "    \"\"\"\n",
    "    padded = np.zeros((H_SUB, W_SUB), dtype=img.dtype)\n",
    "    h, w = img.shape\n",
    "    padded[:, :w] = img\n",
    "\n",
    "    x = torch.from_numpy(padded).unsqueeze(0).unsqueeze(0).float()  # (1,1,160,272)\n",
    "    x = F.interpolate(x, size=(H_MODEL, W_MODEL), mode=\"bilinear\", align_corners=False)\n",
    "    return x.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "\n",
    "def decode_mask(row: np.ndarray) -> np.ndarray:\n",
    "    valid = row[row != IGNORE_INDEX]\n",
    "    w = len(valid) // H_SUB\n",
    "    return valid.reshape(H_SUB, w).astype(np.int64)\n",
    "\n",
    "\n",
    "def resize_mask_to_224(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    mask: (160, w)\n",
    "    -> pad to (160,272) with -1\n",
    "    -> resize to (224,224) using nearest\n",
    "    \"\"\"\n",
    "    padded = np.full((H_SUB, W_SUB), IGNORE_INDEX, dtype=np.int64)\n",
    "    h, w = mask.shape\n",
    "    padded[:, :w] = mask\n",
    "\n",
    "    x = torch.from_numpy(padded).unsqueeze(0).unsqueeze(0).float()\n",
    "    x = F.interpolate(x, size=(H_MODEL, W_MODEL), mode=\"nearest\")\n",
    "    return x.squeeze(0).squeeze(0).long().numpy()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Dataset\n",
    "# =========================\n",
    "class WellDataset(Dataset):\n",
    "    def __init__(self, img_dir: Path, y_csv: Path = None):\n",
    "        self.paths = sorted(img_dir.glob(\"*.npy\"))\n",
    "        self.names = [p.stem for p in self.paths]\n",
    "        self.has_label = y_csv is not None\n",
    "        self.y_df = pd.read_csv(y_csv, index_col=0) if self.has_label else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        img = np.load(self.paths[idx])          # (160, w)\n",
    "        raw_w = img.shape[1]\n",
    "\n",
    "        img = minmax_norm(img)\n",
    "        img224 = resize_image_to_224(img)\n",
    "        x = torch.from_numpy(img224).unsqueeze(0).float()  # (1,224,224)\n",
    "\n",
    "        if not self.has_label:\n",
    "            return {\"name\": name, \"image\": x, \"raw_w\": raw_w}\n",
    "\n",
    "        row = self.y_df.loc[name].values.astype(np.int64)\n",
    "        mask = decode_mask(row)\n",
    "        mask224 = resize_mask_to_224(mask)\n",
    "        y = torch.from_numpy(mask224).long()  # (224,224)\n",
    "\n",
    "        return {\"name\": name, \"image\": x, \"mask\": y, \"raw_w\": raw_w}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Model\n",
    "# =========================\n",
    "def build_model():\n",
    "    return smp.UPerNet(\n",
    "        encoder_name=\"tu-swin_small_patch4_window7_224\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=1,\n",
    "        classes=NUM_CLASSES,\n",
    "        activation=None,\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Train / Validate\n",
    "# =========================\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "\n",
    "    for b in loader:\n",
    "        x = b[\"image\"].to(DEVICE)\n",
    "        y = b[\"mask\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item() * x.size(0)\n",
    "\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "\n",
    "    for b in loader:\n",
    "        x = b[\"image\"].to(DEVICE)\n",
    "        y = b[\"mask\"].to(DEVICE)\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "        total += loss.item() * x.size(0)\n",
    "\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Inference & Submission\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def predict_and_submit(model, out_csv: Path):\n",
    "    model.eval()\n",
    "    test_ds = WellDataset(TEST_IMG_DIR)\n",
    "    loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    preds = {}\n",
    "    for b in loader:\n",
    "        name = b[\"name\"][0]\n",
    "        raw_w = int(b[\"raw_w\"][0])\n",
    "        x = b[\"image\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        pred224 = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "        # resize back to (160,272)\n",
    "        x2 = torch.from_numpy(pred224).unsqueeze(0).unsqueeze(0).float()\n",
    "        x2 = F.interpolate(x2, size=(H_SUB, W_SUB), mode=\"nearest\")\n",
    "        pred160 = x2.squeeze(0).squeeze(0).long().numpy()\n",
    "\n",
    "        pred160 = pred160[:, :raw_w]\n",
    "\n",
    "        flat = np.full((H_SUB * W_SUB,), IGNORE_INDEX, dtype=np.int64)\n",
    "        flat[: H_SUB * raw_w] = pred160.flatten()\n",
    "        preds[name] = flat\n",
    "\n",
    "    pd.DataFrame(preds, dtype=\"int64\").T.to_csv(out_csv)\n",
    "    print(f\"[OK] submission saved to {out_csv}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) Main\n",
    "# =========================\n",
    "def main():\n",
    "    print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "    full_ds = WellDataset(TRAIN_IMG_DIR, Y_TRAIN_CSV)\n",
    "\n",
    "    train_idx, val_idx = [], []\n",
    "    for i, n in enumerate(full_ds.names):\n",
    "        if parse_well_id(n) == 6:\n",
    "            val_idx.append(i)\n",
    "        else:\n",
    "            train_idx.append(i)\n",
    "\n",
    "    train_ds = Subset(full_ds, train_idx)  # well1â€“5\n",
    "    val_ds   = Subset(full_ds, val_idx)    # well6\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = build_model().to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    best_val = 1e9\n",
    "    best_path = DATA_ROOT / \"best_upernet_swin.pth\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr = train_one_epoch(model, train_loader, optimizer)\n",
    "        va = eval_one_epoch(model, val_loader)\n",
    "        print(f\"Epoch {epoch:02d}/{EPOCHS} | train={tr:.4f} | val={va:.4f}\")\n",
    "\n",
    "        if va < best_val:\n",
    "            best_val = va\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(\"  -> best model saved\")\n",
    "\n",
    "    model.load_state_dict(torch.load(best_path, map_location=DEVICE, weights_only=True))\n",
    "    predict_and_submit(model, DATA_ROOT / \"submission.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
