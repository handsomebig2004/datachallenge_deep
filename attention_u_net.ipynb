{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd2e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Train dir: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\X_train_uDRk9z9\\images\n",
      "Test dir:  C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\X_test_xNbnvIa\\images\n",
      "Train samples: 2790 | Val samples: 1620 | val_wells={6}\n",
      "Epoch 01/20 | train_loss=0.2101 | val_loss=0.1172\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_attention_unet.pth\n",
      "Epoch 02/20 | train_loss=0.0944 | val_loss=0.1888\n",
      "Epoch 03/20 | train_loss=0.0832 | val_loss=0.1081\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_attention_unet.pth\n",
      "Epoch 04/20 | train_loss=0.0848 | val_loss=0.1979\n",
      "Epoch 05/20 | train_loss=0.0776 | val_loss=0.0860\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_attention_unet.pth\n",
      "Epoch 06/20 | train_loss=0.0754 | val_loss=0.1289\n",
      "Epoch 07/20 | train_loss=0.0760 | val_loss=0.0803\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_attention_unet.pth\n",
      "Epoch 08/20 | train_loss=0.0732 | val_loss=0.0971\n",
      "Epoch 09/20 | train_loss=0.0735 | val_loss=0.1063\n",
      "Epoch 10/20 | train_loss=0.0712 | val_loss=0.1057\n",
      "Epoch 11/20 | train_loss=0.0703 | val_loss=0.0877\n",
      "Epoch 12/20 | train_loss=0.0699 | val_loss=0.0881\n",
      "Epoch 13/20 | train_loss=0.0699 | val_loss=0.0905\n",
      "Epoch 14/20 | train_loss=0.0680 | val_loss=0.0802\n",
      "  -> Best model saved: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_attention_unet.pth\n",
      "Epoch 15/20 | train_loss=0.0665 | val_loss=0.0923\n",
      "Epoch 16/20 | train_loss=0.0673 | val_loss=0.0847\n",
      "Epoch 17/20 | train_loss=0.0670 | val_loss=0.0874\n",
      "Epoch 18/20 | train_loss=0.0666 | val_loss=0.0949\n",
      "Epoch 19/20 | train_loss=0.0644 | val_loss=0.1550\n",
      "Epoch 20/20 | train_loss=0.0645 | val_loss=0.1053\n",
      "[OK] submission saved to: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Attention U-Net - Full runnable semantic segmentation code (no extra libs)\n",
    "\n",
    "Dataset:\n",
    "- Train images: X_train_uDRk9z9/images (well1-6)\n",
    "- Train labels: Y_train_T9NrBYo.csv (flatten + -1 padding)\n",
    "- Test images:  X_test_xNbnvIa/images  (well7-11)\n",
    "\n",
    "Split:\n",
    "- Train: well1-5\n",
    "- Val:   well6\n",
    "\n",
    "Output:\n",
    "- submission.csv (each row = one patch name, flattened, padded to 160*272 with -1)\n",
    "\n",
    "Notes:\n",
    "- Input patches are (160,160) or (160,272). We pad to (160,272).\n",
    "- Class ids: 0/1/2; padding is -1 (ignored in loss).\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) Paths & Hyperparameters\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lenovo\\Desktop\\deep_datachallenge\")  # change to your path\n",
    "\n",
    "TRAIN_IMAGES_DIR = DATA_ROOT / \"X_train_uDRk9z9\" / \"images\"\n",
    "TEST_IMAGES_DIR = DATA_ROOT / \"X_test_xNbnvIa\" / \"images\"\n",
    "Y_TRAIN_CSV = DATA_ROOT / \"Y_train_T9NrBYo.csv\"\n",
    "\n",
    "H = 160\n",
    "W = 272\n",
    "NUM_CLASSES = 3\n",
    "IGNORE_INDEX = -1\n",
    "\n",
    "BATCH_SIZE = 8          # Attention U-Net is lighter than Swin/Mask2Former; 8 is often OK on 4060(8GB)\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 20\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Utils\n",
    "# =========================\n",
    "def parse_well_id(name: str) -> int:\n",
    "    \"\"\"Extract well id from: well_1_section_0_patch_0 -> 1\"\"\"\n",
    "    m = re.search(r\"well_(\\d+)_\", name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def minmax_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Min-max normalize; replace NaN/inf with 0.\"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    x_min = float(x.min())\n",
    "    x_max = float(x.max())\n",
    "    if x_max - x_min < 1e-6:\n",
    "        return np.zeros_like(x, dtype=np.float32)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "\n",
    "def pad_to_160x272(img: np.ndarray, fill_value: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"Pad (160,160) or (160,272) to (160,272).\"\"\"\n",
    "    h, w = img.shape\n",
    "    assert h == H, f\"Expected height {H}, got {h}\"\n",
    "    if w == W:\n",
    "        return img\n",
    "    if w < W:\n",
    "        out = np.full((H, W), fill_value, dtype=img.dtype)\n",
    "        out[:, :w] = img\n",
    "        return out\n",
    "    return img[:, :W]\n",
    "\n",
    "\n",
    "def decode_mask_from_csv_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Decode one CSV row -> (160,w) semantic mask\n",
    "    - row_values: flattened mask with -1 padding\n",
    "    \"\"\"\n",
    "    valid = row_values[row_values != IGNORE_INDEX]\n",
    "    assert len(valid) % H == 0, f\"Valid mask length {len(valid)} not divisible by 160\"\n",
    "    ww = len(valid) // H\n",
    "    return valid.reshape(H, ww).astype(np.int64)\n",
    "\n",
    "\n",
    "def pad_mask_to_160x272(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Pad (160,w) -> (160,272) using -1 for padding.\"\"\"\n",
    "    h, w = mask.shape\n",
    "    assert h == H\n",
    "    if w == W:\n",
    "        return mask\n",
    "    out = np.full((H, W), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Dataset\n",
    "# =========================\n",
    "class WellSegDataset(Dataset):\n",
    "    def __init__(self, images_dir: Path, y_csv_path: Path = None, wells=None):\n",
    "        \"\"\"\n",
    "        y_csv_path=None => test mode.\n",
    "        wells: optional set of well ids to filter.\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.has_label = y_csv_path is not None\n",
    "        self.wells = set(wells) if wells is not None else None\n",
    "\n",
    "        all_paths = sorted(images_dir.glob(\"*.npy\"))\n",
    "        all_names = [p.stem for p in all_paths]\n",
    "\n",
    "        if self.wells is None:\n",
    "            self.image_paths = all_paths\n",
    "            self.names = all_names\n",
    "        else:\n",
    "            keep = []\n",
    "            keep_names = []\n",
    "            for p, n in zip(all_paths, all_names):\n",
    "                if parse_well_id(n) in self.wells:\n",
    "                    keep.append(p)\n",
    "                    keep_names.append(n)\n",
    "            self.image_paths = keep\n",
    "            self.names = keep_names\n",
    "\n",
    "        self.y_df = pd.read_csv(y_csv_path, index_col=0) if self.has_label else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        name = self.names[idx]\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        img = np.load(img_path)       # (160,160) or (160,272)\n",
    "        raw_w = int(img.shape[1])\n",
    "        img = minmax_normalize(img)\n",
    "        img = pad_to_160x272(img, fill_value=0.0)\n",
    "        x = torch.from_numpy(img).unsqueeze(0).float()  # (1,160,272)\n",
    "\n",
    "        if not self.has_label:\n",
    "            return {\"name\": name, \"image\": x, \"raw_w\": raw_w}\n",
    "\n",
    "        row = self.y_df.loc[name].values.astype(np.int64)\n",
    "        mask = decode_mask_from_csv_row(row)   # (160,w)\n",
    "        mask = pad_mask_to_160x272(mask)       # (160,272)\n",
    "        y = torch.from_numpy(mask).long()      # (160,272)\n",
    "\n",
    "        return {\"name\": name, \"image\": x, \"mask\": y, \"raw_w\": raw_w}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Attention U-Net building blocks\n",
    "# =========================\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv (we use bilinear upsample)\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Gate (AG) from Attention U-Net:\n",
    "    - g: gating signal from decoder\n",
    "    - x: skip connection from encoder\n",
    "    output: attended skip features\n",
    "    \"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g and x may have different spatial sizes; resize g to x size\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        if g1.shape[-2:] != x1.shape[-2:]:\n",
    "            g1 = F.interpolate(g1, size=x1.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)  # (B,1,H,W) attention mask in [0,1]\n",
    "        return x * psi\n",
    "\n",
    "\n",
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=3, base=32):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(in_channels, base)         # 32\n",
    "        self.down1 = Down(base, base*2)                  # 64\n",
    "        self.down2 = Down(base*2, base*4)                # 128\n",
    "        self.down3 = Down(base*4, base*8)                # 256\n",
    "        self.down4 = Down(base*8, base*16)               # 512\n",
    "\n",
    "        # Decoder + Attention gates\n",
    "        self.att4 = AttentionGate(F_g=base*16, F_l=base*8,  F_int=base*4)\n",
    "        self.up4 = Up(in_ch=base*16 + base*8, out_ch=base*8)\n",
    "\n",
    "        self.att3 = AttentionGate(F_g=base*8,  F_l=base*4,  F_int=base*2)\n",
    "        self.up3 = Up(in_ch=base*8 + base*4,  out_ch=base*4)\n",
    "\n",
    "        self.att2 = AttentionGate(F_g=base*4,  F_l=base*2,  F_int=base)\n",
    "        self.up2 = Up(in_ch=base*4 + base*2,  out_ch=base*2)\n",
    "\n",
    "        self.att1 = AttentionGate(F_g=base*2,  F_l=base,    F_int=base//2)\n",
    "        self.up1 = Up(in_ch=base*2 + base,    out_ch=base)\n",
    "\n",
    "        self.outc = nn.Conv2d(base, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)       # (B,base,   H,   W)\n",
    "        x2 = self.down1(x1)    # (B,base*2, H/2, W/2)\n",
    "        x3 = self.down2(x2)    # (B,base*4, H/4, W/4)\n",
    "        x4 = self.down3(x3)    # (B,base*8, H/8, W/8)\n",
    "        x5 = self.down4(x4)    # (B,base*16,H/16,W/16)\n",
    "\n",
    "        # Decoder with attention on skip connections\n",
    "        s4 = self.att4(g=x5, x=x4)\n",
    "        d4 = self.up4(x5, s4)\n",
    "\n",
    "        s3 = self.att3(g=d4, x=x3)\n",
    "        d3 = self.up3(d4, s3)\n",
    "\n",
    "        s2 = self.att2(g=d3, x=x2)\n",
    "        d2 = self.up2(d3, s2)\n",
    "\n",
    "        s1 = self.att1(g=d2, x=x1)\n",
    "        d1 = self.up1(d2, s1)\n",
    "\n",
    "        logits = self.outc(d1)  # (B,C,H,W)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Train / Validate\n",
    "# =========================\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)      # (B,1,160,272)\n",
    "        y = batch[\"mask\"].to(DEVICE)       # (B,160,272)\n",
    "\n",
    "        logits = model(x)                  # (B,C,160,272)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.item()) * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "        y = batch[\"mask\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "        total_loss += float(loss.item()) * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Inference & submission\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def predict_and_make_submission(model, test_images_dir: Path, out_csv_path: Path):\n",
    "    \"\"\"\n",
    "    Predict all test patches and write submission.csv:\n",
    "    - argmax over classes\n",
    "    - crop to raw width\n",
    "    - pad to 160*272 using -1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    test_ds = WellSegDataset(test_images_dir, y_csv_path=None)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    preds_dict = {}\n",
    "\n",
    "    for batch in test_loader:\n",
    "        name = batch[\"name\"][0]\n",
    "        raw_w = int(batch[\"raw_w\"][0])\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        pred_full = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)  # (160,272)\n",
    "\n",
    "        pred = pred_full[:, :raw_w]  # crop to original width\n",
    "\n",
    "        if raw_w < W:\n",
    "            padded = np.full((H * W,), IGNORE_INDEX, dtype=np.int64)\n",
    "            padded[: H * raw_w] = pred.flatten()\n",
    "            preds_dict[name] = padded\n",
    "        else:\n",
    "            preds_dict[name] = pred.flatten()\n",
    "\n",
    "    sub = pd.DataFrame(preds_dict, dtype=\"int64\").T\n",
    "    sub.to_csv(out_csv_path)\n",
    "    print(f\"[OK] submission saved to: {out_csv_path}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) Main\n",
    "# =========================\n",
    "def main():\n",
    "    print(f\"DEVICE: {DEVICE}\")\n",
    "    print(f\"Train dir: {TRAIN_IMAGES_DIR}\")\n",
    "    print(f\"Test dir:  {TEST_IMAGES_DIR}\")\n",
    "\n",
    "    # Load all train data (well1-6)\n",
    "    train_ds_all = WellSegDataset(TRAIN_IMAGES_DIR, Y_TRAIN_CSV)\n",
    "\n",
    "    # Split by well: well6 as validation\n",
    "    VAL_WELLS = {6}\n",
    "    train_indices, val_indices = [], []\n",
    "    for i, name in enumerate(train_ds_all.names):\n",
    "        w = parse_well_id(name)\n",
    "        if w in VAL_WELLS:\n",
    "            val_indices.append(i)\n",
    "        else:\n",
    "            train_indices.append(i)\n",
    "\n",
    "    train_ds = Subset(train_ds_all, train_indices)  # well1-5\n",
    "    val_ds = Subset(train_ds_all, val_indices)      # well6\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Train samples: {len(train_ds)} | Val samples: {len(val_ds)} | val_wells={VAL_WELLS}\")\n",
    "\n",
    "    model = AttentionUNet(in_channels=1, num_classes=NUM_CLASSES, base=32).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    best_val = 1e9\n",
    "    best_path = DATA_ROOT / \"best_attention_unet.pth\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "        va_loss = valid_one_epoch(model, val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{EPOCHS} | train_loss={tr_loss:.4f} | val_loss={va_loss:.4f}\")\n",
    "\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"  -> Best model saved: {best_path}\")\n",
    "\n",
    "    # Predict test and write submission\n",
    "    out_csv = DATA_ROOT / \"submission.csv\"\n",
    "    state_dict = torch.load(best_path, map_location=DEVICE, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    predict_and_make_submission(model, TEST_IMAGES_DIR, out_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
