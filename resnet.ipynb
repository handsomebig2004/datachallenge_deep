{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e145ce",
   "metadata": {},
   "source": [
    "## Res Net34-Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3cbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本数: 2790 | 验证样本数: 1620 | val_wells={6}\n",
      "Epoch 01/20 | train_loss=0.1348 | val_loss=0.1186\n",
      "  -> 保存最优模型: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_resnet34_unet.pth\n",
      "Epoch 02/20 | train_loss=0.0833 | val_loss=0.4633\n",
      "Epoch 03/20 | train_loss=0.0795 | val_loss=0.1263\n",
      "Epoch 04/20 | train_loss=0.0759 | val_loss=0.0764\n",
      "  -> 保存最优模型: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_resnet34_unet.pth\n",
      "Epoch 05/20 | train_loss=0.0762 | val_loss=0.0862\n",
      "Epoch 06/20 | train_loss=0.0723 | val_loss=0.2669\n",
      "Epoch 07/20 | train_loss=0.0719 | val_loss=0.0981\n",
      "Epoch 08/20 | train_loss=0.0703 | val_loss=0.4578\n",
      "Epoch 09/20 | train_loss=0.0725 | val_loss=0.0795\n",
      "Epoch 10/20 | train_loss=0.0686 | val_loss=0.0902\n",
      "Epoch 11/20 | train_loss=0.0678 | val_loss=0.0798\n",
      "Epoch 12/20 | train_loss=0.0682 | val_loss=0.1063\n",
      "Epoch 13/20 | train_loss=0.0683 | val_loss=0.0870\n",
      "Epoch 14/20 | train_loss=0.0655 | val_loss=0.0828\n",
      "Epoch 15/20 | train_loss=0.0654 | val_loss=0.0841\n",
      "Epoch 16/20 | train_loss=0.0668 | val_loss=0.0817\n",
      "Epoch 17/20 | train_loss=0.0639 | val_loss=0.0867\n",
      "Epoch 18/20 | train_loss=0.0636 | val_loss=0.0818\n",
      "Epoch 19/20 | train_loss=0.0634 | val_loss=0.0777\n",
      "Epoch 20/20 | train_loss=0.0633 | val_loss=0.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_11248\\3190494213.py:345: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] submission 已保存: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ResNet34-UNet (simplified, runnable)\n",
    "- Training images: X_train_uDRk9z9/images (well1-6)\n",
    "- Test images: X_test_xNbnvIa/images (well7-11)\n",
    "- Training labels: Y_train_T9NrBYo.csv (flatten + -1 padding)\n",
    "- Validation: split by well from training set (e.g. well6 as val, others as train)\n",
    "- Output: submission.csv (one row per patch, flattened, padded to 160*272 with -1)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0. Hyperparameters & Paths\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lenovo\\Desktop\\deep_datachallenge\")  # change to your actual path\n",
    "\n",
    "TRAIN_IMAGES_DIR = DATA_ROOT / \"X_train_uDRk9z9\" / \"images\"\n",
    "TEST_IMAGES_DIR = DATA_ROOT / \"X_test_xNbnvIa\" / \"images\"\n",
    "Y_TRAIN_CSV = DATA_ROOT / \"Y_train_T9NrBYo.csv\"\n",
    "\n",
    "TARGET_H = 160\n",
    "TARGET_W = 272\n",
    "\n",
    "NUM_CLASSES = 3          # you confirmed the CSV has only 0/1/2\n",
    "IGNORE_INDEX = -1        # CSV padding\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 20              # if training is slow, set to 5 first; increase after it runs\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1. Utility Functions\n",
    "# =========================\n",
    "def parse_well_id(name: str) -> int:\n",
    "    \"\"\"Extract well id=1 from name like well_1_section_0_patch_0\"\"\"\n",
    "    m = re.search(r\"well_(\\d+)_\", name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def minmax_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Min-max normalization; set NaN/inf to 0.\"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    x_min = float(x.min())\n",
    "    x_max = float(x.max())\n",
    "    if x_max - x_min < 1e-6:\n",
    "        return np.zeros_like(x, dtype=np.float32)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "\n",
    "def pad_to_160x272(img: np.ndarray, fill_value: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"Pad (160,160) or (160,272) to (160,272).\"\"\"\n",
    "    h, w = img.shape\n",
    "    assert h == TARGET_H, f\"Expected height {TARGET_H}, but got {h}\"\n",
    "    if w == TARGET_W:\n",
    "        return img\n",
    "    if w < TARGET_W:\n",
    "        out = np.full((TARGET_H, TARGET_W), fill_value, dtype=img.dtype)\n",
    "        out[:, :w] = img\n",
    "        return out\n",
    "    return img[:, :TARGET_W]\n",
    "\n",
    "\n",
    "def decode_mask_from_csv_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Restore mask from one CSV row:\n",
    "    - row_values: flatten + -1 padding\n",
    "    - remove -1 then reshape to (160, w)\n",
    "    \"\"\"\n",
    "    valid = row_values[row_values != IGNORE_INDEX]\n",
    "    assert len(valid) % TARGET_H == 0, f\"Valid mask length {len(valid)} is not divisible by 160\"\n",
    "    w = len(valid) // TARGET_H\n",
    "    return valid.reshape(TARGET_H, w).astype(np.int64)\n",
    "\n",
    "\n",
    "def pad_mask_to_160x272(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Pad (160,w) to (160,272), pad with -1 (ignore).\"\"\"\n",
    "    h, w = mask.shape\n",
    "    assert h == TARGET_H\n",
    "    if w == TARGET_W:\n",
    "        return mask\n",
    "    out = np.full((TARGET_H, TARGET_W), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. Dataset (shared for train/test)\n",
    "# =========================\n",
    "class WellSegDataset(Dataset):\n",
    "    def __init__(self, images_dir: Path, y_csv_path: Path = None):\n",
    "        \"\"\"\n",
    "        y_csv_path=None indicates unlabeled data (test set).\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.has_label = y_csv_path is not None\n",
    "\n",
    "        self.image_paths = sorted(images_dir.glob(\"*.npy\"))\n",
    "        self.names = [p.stem for p in self.image_paths]\n",
    "\n",
    "        if self.has_label:\n",
    "            # CSV index is usually patch name (without .npy)\n",
    "            self.y_df = pd.read_csv(y_csv_path, index_col=0)\n",
    "        else:\n",
    "            self.y_df = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        name = self.names[idx]\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        img = np.load(img_path)        # (160,160) or (160,272)\n",
    "        raw_w = img.shape[1]           # record original width (crop back during inference)\n",
    "        img = minmax_normalize(img)\n",
    "        img = pad_to_160x272(img, fill_value=0.0)\n",
    "        img_t = torch.from_numpy(img).unsqueeze(0).float()  # (1,160,272)\n",
    "\n",
    "        if not self.has_label:\n",
    "            return {\"name\": name, \"image\": img_t, \"raw_w\": raw_w}\n",
    "\n",
    "        row = self.y_df.loc[name].values.astype(np.int64)\n",
    "        mask = decode_mask_from_csv_row(row)     # (160,w)\n",
    "        mask = pad_mask_to_160x272(mask)         # (160,272)\n",
    "        mask_t = torch.from_numpy(mask).long()\n",
    "\n",
    "        return {\"name\": name, \"image\": img_t, \"mask\": mask_t, \"raw_w\": raw_w}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. ResNet34-UNet (simplified implementation)\n",
    "# =========================\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvRelu(in_ch + skip_ch, out_ch)\n",
    "        self.conv2 = ConvRelu(out_ch, out_ch)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet34UNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        backbone = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # Single-channel input: change first conv to 1 channel (initialize by mean of original weights)\n",
    "        old_conv1 = backbone.conv1\n",
    "        new_conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            new_conv1.weight[:] = old_conv1.weight.mean(dim=1, keepdim=True)\n",
    "        backbone.conv1 = new_conv1\n",
    "\n",
    "        self.enc0 = nn.Sequential(backbone.conv1, backbone.bn1, backbone.relu)  # /2\n",
    "        self.pool0 = backbone.maxpool                                           # /4\n",
    "        self.enc1 = backbone.layer1                                             # /4\n",
    "        self.enc2 = backbone.layer2                                             # /8\n",
    "        self.enc3 = backbone.layer3                                             # /16\n",
    "        self.enc4 = backbone.layer4                                             # /32\n",
    "\n",
    "        self.center = nn.Sequential(ConvRelu(512, 512), ConvRelu(512, 512))\n",
    "        self.up4 = UpBlock(512, 256, 256)\n",
    "        self.up3 = UpBlock(256, 128, 128)\n",
    "        self.up2 = UpBlock(128, 64, 64)\n",
    "        self.up1 = UpBlock(64, 64, 64)\n",
    "\n",
    "        self.head = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e0 = self.enc0(x)\n",
    "        e1 = self.enc1(self.pool0(e0))\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "\n",
    "        c = self.center(e4)\n",
    "        d4 = self.up4(c, e3)\n",
    "        d3 = self.up3(d4, e2)\n",
    "        d2 = self.up2(d3, e1)\n",
    "        d1 = self.up1(d2, e0)\n",
    "\n",
    "        out = self.head(d1)\n",
    "        out = F.interpolate(out, size=(TARGET_H, TARGET_W), mode=\"bilinear\", align_corners=False)\n",
    "        return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. Training & Validation (minimal)\n",
    "# =========================\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "        y = batch[\"mask\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "        y = batch[\"mask\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. Inference & Submission CSV\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def predict_and_make_submission(model, test_images_dir: Path, out_csv_path: Path):\n",
    "    \"\"\"\n",
    "    Predict all npy files in test_images_dir and generate submission CSV.\n",
    "    - one row per patch\n",
    "    - length: 160*272\n",
    "    - if original width < 272, pad the rest with -1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    test_ds = WellSegDataset(test_images_dir, y_csv_path=None)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    preds_dict = {}\n",
    "\n",
    "    for batch in test_loader:\n",
    "        name = batch[\"name\"][0]\n",
    "        raw_w = int(batch[\"raw_w\"][0])\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        pred_full = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)  # (160,272)\n",
    "\n",
    "        pred = pred_full[:, :raw_w]  # crop back to original width\n",
    "        if raw_w < TARGET_W:\n",
    "            padded = np.full((TARGET_H * TARGET_W,), IGNORE_INDEX, dtype=np.int64)\n",
    "            padded[: TARGET_H * raw_w] = pred.flatten()\n",
    "            preds_dict[name] = padded\n",
    "        else:\n",
    "            preds_dict[name] = pred.flatten()\n",
    "\n",
    "    sub = pd.DataFrame(preds_dict, dtype=\"int64\").T\n",
    "    sub.to_csv(out_csv_path)\n",
    "    print(f\"[OK] Submission saved: {out_csv_path}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6. Main: train (well1-5) + validate (well6) + predict test (well7-11)\n",
    "# =========================\n",
    "def main():\n",
    "    # (A) Build the training dataset (well1-6)\n",
    "    train_ds_all = WellSegDataset(TRAIN_IMAGES_DIR, Y_TRAIN_CSV)\n",
    "\n",
    "    # (B) Split train/val by well: use well6 as validation\n",
    "    VAL_WELLS = {6}\n",
    "    train_indices, val_indices = [], []\n",
    "    for i, name in enumerate(train_ds_all.names):\n",
    "        w = parse_well_id(name)\n",
    "        if w in VAL_WELLS:\n",
    "            val_indices.append(i)\n",
    "        else:\n",
    "            train_indices.append(i)\n",
    "\n",
    "    train_ds = Subset(train_ds_all, train_indices)  # well1-5\n",
    "    val_ds = Subset(train_ds_all, val_indices)      # well6\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Train samples: {len(train_ds)} | Val samples: {len(val_ds)} | val_wells={VAL_WELLS}\")\n",
    "\n",
    "    # (C) Model & optimizer\n",
    "    model = ResNet34UNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    # (D) Train\n",
    "    best_val = 1e9\n",
    "    best_path = DATA_ROOT / \"best_resnet34_unet.pth\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "        va_loss = valid_one_epoch(model, val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch:02d}/{EPOCHS} | train_loss={tr_loss:.4f} | val_loss={va_loss:.4f}\")\n",
    "\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"  -> Best model saved: {best_path}\")\n",
    "\n",
    "    # (E) Generate submission (test directory well7-11)\n",
    "    out_csv = DATA_ROOT / \"submission.csv\"\n",
    "    model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "    predict_and_make_submission(model, TEST_IMAGES_DIR, out_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
