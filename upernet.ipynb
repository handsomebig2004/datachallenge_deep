{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaeb914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本数: 2790 | 验证样本数: 1620 | val_wells={6}\n",
      "DEVICE: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\lenovo/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:09<00:00, 10.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20 | train_loss=0.1318 | val_loss=0.1120\n",
      "  -> 保存最优模型: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_upernet.pth\n",
      "Epoch 02/20 | train_loss=0.0745 | val_loss=0.0900\n",
      "  -> 保存最优模型: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\best_upernet.pth\n",
      "Epoch 03/20 | train_loss=0.0664 | val_loss=0.0940\n",
      "Epoch 04/20 | train_loss=0.0616 | val_loss=0.1032\n",
      "Epoch 05/20 | train_loss=0.0576 | val_loss=0.1283\n",
      "Epoch 06/20 | train_loss=0.0555 | val_loss=0.0903\n",
      "Epoch 07/20 | train_loss=0.0538 | val_loss=0.0936\n",
      "Epoch 08/20 | train_loss=0.0509 | val_loss=0.1156\n",
      "Epoch 09/20 | train_loss=0.0481 | val_loss=0.0915\n",
      "Epoch 10/20 | train_loss=0.0446 | val_loss=0.0991\n",
      "Epoch 11/20 | train_loss=0.0449 | val_loss=0.1008\n",
      "Epoch 12/20 | train_loss=0.0416 | val_loss=0.1002\n",
      "Epoch 13/20 | train_loss=0.0402 | val_loss=0.1123\n",
      "Epoch 14/20 | train_loss=0.0419 | val_loss=0.1042\n",
      "Epoch 15/20 | train_loss=0.0380 | val_loss=0.1052\n",
      "Epoch 16/20 | train_loss=0.0379 | val_loss=0.1320\n",
      "Epoch 17/20 | train_loss=0.0359 | val_loss=0.1031\n",
      "Epoch 18/20 | train_loss=0.0340 | val_loss=0.1163\n",
      "Epoch 19/20 | train_loss=0.0341 | val_loss=0.1079\n",
      "Epoch 20/20 | train_loss=0.0381 | val_loss=0.1154\n",
      "[OK] submission 已保存: C:\\Users\\lenovo\\Desktop\\deep_datachallenge\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "UPerNet (ResNet50 backbone, torchvision pretrained) - Full runnable version (simple implementation)\n",
    "\n",
    "- Training images: X_train_uDRk9z9/images (well1–6)\n",
    "- Test images: X_test_xNbnvIa/images (well7–11)\n",
    "- Training labels: Y_train_T9NrBYo.csv (flattened with -1 padding)\n",
    "- Validation split: by well (e.g. well6 as validation, others as training)\n",
    "- Output: submission.csv (one row per patch, flattened, padded to 160*272 with -1)\n",
    "\n",
    "You only need to check / modify:\n",
    "1) DATA_ROOT path\n",
    "2) EPOCHS / BATCH_SIZE (set smaller if training is slow)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0. Hyperparameters & Paths\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"C:\\Users\\lenovo\\Desktop\\deep_datachallenge\")  # change to your actual path\n",
    "\n",
    "TRAIN_IMAGES_DIR = DATA_ROOT / \"X_train_uDRk9z9\" / \"images\"\n",
    "TEST_IMAGES_DIR = DATA_ROOT / \"X_test_xNbnvIa\" / \"images\"\n",
    "Y_TRAIN_CSV = DATA_ROOT / \"Y_train_T9NrBYo.csv\"\n",
    "\n",
    "TARGET_H = 160\n",
    "TARGET_W = 272\n",
    "\n",
    "NUM_CLASSES = 3          # only classes 0/1/2 in CSV\n",
    "IGNORE_INDEX = -1        # padding value in CSV\n",
    "\n",
    "BATCH_SIZE = 4           # UPerNet is memory-heavy; for RTX 4060 (8GB) start with 2–4\n",
    "LR = 1e-4                # smaller LR is usually more stable with pretrained backbones\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 20              # reduce for quick debugging\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1. Utility Functions\n",
    "# =========================\n",
    "def parse_well_id(name: str) -> int:\n",
    "    \"\"\"Extract well id from name like: well_1_section_0_patch_0 -> 1\"\"\"\n",
    "    m = re.search(r\"well_(\\d+)_\", name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "\n",
    "def minmax_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Min-max normalization; replace NaN/Inf with 0.\"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    x_min = float(x.min())\n",
    "    x_max = float(x.max())\n",
    "    if x_max - x_min < 1e-6:\n",
    "        return np.zeros_like(x, dtype=np.float32)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "\n",
    "def pad_to_160x272(img: np.ndarray, fill_value: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"Pad (160,160) or (160,272) image to (160,272).\"\"\"\n",
    "    h, w = img.shape\n",
    "    assert h == TARGET_H, f\"Expected height {TARGET_H}, got {h}\"\n",
    "    if w == TARGET_W:\n",
    "        return img\n",
    "    if w < TARGET_W:\n",
    "        out = np.full((TARGET_H, TARGET_W), fill_value, dtype=img.dtype)\n",
    "        out[:, :w] = img\n",
    "        return out\n",
    "    return img[:, :TARGET_W]\n",
    "\n",
    "\n",
    "def decode_mask_from_csv_row(row_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Restore mask from one CSV row:\n",
    "    - row_values: flattened mask with -1 padding\n",
    "    - remove -1 and reshape to (160, w)\n",
    "    \"\"\"\n",
    "    valid = row_values[row_values != IGNORE_INDEX]\n",
    "    assert len(valid) % TARGET_H == 0, f\"Valid mask length {len(valid)} not divisible by 160\"\n",
    "    w = len(valid) // TARGET_H\n",
    "    return valid.reshape(TARGET_H, w).astype(np.int64)\n",
    "\n",
    "\n",
    "def pad_mask_to_160x272(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Pad (160, w) mask to (160,272) using -1 as ignore index.\"\"\"\n",
    "    h, w = mask.shape\n",
    "    assert h == TARGET_H\n",
    "    if w == TARGET_W:\n",
    "        return mask\n",
    "    out = np.full((TARGET_H, TARGET_W), IGNORE_INDEX, dtype=np.int64)\n",
    "    out[:, :w] = mask\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. Dataset (shared for train/test)\n",
    "# =========================\n",
    "class WellSegDataset(Dataset):\n",
    "    def __init__(self, images_dir: Path, y_csv_path: Path = None):\n",
    "        \"\"\"\n",
    "        y_csv_path=None indicates unlabeled data (test set).\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.has_label = y_csv_path is not None\n",
    "\n",
    "        self.image_paths = sorted(images_dir.glob(\"*.npy\"))\n",
    "        self.names = [p.stem for p in self.image_paths]\n",
    "\n",
    "        if self.has_label:\n",
    "            self.y_df = pd.read_csv(y_csv_path, index_col=0)\n",
    "        else:\n",
    "            self.y_df = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        name = self.names[idx]\n",
    "        img_path = self.image_paths[idx]\n",
    "\n",
    "        img = np.load(img_path)        # (160,160) or (160,272)\n",
    "        raw_w = img.shape[1]           # used to crop back during inference\n",
    "        img = minmax_normalize(img)\n",
    "        img = pad_to_160x272(img, fill_value=0.0)\n",
    "        img_t = torch.from_numpy(img).unsqueeze(0).float()  # (1,160,272)\n",
    "\n",
    "        if not self.has_label:\n",
    "            return {\"name\": name, \"image\": img_t, \"raw_w\": raw_w}\n",
    "\n",
    "        row = self.y_df.loc[name].values.astype(np.int64)\n",
    "        mask = decode_mask_from_csv_row(row)     # (160,w)\n",
    "        mask = pad_mask_to_160x272(mask)         # (160,272)\n",
    "        mask_t = torch.from_numpy(mask).long()\n",
    "\n",
    "        return {\"name\": name, \"image\": img_t, \"mask\": mask_t, \"raw_w\": raw_w}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. UPerNet Head (simplified)\n",
    "# =========================\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class PSPModule(nn.Module):\n",
    "    \"\"\"\n",
    "    PSP module: multi-scale pooling on the highest-level feature.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch=256, pool_sizes=(1, 2, 3, 6)):\n",
    "        super().__init__()\n",
    "        self.stages = nn.ModuleList()\n",
    "        for ps in pool_sizes:\n",
    "            self.stages.append(nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d((ps, ps)),\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ))\n",
    "        self.bottleneck = ConvBNReLU(in_ch + len(pool_sizes) * out_ch, out_ch, k=3, p=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[-2:]\n",
    "        priors = [x]\n",
    "        for stage in self.stages:\n",
    "            y = stage(x)\n",
    "            y = F.interpolate(y, size=(h, w), mode=\"bilinear\", align_corners=False)\n",
    "            priors.append(y)\n",
    "        x = torch.cat(priors, dim=1)\n",
    "        return self.bottleneck(x)\n",
    "\n",
    "\n",
    "class UPerHead(nn.Module):\n",
    "    \"\"\"\n",
    "    UPerNet Head = PSP + FPN\n",
    "    Input features: c2(1/4), c3(1/8), c4(1/16), c5(1/32)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=(256, 512, 1024, 2048), fpn_dim=256, num_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        c2, c3, c4, c5 = in_channels\n",
    "\n",
    "        self.psp = PSPModule(c5, out_ch=fpn_dim)\n",
    "\n",
    "        self.lateral_c2 = nn.Conv2d(c2, fpn_dim, kernel_size=1, bias=False)\n",
    "        self.lateral_c3 = nn.Conv2d(c3, fpn_dim, kernel_size=1, bias=False)\n",
    "        self.lateral_c4 = nn.Conv2d(c4, fpn_dim, kernel_size=1, bias=False)\n",
    "\n",
    "        self.fpn_c2 = ConvBNReLU(fpn_dim, fpn_dim)\n",
    "        self.fpn_c3 = ConvBNReLU(fpn_dim, fpn_dim)\n",
    "        self.fpn_c4 = ConvBNReLU(fpn_dim, fpn_dim)\n",
    "        self.fpn_c5 = ConvBNReLU(fpn_dim, fpn_dim)\n",
    "\n",
    "        self.fuse = ConvBNReLU(fpn_dim * 4, fpn_dim)\n",
    "        self.cls = nn.Conv2d(fpn_dim, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, c2, c3, c4, c5):\n",
    "        p5 = self.psp(c5)\n",
    "\n",
    "        p4 = self.lateral_c4(c4)\n",
    "        p3 = self.lateral_c3(c3)\n",
    "        p2 = self.lateral_c2(c2)\n",
    "\n",
    "        p4 = p4 + F.interpolate(p5, size=p4.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        p3 = p3 + F.interpolate(p4, size=p3.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        p2 = p2 + F.interpolate(p3, size=p2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        p5 = self.fpn_c5(p5)\n",
    "        p4 = self.fpn_c4(p4)\n",
    "        p3 = self.fpn_c3(p3)\n",
    "        p2 = self.fpn_c2(p2)\n",
    "\n",
    "        p5_u = F.interpolate(p5, size=p2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        p4_u = F.interpolate(p4, size=p2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        p3_u = F.interpolate(p3, size=p2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        x = torch.cat([p2, p3_u, p4_u, p5_u], dim=1)\n",
    "        x = self.fuse(x)\n",
    "        logits = self.cls(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. UPerNet (ResNet50 backbone)\n",
    "# =========================\n",
    "class UPerNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "        old_conv1 = backbone.conv1\n",
    "        new_conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=old_conv1.out_channels,\n",
    "            kernel_size=old_conv1.kernel_size,\n",
    "            stride=old_conv1.stride,\n",
    "            padding=old_conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            new_conv1.weight[:] = old_conv1.weight.mean(dim=1, keepdim=True)\n",
    "        backbone.conv1 = new_conv1\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.head = UPerHead(\n",
    "            in_channels=(256, 512, 1024, 2048),\n",
    "            fpn_dim=256,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        c2 = self.backbone.layer1(x)\n",
    "        c3 = self.backbone.layer2(c2)\n",
    "        c4 = self.backbone.layer3(c3)\n",
    "        c5 = self.backbone.layer4(c4)\n",
    "\n",
    "        logits_1_4 = self.head(c2, c3, c4, c5)\n",
    "        logits = F.interpolate(logits_1_4, size=(TARGET_H, TARGET_W),\n",
    "                               mode=\"bilinear\", align_corners=False)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. Training & Validation\n",
    "# =========================\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "        y = batch[\"mask\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "        y = batch[\"mask\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y, ignore_index=IGNORE_INDEX)\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6. Inference & Submission\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def predict_and_make_submission(model, test_images_dir: Path, out_csv_path: Path):\n",
    "    \"\"\"\n",
    "    Run inference on all npy files and generate submission CSV:\n",
    "    - one row per patch\n",
    "    - length = 160*272\n",
    "    - pad with -1 if original width < 272\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    test_ds = WellSegDataset(test_images_dir, y_csv_path=None)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    preds_dict = {}\n",
    "\n",
    "    for batch in test_loader:\n",
    "        name = batch[\"name\"][0]\n",
    "        raw_w = int(batch[\"raw_w\"][0])\n",
    "        x = batch[\"image\"].to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        pred_full = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype(np.int64)\n",
    "\n",
    "        pred = pred_full[:, :raw_w]\n",
    "        if raw_w < TARGET_W:\n",
    "            padded = np.full((TARGET_H * TARGET_W,), IGNORE_INDEX, dtype=np.int64)\n",
    "            padded[: TARGET_H * raw_w] = pred.flatten()\n",
    "            preds_dict[name] = padded\n",
    "        else:\n",
    "            preds_dict[name] = pred.flatten()\n",
    "\n",
    "    sub = pd.DataFrame(preds_dict, dtype=\"int64\").T\n",
    "    sub.to_csv(out_csv_path)\n",
    "    print(f\"[OK] Submission saved to: {out_csv_path}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 7. Main\n",
    "# =========================\n",
    "def main():\n",
    "    train_ds_all = WellSegDataset(TRAIN_IMAGES_DIR, Y_TRAIN_CSV)\n",
    "\n",
    "    VAL_WELLS = {6}\n",
    "    train_indices, val_indices = [], []\n",
    "    for i, name in enumerate(train_ds_all.names):\n",
    "        w = parse_well_id(name)\n",
    "        if w in VAL_WELLS:\n",
    "            val_indices.append(i)\n",
    "        else:\n",
    "            train_indices.append(i)\n",
    "\n",
    "    train_ds = Subset(train_ds_all, train_indices)\n",
    "    val_ds = Subset(train_ds_all, val_indices)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Training samples: {len(train_ds)} | Validation samples: {len(val_ds)} | val_wells={VAL_WELLS}\")\n",
    "    print(f\"DEVICE: {DEVICE}\")\n",
    "\n",
    "    model = UPerNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    best_val = 1e9\n",
    "    best_path = DATA_ROOT / \"best_upernet.pth\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "        va_loss = valid_one_epoch(model, val_loader)\n",
    "        print(f\"Epoch {epoch:02d}/{EPOCHS} | train_loss={tr_loss:.4f} | val_loss={va_loss:.4f}\")\n",
    "\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"  -> Best model saved: {best_path}\")\n",
    "\n",
    "    out_csv = DATA_ROOT / \"submission.csv\"\n",
    "    state_dict = torch.load(best_path, map_location=DEVICE, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    predict_and_make_submission(model, TEST_IMAGES_DIR, out_csv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
